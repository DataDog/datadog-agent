import io
import os
import platform
import re
import sys
import tarfile
import tempfile
import xml.etree.ElementTree as ET
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from shutil import which
from subprocess import PIPE, CalledProcessError, Popen

from invoke.exceptions import Exit

from tasks.flavor import AgentFlavor
from tasks.libs.common.color import color_message
from tasks.libs.common.utils import gitlab_section
from tasks.libs.pipeline.notifications import (
    DEFAULT_JIRA_PROJECT,
    DEFAULT_SLACK_CHANNEL,
    GITHUB_JIRA_MAP,
    GITHUB_SLACK_MAP,
)
from tasks.testwasher import TestWasher

E2E_INTERNAL_ERROR_STRING = "E2E INTERNAL ERROR"
CODEOWNERS_ORG_PREFIX = "@DataDog/"
REPO_NAME_PREFIX = "github.com/DataDog/datadog-agent/"
JOB_ENV_FILE_NAME = "job_env.txt"
TAGS_FILE_NAME = "tags.txt"


def get_datadog_ci_command():
    path_datadog_ci = which("datadog-ci")
    if path_datadog_ci is None:
        raise FileNotFoundError("datadog-ci command not found")
    return path_datadog_ci


def enrich_junitxml(xml_path: str, flavor: AgentFlavor):
    """
    Modifies the JUnit XML file:
    1. Adds a flavor field to it, to allow tagging tests by flavor.
    2. Assigns empty classname attributes for each test case given the name
       of the parent test suite (timeouts do not have classnames).
    """
    tree = ET.parse(xml_path)
    root = tree.getroot()

    # 1. Create a new element containing the flavor and append it to the tree
    flavor_element = ET.Element('flavor')
    flavor_element.text = flavor.name
    root.append(flavor_element)

    # 2. Assign empty test cases
    for testsuite in root.findall('.//testsuite'):
        testsuite_name = testsuite.get('name')
        for testcase in testsuite.findall('.//testcase'):
            # The class name cannot be found, set it to the testsuite name
            if testcase.get('classname') == '':
                testcase.set('classname', testsuite_name)

    # Write back to the original file
    tree.write(xml_path)


def junit_upload_from_tgz(junit_tgz, result_json, codeowners_path=".github/CODEOWNERS"):
    """
    Upload all JUnit XML files contained in given tgz archive.
    """
    from codeowners import CodeOwners

    with open(codeowners_path) as f:
        codeowners = CodeOwners(f.read())

    junit_tgz = find_tarball(junit_tgz)

    with (
        gitlab_section(f"Uploading JUnit files for {junit_tgz}", collapsed=True),
        tempfile.TemporaryDirectory() as unpack_dir,
    ):
        flaky_failures, marked_flaky_tests = get_flaky_failures_and_marked_flaky_tests_from_test_output(result_json)
        working_dir = Path(unpack_dir)
        # unpack all files from archive
        with tarfile.open(junit_tgz) as tgz:
            tgz.extractall(path=str(working_dir))
        # If archive contains folders, save them as we will put split xmls in folder on the working_dir
        xml_folders = [item for item in working_dir.iterdir() if item.is_dir()]

        # Split xml files by codeowners
        generated_xmls = 0
        for xmlfile in list(working_dir.glob("**/*.xml")):  # We need to cast the generator to avoid infinite loop
            if not xmlfile.is_file():
                print(f"[WARN] Matched folder named {xmlfile}")
                continue
            generated_xmls += split_junitxml(working_dir, xmlfile, codeowners, flaky_failures, marked_flaky_tests)
        print(f"Created {generated_xmls} JUnit XML files from {junit_tgz}")
        # *-fast(-v2).tgz contains only tests related to the modified code, they can be empty
        if generated_xmls == 0 and "-fast" not in junit_tgz:
            raise Exit(f"[ERROR] No JUnit XML files for upload found in: {junit_tgz}")

        # Upload junit on a per-team basis (all folders except the one part of the original archive)
        team_folders = [item for item in working_dir.iterdir() if item.is_dir() and item not in xml_folders]
        with ThreadPoolExecutor() as executor:
            for log in executor.map(upload_junitxmls, team_folders):
                print(log)


def get_flaky_failures_and_marked_flaky_tests_from_test_output(result_json):
    """
    Read the test output file generated by gotestsum which contains a list of json for each unit test.
    We catch all tests marked as flaky in source code: they contain a certain message in the output field.
    """
    flaky_failures = defaultdict(set)
    flaky_tests = defaultdict(set)

    if os.path.exists(result_json):
        tw = TestWasher(test_output_json_file=result_json)
        flaky_failures.update(tw.get_flaky_failures())
        flaky_tests.update(tw.get_flaky_marked_tests())
    else:
        print(f"{color_message('Warning', 'yellow')}: No test output file found at {result_json}")

    return flaky_failures, flaky_tests


def find_tarball(tarball):
    """
    handle weird kitchen bug where it places the tarball in a subdirectory of the same name
    """
    if os.path.isdir(tarball):
        tmp_tgz = os.path.join(tarball, os.path.basename(tarball))
        if not os.path.isfile(tmp_tgz):
            tmp_tgz = os.path.join(tarball, "junit.tar.gz")
        return tmp_tgz
    return tarball


def read_additional_tags(folder: Path):
    """
    Read tags from a tags.txt file in the given folder
    """
    tags = []
    tagsfile = folder / TAGS_FILE_NAME
    if tagsfile.exists():
        with tagsfile.open() as tf:
            tags = tf.read().split()
    return tags


def split_junitxml(root_dir: Path, xml_path: Path, codeowners, flaky_failures, marked_flaky_tests):
    """
    Split a junit XML into several according to the suite name and the codeowners.
    Returns a list with the owners of the written files.
    """
    tree = ET.parse(xml_path)
    output_xmls = {}

    flem = tree.find("flavor")
    flavor = flem.text if flem else AgentFlavor.base.name

    for suite in tree.iter("testsuite"):
        path = suite.attrib["name"].replace(REPO_NAME_PREFIX, "", 1)

        # Dirs in CODEOWNERS might end with "/", but testsuite names in JUnit XML
        # don't, so for determining ownership we append "/" temporarily.
        owners = codeowners.of(path + "/")
        if not owners:
            # In kitchen testing the test name might not be a file path, so we check the file attribute instead
            filepath = next(tree.iter("testcase")).attrib.get("file", None)
            if filepath:
                if filepath.startswith("./"):  # Leading "./" is not handled by codeowners
                    filepath = filepath[2:]
                owners = codeowners.of(filepath)
                main_owner = owners[0][1][len(CODEOWNERS_ORG_PREFIX) :]
            else:
                main_owner = "none"
        else:
            main_owner = owners[0][1][len(CODEOWNERS_ORG_PREFIX) :]

        if main_owner in output_xmls:
            xml = output_xmls[main_owner]
        else:
            xml = ET.ElementTree(ET.Element("testsuites"))
            output_xmls[main_owner] = xml
        # Flag the test as known flaky if gotestsum already knew it
        for test_case in suite.iter("testcase"):
            pkg_name = test_case.attrib["classname"]
            test_name = test_case.attrib["name"]
            if pkg_name in flaky_failures and test_name in flaky_failures[pkg_name]:
                test_case.attrib["agent_is_known_flaky"] = "true"
                test_case.attrib["agent_is_flaky_failure"] = "true"
            else:
                test_case.attrib["agent_is_known_flaky"] = "false"
                test_case.attrib["agent_is_flaky_failure"] = "false"
            if pkg_name in marked_flaky_tests and test_name in marked_flaky_tests[pkg_name]:
                test_case.attrib["agent_is_marked_flaky"] = "true"
            else:
                test_case.attrib["agent_is_marked_flaky"] = "false"

        xml.getroot().append(suite)

    # Save the split XMLs in folders with <owner>_<flavor> name (they will be uploaded with the same tags)
    for owner, xml in output_xmls.items():
        write_dir = root_dir / f"{owner}_{flavor}"
        if not write_dir.exists():
            write_dir.mkdir()
        xml.write(write_dir / xml_path.name, encoding="UTF-8", xml_declaration=True)
    return len(output_xmls)


def upload_junitxmls(team_dir: Path):
    """
    Upload all per-team split JUnit XMLs from given directory.
    """
    datadog_ci_command = [get_datadog_ci_command(), "junit", "upload"]
    additional_tags = read_additional_tags(team_dir.parent)
    process_env = _update_environ(team_dir.parent)
    processes = []

    owner, flavor = team_dir.name.split("_")
    # Kitchen/e2e can generate additional tags
    xml_files = group_per_tags(team_dir, additional_tags)
    for flags, files in xml_files.items():
        args = set_tags(owner, flavor, flags, additional_tags, files[0])
        args.extend(files)
        processes.append(Popen(datadog_ci_command + args, bufsize=-1, env=process_env, stdout=PIPE, stderr=PIPE))

    for process in processes:
        stdout, stderr = process.communicate()
        print(stdout)
        print(f" Uploaded {len(tuple(team_dir.iterdir()))} files for {team_dir.name}")
        if stderr:
            print(f"Failed uploading junit:\n{stderr.decode()}", file=sys.stderr)
            raise CalledProcessError(process.returncode, datadog_ci_command)
    return ""  # For ThreadPoolExecutor.map. Without this it prints None in the log output.


def group_per_tags(team_dir: Path, additional_tags: list):
    xml_files = defaultdict(list)
    for file in team_dir.iterdir():
        flags = "default"
        if is_e2e_internal_failure(file):
            flags = "e2e"
        if is_kitchen_version(additional_tags):
            flags = "kitchen" if flags == "default" else "kitchen-e2e"
        xml_files[flags].append(str(file))
    return xml_files


def is_e2e_internal_failure(xml_path: Path):
    """
    Check if the given JUnit XML file contains E2E INTERAL ERROR string.
    """
    with xml_path.open(encoding="utf8") as f:
        filecontent = f.read()
    return E2E_INTERNAL_ERROR_STRING in filecontent


def is_kitchen_version(tags):
    """
    Check if we need to add the version from the kitchen file name to the tags
    """
    return tags and "upload_option.os_version_from_name" in tags


def set_tags(owner, flavor, flag: str, additional_tags, file_name):
    codeowner = CODEOWNERS_ORG_PREFIX + owner
    slack_channel = GITHUB_SLACK_MAP.get(codeowner.lower(), DEFAULT_SLACK_CHANNEL)[1:]
    jira_project = GITHUB_JIRA_MAP.get(codeowner.lower(), DEFAULT_JIRA_PROJECT)[0:]
    tags = [
        "--service",
        "datadog-agent",
        "--tags",
        f'test.codeowners:["{codeowner}"]',
        "--tags",
        f"test.flavor:{flavor}",
        "--tags",
        f"slack_channel:{slack_channel}",
        "--tags",
        f"jira_project:{jira_project}",
        "--tags",
        f"gitlab.pipeline_source:{os.environ['CI_PIPELINE_SOURCE']}",
        "--xpath-tag",
        "test.agent_is_known_flaky=/testcase/@agent_is_known_flaky",
        "--xpath-tag",
        "test.agent_is_flaky_failure=/testcase/@agent_is_flaky_failure",
        "--xpath-tag",
        "test.agent_is_marked_flaky=/testcase/@agent_is_marked_flaky",
    ]
    if 'e2e' in flag:
        tags.extend(["--tags", "e2e_internal_error:true"])
    if 'kitchen' in flag:
        version_match = re.search(r"kitchen-rspec-([a-zA-Z0-9]+)-?([0-9-]*)-.*\.xml", file_name)
        exact_version = version_match.group(1) + version_match.group(2).replace("-", ".")
        tags.extend(["--tags", f"version:{exact_version}"])
        additional_tags.remove("upload_option.os_version_from_name")
    tags.extend(additional_tags)
    return tags


def _update_environ(unpack_dir: Path):
    """
    Add data from the job_env to current env if any, for the junit upload command
    """
    process_env = os.environ.copy()

    job_env = {}
    envfile = unpack_dir / JOB_ENV_FILE_NAME
    if envfile.exists():
        with envfile.open() as jf:
            for line in jf:
                if not line.strip():
                    continue
                key, val = line.strip().split('=', 1)
                job_env[key] = val
        process_env.update(job_env)
    return process_env


def _normalize_architecture(architecture):
    architecture = architecture.lower()
    normalize_table = {"amd64": "x86_64"}
    return normalize_table.get(architecture, architecture)


def produce_junit_tar(files: list[str], result_path):
    """
    Produce a tgz file containing all given files JUnit XML files and add a special file
    with additional tags.
    """
    # NOTE: for now, we can't pass CI_JOB_URL or CI_JOB_NAME through `--tags`, because
    # the parsing logic tags breaks on URLs, as they contain colons.
    # Therefore we pass it through environment variable.
    tags = {
        "os.platform": platform.system().lower(),
        "os.architecture": _normalize_architecture(platform.machine()),
    }
    with tarfile.open(result_path, "w:gz") as tgz:
        for file in files:
            tgz.add(file, arcname=file.replace(os.path.sep, "-"))

        tags_file = io.BytesIO()
        for k, v in tags.items():
            tags_file.write(f"--tags {k}:{v} ".encode())
        tags_info = tarfile.TarInfo(TAGS_FILE_NAME)
        tags_info.size = tags_file.getbuffer().nbytes
        tags_file.seek(0)
        tgz.addfile(tags_info, tags_file)

        job_env_file = io.BytesIO()
        job_env_file.writelines(
            [
                f'CI_JOB_URL={os.environ.get("CI_JOB_URL", "")}\n'.encode(),
                f'CI_JOB_NAME={os.environ.get("CI_JOB_NAME", "")}'.encode(),
            ]
        )
        job_env_info = tarfile.TarInfo(JOB_ENV_FILE_NAME)
        job_env_info.size = job_env_file.getbuffer().nbytes
        job_env_file.seek(0)
        tgz.addfile(job_env_info, job_env_file)
