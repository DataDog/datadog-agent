{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Datadog Agent","text":"<p>Welcome to the wonderful world of developing the Datadog Agent. Here we document how we do things, advanced debugging techniques, coding conventions &amp; best practices, the internals of our testing infrastructure, and so much more.</p> <p>If you are intrigued, continue reading. If not, continue all the same </p>"},{"location":"#getting-started","title":"Getting started","text":"<p>First, you'll want to set up your development environment.</p>"},{"location":"#navigation","title":"Navigation","text":"<p>Desktop readers can use keyboard shortcuts to navigate.</p> Keys Action <ul><li>, (comma)</li><li>p</li></ul> Navigate to the \"previous\" page <ul><li>. (period)</li><li>n</li></ul> Navigate to the \"next\" page <ul><li>/</li><li>s</li></ul> Display the search modal"},{"location":"setup/","title":"Set up development environment","text":""},{"location":"setup/#windows","title":"Windows","text":"<p>To build the agent on Windows, see datadog-agent-buildimages.</p>"},{"location":"setup/#linux-and-macos","title":"Linux and macOS","text":""},{"location":"setup/#python","title":"Python","text":"<p>The Agent embeds a full-fledged CPython interpreter so it requires the development files to be available in the dev env. The Agent can embed Python 2 and/or Python 3, you will need development files for all versions you want to support.</p> <p>If you're on OSX/macOS, installing Python 2.7 and/or 3.11 with Homebrew:</p> <pre><code>brew install python@2\nbrew install python@3.11\n</code></pre> <p>On Linux, depending on the distribution, you might need to explicitly install the development files, for example on Ubuntu:</p> <pre><code>sudo apt-get install python2.7-dev\nsudo apt-get install python3.11-dev\n</code></pre> <p>On Windows, install Python 2.7 and/or 3.11 via the official installer brings along all the development files needed:</p> <p>Warning</p> <p>If you don't use one of the Python versions that are explicitly supported, you may have problems running the built Agent's Python checks, especially if using a virtualenv. At this time, only Python 3.11 is confirmed to work as expected in the development environment.</p>"},{"location":"setup/#python-dependencies","title":"Python Dependencies","text":""},{"location":"setup/#preface","title":"Preface","text":"<p>To protect and isolate your system-wide python installation, a python virtual environment is highly recommended (though optional). It will help keep a self-contained development environment and ensure a clean system Python.</p> <p>Note</p> <p>Due to the way some virtual environments handle executable paths (e.g. <code>python -m venv</code>), not all virtual environment options will be able to run the built Agent correctly. At this time, the only confirmed virtual enviroment creator that is known for sure to work is <code>virtualenv</code>.</p> <ul> <li>Install the virtualenv module:     <pre><code>python3 -m pip install virtualenv\n</code></pre></li> <li>Create the virtual environment:     <pre><code>virtualenv $GOPATH/src/github.com/DataDog/datadog-agent/venv\n</code></pre></li> <li>Activate the virtualenv (OS-dependent). This must be done for every new terminal before you start.</li> </ul> <p>If using virtual environments when running the built Agent, you may need to override the built Agent's search path for Python check packages using the <code>PYTHONPATH</code> variable (your target path must have the pre-requisite core integration packages installed though).</p> <pre><code>PYTHONPATH=\"./venv/lib/python3.11/site-packages:$PYTHONPATH\" ./agent run ...\n</code></pre> <p>See also some notes in ./checks about running custom python checks.</p>"},{"location":"setup/#invoke","title":"Invoke","text":"<p>Invoke is a task runner written in Python that is extensively used in this project to orchestrate builds and test runs. Our invoke tasks are only compatible with Python 3, thus you will need to use Python 3 to run them.</p> <p>Though you may install invoke in a variety of way we suggest you use the provided requirements file and <code>pip</code>:</p> <pre><code>pip install -r tasks/requirements.txt\n</code></pre> <p>This procedure ensures you not only get the correct version of <code>invoke</code>, but also any additional python dependencies our development workflow may require, at their expected versions. It will also pull other handy development tools/deps (<code>reno</code>, or <code>docker</code>).</p>"},{"location":"setup/#golang","title":"Golang","text":"<p>You must install Golang version <code>1.21.7</code> or higher. Make sure that <code>$GOPATH/bin</code> is in your <code>$PATH</code> otherwise <code>invoke</code> cannot use any additional tool it might need.</p> <p>Note</p> <p>Versions of Golang that aren't an exact match to the version specified in our build images (see e.g. here) may not be able to build the agent and/or the rtloader binary properly.</p>"},{"location":"setup/#installing-tooling","title":"Installing tooling","text":"<p>From the root of <code>datadog-agent</code>, run <code>invoke install-tools</code> to install go tooling. This uses <code>go</code> to install the necessary dependencies.</p>"},{"location":"setup/#system-or-embedded","title":"System or Embedded?","text":"<p>When working on the Agent codebase you can choose among two different ways to build the binary, informally named System and Embedded builds. For most contribution scenarios you should rely on the System build (the default) and use the Embedded one only for specific use cases. Let's explore the differences.</p>"},{"location":"setup/#system-build","title":"System build","text":"<p>System builds use your operating system's standard system libraries to satisfy the Agent's external dependencies. Since, for example, macOS 10.11 may provide a different version of Python than macOS 10.12, system builds on each of these platforms may produce different Agent binaries. If this doesn't matter to you\u2014perhaps you just want to contribute a quick bugfix\u2014do a System build; it's easier and faster than an Embedded build. System build is the default for all build and test tasks, so you don't need to configure anything there. But to make sure you have system copies of all the Agent's dependencies, skip the Embedded build section below and read on to see how to install them via your usual package manager (apt, yum, brew, etc).</p>"},{"location":"setup/#embedded-build","title":"Embedded build","text":"<p>Embedded builds download specifically-versioned dependencies and compile them locally from sources. We run Embedded builds to create Datadog's official Agent releases (i.e. RPMs, debs, etc), and while you can run the same builds while developing locally, the process is as slow as it sounds. Hence, you should only use them when you care about reproducible builds. For example:</p> <ul> <li>you want to build an agent binary that can be used as-is to replace the binary of an existing agent installation</li> <li>some dependencies are not available on your system</li> <li>you're working or debugging at a very low level: let's say you're adding a function to the Python bindings, you want to make sure you're using the exact same versions of Python as the official Agent packages</li> </ul> <p>Embedded builds rely on Omnibus to download and build dependencies, so you need a recent <code>ruby</code> environment with <code>bundler</code> installed. See how to build Agent packages with Omnibus for more details.</p>"},{"location":"setup/#systemd","title":"Systemd","text":"<p>The agent is able to collect systemd journal logs using a wrapper on the systemd utility library.</p> <p>On Ubuntu/Debian:</p> <pre><code>sudo apt-get install libsystemd-dev\n</code></pre> <p>On Redhat/CentOS:</p> <pre><code>sudo yum install systemd-devel\n</code></pre>"},{"location":"setup/#docker","title":"Docker","text":"<p>If you want to build a Docker image containing the Agent, or if you wan to run system and integration tests you need to run a recent version of Docker in your dev environment.</p>"},{"location":"setup/#doxygen","title":"Doxygen","text":"<p>We use Doxygen to generate the documentation for the <code>rtloader</code> part of the Agent.</p> <p>To generate it (using the <code>invoke rtloader.generate-doc</code> command), you'll need to have Doxygen installed on your system and available in your <code>$PATH</code>. You can compile and install Doxygen from source with the instructions available here. Alternatively, you can use already-compiled Doxygen binaries from here.</p> <p>To get the dependency graphs, you may also need to install the <code>dot</code> executable from graphviz and add it to your <code>$PATH</code>.</p>"},{"location":"setup/#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>It is optional but recommended to install <code>pre-commit</code> to run a number of checks done by the CI locally.</p>"},{"location":"setup/#installation","title":"Installation","text":"<p>To install it, run:</p> <pre><code>python3 -m pip install pre-commit\npre-commit install\n</code></pre> <p>The <code>shellcheck</code> pre-commit hook requires having the <code>shellcheck</code> binary installed and in your <code>$PATH</code>. To install it, run:</p> <pre><code>inv install-shellcheck --destination &lt;path&gt;\n</code></pre> <p>(by default, the shellcheck binary is installed in <code>/usr/local/bin</code>).</p>"},{"location":"setup/#skipping-pre-commit","title":"Skipping <code>pre-commit</code>","text":"<p>If you want to skip <code>pre-commit</code> for a specific commit you can add <code>--no-verify</code> to the <code>git commit</code> command.</p>"},{"location":"setup/#running-pre-commit-manually","title":"Running <code>pre-commit</code> manually","text":"<p>If you want to run one of the checks manually, you can run <code>pre-commit run &lt;check name&gt;</code>.</p> <p>You can run it on all files with the <code>--all-files</code> flag.</p> <pre><code>pre-commit run flake8 --all-files  # run flake8 on all files\n</code></pre> <p>See <code>pre-commit run --help</code> for further options.</p>"},{"location":"setup/#setting-up-visual-studio-code-dev-container","title":"Setting up Visual Studio Code Dev Container","text":"<p>Microsoft Visual Studio Code with the devcontainer plugin allow to use a container as remote development environment in vscode. It simplify and isolate the dependencies needed to develop in this repository.</p> <p>To configure the vscode editor to use a container as remote development environment you need to:</p> <ul> <li>Install the devcontainer plugin and the golang language plugin.</li> <li>Run the following invoke command <code>invoke vscode.setup-devcontainer --image \"&lt;image name&gt;\"</code>. This command will create the devcontainer configuration file <code>./devcontainer/devcontainer.json</code>.</li> <li>Start or restart your vscode editor.</li> <li>A pop-up should show-up to propose to \"reopen in container\" your workspace.</li> <li>The first start, it might propose you to install the golang plugin dependencies/tooling.</li> </ul>"},{"location":"setup/#windows-development-environment","title":"Windows development environment","text":""},{"location":"setup/#code-editor","title":"Code editor","text":"<p>Microsoft Visual Studio Code is recommended as it's lightweight and versatile.</p> <p>Building on Windows requires multiple 3<sup>rd</sup>-party software to be installed. To avoid the complexity, Datadog recommends to make the code change in VS Code, and then do the build in Docker image. For complete information, see Build the Agent packages</p>"},{"location":"guidelines/contributing/","title":"Contributing to Datadog Agent","text":"<p>First of all, thanks for contributing!</p> <p>This document provides some basic guidelines for contributing to this repository. To propose improvements, feel free to submit a PR.</p>"},{"location":"guidelines/contributing/#submitting-issues","title":"Submitting issues","text":"<ul> <li>If you think you've found an issue, please search the Agent Troubleshooting section to see if it's known.</li> <li>If you\u2019re still unsure about the issue, you may reach out to the Datadog support team with a flare from your Agent.</li> <li>Finally, you can open a Github issue.</li> </ul>"},{"location":"guidelines/contributing/#pull-requests","title":"Pull Requests","text":"<p>Have you fixed a bug or written a new check and want to share it? Many thanks!</p> <p>In order to ease/speed up our review, here are some items you can check/improve when submitting your PR:</p> Contributor ChecklistReviewer Checklist <ul> <li> <p> Have a proper commit history (we advise you to rebase if needed) with clear commit messages.</p> </li> <li> <p> Write tests for the code you wrote.</p> </li> <li> <p> Preferably make sure that all tests pass locally.</p> </li> <li> <p> Summarize your PR with an explanatory title and a message describing your changes, cross-referencing any related bugs/PRs.</p> </li> <li> <p> Use Reno to create a release note.</p> </li> <li> <p> Open your PR against the <code>main</code> branch.</p> </li> <li> <p> Provide adequate QA/testing plan information.</p> </li> </ul> <ul> <li> <p> The added code comes with tests.</p> </li> <li> <p> The CI is green, all tests are passing (required or not).</p> </li> <li> <p> All applicable labels are set on the PR (see PR labels list).</p> </li> <li> <p> If applicable, the config template has been updated.</p> </li> </ul> <p>Note</p> <p>Adding GitHub labels is only possible for contributors with write access.</p> <p>Your pull request must pass all CI tests before we will merge it. If you're seeing an error and don't think it's your fault, it may not be! Join us on Slack or send us an email, and together we'll get it sorted out.</p>"},{"location":"guidelines/contributing/#keep-it-small-focused","title":"Keep it small, focused","text":"<p>Avoid changing too many things at once. For instance if you're fixing the NTP check and at the same time shipping a dogstatsd improvement, it makes reviewing harder and the time-to-release longer.</p>"},{"location":"guidelines/contributing/#commit-messages","title":"Commit Messages","text":"<p>Please don't be this person: <code>git commit -m \"Fixed stuff\"</code>. Take a moment to write meaningful commit messages.</p> <p>The commit message should describe the reason for the change and give extra details that will allow someone later on to understand in 5 seconds the thing you've been working on for a day.</p> <p>This includes editing the commit message generated by GitHub from:</p> <pre><code>Including new features\n\n* Fix linter\n* WIP\n* Add test for x86\n* Fix licenses\n* Cleanup headers\n</code></pre> <p>to:</p> <pre><code>Including new features\n\nThis feature does this and that. Some tests are excluded on x86 because of ...\n</code></pre> <p>If your commit is only shipping documentation changes or example files, and is a complete no-op for the test suite, please add [skip ci] in the commit message body to skip the build and give that slot to someone else who does need it.</p>"},{"location":"guidelines/contributing/#pull-request-workflow","title":"Pull request workflow","text":"<p>The goals ordered by priority are:</p> <ul> <li>Make PR reviews (both initial and follow-up reviews) easy for reviewers using GitHub</li> <li>On the <code>main</code> branch, have a meaningful commit history that allows understanding (even years later) what each commit does, and why.</li> </ul> <p>You must open the PR when the code is reviewable or you must set the PR as draft if you want to share code before it's ready for actual reviews.</p>"},{"location":"guidelines/contributing/#before-the-first-pr-review","title":"Before the first PR review","text":"<p>Before the first PR review, meaningful commits are best: logically-encapsulated commits help the reviews go quicker and make the job for the reviewer easier. Conflicts with <code>main</code> can be resolved with a <code>git rebase origin/main</code> and a force push if it makes future review(s) easier.</p>"},{"location":"guidelines/contributing/#after-the-first-review","title":"After the first review","text":"<p>After the first review, to make follow-up reviews easier:</p> <ul> <li>Avoid force pushes: rewriting the history that was already reviewed makes follow-up reviews painful as GitHub loses track of each comment. Instead, address reviews with additional commits on the PR branch.</li> <li>Resolve merge conflicts with <code>main</code> using <code>git merge origin/main</code></li> </ul>"},{"location":"guidelines/contributing/#how-to-merge-to-main","title":"How to merge to <code>main</code>","text":"<p>Once reviews are complete, the merge to <code>main</code> should be done with either:</p> <ul> <li>the squash-merge option, to keep the history of <code>main</code> clean (even though some context/details are lost in the squash). The commit message for this squash should always be edited to concisely describe the commit without extraneous \u201caddress review comments\u201d text.</li> <li>the \u201crebase-merge\u201d option, after manually rewriting the PR\u2019s commit history and force-pushing to the branch. When using this option, the branch must have a clean history.</li> </ul>"},{"location":"guidelines/contributing/#reno","title":"Reno","text":"<p>We use <code>Reno</code> to create our CHANGELOG. Reno is a pretty simple tool.</p> <p>Each PR should include a <code>releasenotes</code> file created with <code>reno</code>, unless the PR doesn't have any impact on the behavior of the Agent and therefore shouldn't be mentioned in the CHANGELOG (examples: repository documentation updates, changes in code comments). PRs that don't require a release note file will be labeled <code>changelog/no-changelog</code> by maintainers.</p> <p>To install reno: <code>pip install reno</code></p> <p>Ultra quick <code>Reno</code> HOWTO:</p> <pre><code>$&gt; reno new &lt;topic-of-my-pr&gt; --edit\n[...]\n# Remove unused sections and fill the relevant ones.\n# Reno will create a new file in releasenotes/notes.\n#\n# Each section from every release note are combined when the CHANGELOG.rst is\n# rendered. So the text needs to be worded so that it does not depend on any\n# information only available in another section. This may mean repeating some\n# details, but each section must be readable independently of the other.\n#\n# Each section note must be formatted as reStructuredText.\n[...]\n</code></pre> <p>Then just add and commit the new releasenote (located in <code>releasenotes/notes/</code>) with your PR. If the change is on the <code>trace-agent</code> (folders <code>cmd/trace-agent</code> or <code>pkg/trace</code>) please prefix the release note with \"APM :\" and the  argument with \"apm-\"."},{"location":"guidelines/contributing/#reno-sections","title":"Reno sections","text":"<p>The main thing to keep in mind is that the CHANGELOG is written for the agent's users and not its developers.</p> <ul> <li> <p><code>features</code>: describe shortly what your feature does.</p> <p>example: <pre><code>features:\n  - |\n    Introducing the Datadog Process Agent for Windows.\n</code></pre></p> </li> <li> <p><code>enhancements</code>: describe enhancements here: new behavior that are too small to be considered a new feature.</p> <p>example: <pre><code>enhancements:\n  - |\n    Windows: Add PDH data to flare.\n</code></pre></p> </li> <li> <p><code>issues</code>: describe known issues or limitation of the agent.</p> <p>example: <pre><code>issues:\n  - |\n    Kubernetes 1.3 &amp; OpenShift 3.3 are currently not fully supported: docker\n    and kubelet integrations work OK, but apiserver communication (event\n    collection, `kube_service` tagging) is not implemented\n</code></pre></p> </li> <li> <p><code>upgrade</code>: List actions to take or limitations that could arise upon upgrading the Agent. Notes here must include steps that users can follow to 1. know if they're affected and 2. handle the change gracefully on their end.</p> <p>example: <pre><code>upgrade:\n  - |\n    If you run a Nomad agent older than 0.6.0, the `nomad_group`\n    tag will be absent until you upgrade your orchestrator.\n</code></pre></p> </li> <li> <p><code>deprecations</code>: List deprecation notes here.</p> <p>example: <pre><code>deprecations:\n- |\n  Changed the attribute name to enable log collection from YAML configuration\n  file from \"log_enabled\" to \"logs_enabled\", \"log_enabled\" is still\n  supported.\n</code></pre></p> </li> <li> <p><code>security</code>: List security fixes, issues, warning or related topics here.</p> <p>example: <pre><code>security:\n  - |\n    The /agent/check-config endpoint has been patched to enforce\n    authentication of the caller via a bearer session token.\n</code></pre></p> </li> <li> <p><code>fixes</code>: List the fixes done in your PR here. Remember to be clear and give a minimum of context so people reading the CHANGELOG understand what the fix is about.</p> <p>example: <pre><code>fixes:\n  - |\n    Fix EC2 tags collection when multiple marketplaces are set.\n</code></pre></p> </li> <li> <p><code>other</code>: Add here every other information you want in the CHANGELOG that don't feat in any other section. This section should rarely be used.</p> <p>example: <pre><code>other:\n  - |\n    Only enable the ``resources`` metadata collector on Linux by default, to match\n    Agent 5's behavior.\n</code></pre></p> </li> </ul>"},{"location":"guidelines/contributing/#pr-labels","title":"PR labels","text":"<p>For internal PRs (from people in the Datadog organisation), you have few extra labels that can be use:</p> <ul> <li><code>community/help-wanted</code>: for community PRs where help is needed to finish it.</li> <li><code>community</code>: for community PRs.</li> <li><code>changelog/no-changelog</code>: for PRs that don't require a reno releasenote (useful for PRs only changing documentation or tests).</li> <li><code>qa/done</code>, <code>qa/no-code-change</code>: if either the <code>qa/no-code-change</code> label or the <code>qa/done</code> label is set, it will skip the creation of a QA card related to this PR during next release process (example: documentation-only PRs).</li> <li><code>major_change</code>: to flag the PR as a major change impacting many/all teams working on the agent and will require deeper QA (example: when we change the Python version shipped in the agent).</li> <li><code>need-change/operator</code>, <code>need-change/helm</code>: indicate that the configuration needs to be modified in the operator / helm chart as well.</li> <li><code>k8s/&lt;min-version&gt;</code>: indicate the lowest Kubernetes version compatible with the PR's feature.</li> <li><code>backport/&lt;branch-name&gt;</code>: Add this label to have your changes automatically backported to <code>&lt;branch-name&gt;</code>.</li> </ul>"},{"location":"guidelines/contributing/#integrations","title":"Integrations","text":"<p>Also called checks, all officially supported Agent integrations live in the integrations-core repo. Please look there to submit related issues, PRs, or review the latest changes. For new integrations, please open a pull request in the integrations-extras repo.</p>"}]}