include: 'https://gitlab-templates.ddbuild.io/slack-notifier/v1/template.yml'

stages:
  - fail_on_tag
  - deps_build
  - source_test
  - binary_build
  - integration_test
  - package_build
  - internal_deploy
  - check_deploy
  - testkitchen_deploy
  - testkitchen_testing
  - pkg_metrics
  - image_build
  - image_deploy
  - deploy6
  - deploy7
  - deploy_invalidate
  - e2e
  - testkitchen_cleanup
  - notify

variables:
  # The SRC_PATH is in the GOPATH of the builders which
  # currently is /go
  SRC_PATH: /go/src/github.com/DataDog/datadog-agent
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /.omnibus
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR: $CI_PROJECT_DIR/.omnibus/pkg/
  # Directory in which we execute the omnibus build for SUSE
  # as we want to separate the RPM built for this distro.
  OMNIBUS_BASE_DIR_SUSE: /.omnibus/suse
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR_SUSE: $CI_PROJECT_DIR/.omnibus/suse/pkg
  OMNIBUS_BASE_DIR_WIN: c:\omni-base\$CI_RUNNER_ID
  OMNIBUS_BASE_DIR_WIN_OMNIBUS: c:/omni-base/$CI_RUNNER_ID
  DD_AGENT_TESTING_DIR: $CI_PROJECT_DIR/test/kitchen
  STATIC_BINARIES_DIR: bin/static
  DOGSTATSD_BINARIES_DIR: bin/dogstatsd
  AGENT_BINARIES_DIR: bin/agent
  CLUSTER_AGENT_BINARIES_DIR: bin/datadog-cluster-agent
  SYSTEM_PROBE_BINARIES_DIR: bin/system-probe
  DEB_S3_BUCKET: apt.datad0g.com
  RPM_S3_BUCKET: yum.datad0g.com
  WIN_S3_BUCKET: dd-agent-mstesting
  PROCESS_S3_BUCKET: datad0g-process-agent
  ANDROID_S3_BUCKET: dd-agent-androidtesting
  DEB_RPM_BUCKET_BRANCH: nightly  # branch of the DEB_S3_BUCKET and RPM_S3_BUCKET repos to release to, 'nightly' or 'beta'
  DEB_TESTING_S3_BUCKET: apttesting.datad0g.com
  RPM_TESTING_S3_BUCKET: yumtesting.datad0g.com
  WINDOWS_TESTING_S3_BUCKET_A6: pipelines/A6/$CI_PIPELINE_ID
  WINDOWS_TESTING_S3_BUCKET_A7: pipelines/A7/$CI_PIPELINE_ID
  WINDOWS_BUILDS_S3_BUCKET: $WIN_S3_BUCKET/builds
  ANDROID_BUILDS_S3_BUCKET: $ANDROID_S3_BUCKET/builds
  DEB_RPM_TESTING_BUCKET_BRANCH: testing  # branch of the DEB_TESTING_S3_BUCKET and RPM_TESTING_S3_BUCKET repos to release to, 'testing'
  DD_REPO_BRANCH_NAME: $CI_COMMIT_REF_NAME
  S3_CP_OPTIONS: --only-show-errors --region us-east-1 --sse AES256
  S3_CP_CMD: aws s3 cp $S3_CP_OPTIONS
  S3_ARTIFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME/$CI_PIPELINE_ID
## comment out both lines below (S3_OMNIBUS_CACHE_BUCKET and USE_S3_CACHING) to allow
## build to succeed with S3 caching disabled.
  S3_OMNIBUS_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-cache-build-stable
  USE_S3_CACHING: --omnibus-s3-cache
  S3_DSD6_URI: s3://dsd6-staging
  RELEASE_VERSION_6: nightly
  RELEASE_VERSION_7: nightly-a7
  DATADOG_AGENT_BUILDIMAGES: v2195996-580f7f3
  DATADOG_AGENT_BUILDERS: v2235609-1baad87
  DATADOG_AGENT_WINBUILDIMAGES: v2123666-a884483
  DATADOG_AGENT_ARMBUILDIMAGES: v2195996-580f7f3
  DATADOG_AGENT_SYSPROBE_BUILDIMAGES: v2233068-8d1298b
  BCC_VERSION: v0.12.0


# Default before_script for all the jobs. If you create a new job and don't want this to execute
# you NEED to overwrite it.
before_script:
  - echo running default before_script
  - cd $SRC_PATH
  - pip install --upgrade --ignore-installed pip setuptools
  - pip install -r requirements.txt
  - inv -e deps --dep-vendor-only

#
# Trigger conditions
#

# run job only when triggered by an external tool (ex: Jenkins). This is used
# for jobs that run both on nightlies and tags
.run_when_triggered: &run_when_triggered
  only:
    - triggers


# anchor to trigger test kitchen setup, run, and cleanup (so all stages
# are run if one stage is run).  Triggers as defined:
# - master
# - tags (a tagged build)
# - triggers (as above, when triggered by an external tool like jenkins)
# - web (when the build is triggered by a specific build request through the
#        web interface.  This way, if a kitchen run is desired on a specific branch,
#        it can be triggered by requesting a specific build)
#
.run_when_testkitchen_triggered: &run_when_testkitchen_triggered
  only:
    - master
    - tags
    - triggers
    - web

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is NOT "nightly". In this setting we are building either a
# new tagged version of the agent (an RC for example). In both cases the
# artifacts should be uploaded to our staging repository.

.run_when_triggered_on_tag_6: &run_when_triggered_on_tag_6
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_6 == "" # no  RELEASE_VERSION means a nightly build for omnibus

.run_when_triggered_on_tag_7: &run_when_triggered_on_tag_7
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_7 == "nightly-a7"
      - $RELEASE_VERSION_7 == "" # no  RELEASE_VERSION means a nightly build for omnibus

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is "nightly". In this setting we build from master and update
# the nightly build for windows, linux and docker.

.run_when_triggered_on_nightly: &run_when_triggered_on_nightly
  only:
    refs:
      - triggers
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_7 == "nightly-a7"

# run job only when triggered on nightly AND when it's a merge to master
.run_when_triggered_on_nightly_or_master: &run_when_triggered_on_nightly_or_master
  only:
    refs:
      - triggers
      - master
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_7 == "nightly-a7"

# skip job only when triggered by an external tool (ex: Jenkins) and when
# BUILD_AGENT_X is set to "no".

.skip_when_unwanted_on_6: &skip_when_unwanted_on_6
  except:
    variables:
      - $RELEASE_VERSION_6 == ""

.skip_when_unwanted_on_7: &skip_when_unwanted_on_7
  except:
    variables:
      - $RELEASE_VERSION_7 == ""

# Fail if we're running a pipeline on a non-triggered tag build
# NOTE: All jobs with 'needs' dependencies should also 'need' this to workaround a Gitlab issue: https://gitlab.com/gitlab-org/gitlab/issues/31526
fail_on_non_triggered_tag:
  stage: fail_on_tag
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  before_script:
    - "# noop"
  script:
    - echo CI_PIPELINE_SOURCE=$CI_PIPELINE_SOURCE CI_COMMIT_TAG=$CI_COMMIT_TAG
    - '[ "$CI_COMMIT_TAG" == "" -o "$CI_PIPELINE_SOURCE" != "push" ]'

#
# deps_build
#
#

# build libbcc
.build_libbcc_common:
  stage: deps_build
  needs: ["fail_on_non_triggered_tag"]
  before_script: []
  script:
    - git clone -b "$BCC_VERSION" --depth=1 https://github.com/iovisor/bcc.git /tmp/bcc
    - mkdir /tmp/bcc/build
    - cd /tmp/bcc/build
    - cmake .. -DCMAKE_INSTALL_PREFIX=/opt/libbcc -DCMAKE_EXE_LINKER_FLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib' -DCMAKE_SHARED_LINKER_FLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib'
    - make -j 4 #"$(nproc)"
    - make install
    - cd /opt/libbcc
    - rm share/bcc/introspection/bps
    - cp $(ldd lib/libbcc.so | awk '$1 ~ /^libtinfo/ {system("dirname " $3)}')/libtinfo* lib
    - tar cvaf /tmp/libbcc.tar.xz .
    - $S3_CP_CMD /tmp/libbcc.tar.xz $S3_ARTIFACTS_URI/libbcc-$ARCH.tar.xz

build_libbcc_x64:
  extends: .build_libbcc_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  variables:
    ARCH: amd64

build_libbcc_arm64:
  extends: .build_libbcc_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64


#
# source_test
#
#

# run tests for windows-64
.run_tests_windows_base:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  before_script:
    - echo "Running windows source tests"
  tags: ["runner:windows-docker", "windowsversion:1809"]
  script:
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true -e PY_RUNTIMES="$PYTHON_RUNTIMES" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_${ARCH}:$Env:DATADOG_AGENT_WINBUILDIMAGES c:\mnt\tasks\winbuildscripts\unittests.bat

run_tests_windows-x64:
  # temporarily allow failure for tests
  extends: .run_tests_windows_base
  allow_failure: true
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x64"

run_tests_windows-x86:
  <<: *run_when_triggered_on_nightly_or_master
  # temporarily allow failure for tests
  extends: .run_tests_windows_base
  allow_failure: true
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x86"

.run_tests_preparation: &run_tests_preparation
  needs: ["fail_on_non_triggered_tag"]
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - pip install wheel
    - pip install -r requirements.txt
    - go get gopkg.in/yaml.v2
    - go get github.com/stretchr/testify
    - inv -e rtloader.make --install-prefix=$SRC_PATH/dev --python-runtimes "$PYTHON_RUNTIMES"
    - inv -e rtloader.install
    - inv -e rtloader.format --raise-if-changed
    - inv -e rtloader.test
    - inv -e deps --verbose --dep-vendor-only

# run tests for deb-x64
run_tests_deb-x64-py2:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '2'
    CONDA_ENV: ddpy2
  <<: *run_tests_preparation
  script:
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4

run_tests_deb-x64-py3:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '3'
    CONDA_ENV: ddpy3
  <<: *run_tests_preparation
  script:
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4

# run tests for rpm-x64
run_tests_rpm-x64-py2:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '2'
    CONDA_ENV: ddpy2
  <<: *run_tests_preparation
  script:
    # Exclude systemd because it cannot succeed on Centos 6: the image doesn't have the shared object required by
    # https://github.com/coreos/go-systemd/blob/c8cc474ba8655dfbdb0ac7fcc09b7faf5b643caf/sdjournal/functions.go#L46
    # This is OK because the test on systemd still runs on the debian image above
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4 --build-exclude=systemd

run_tests_rpm-x64-py3:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '3'
    CONDA_ENV: ddpy3
  <<: *run_tests_preparation
  script:
    # Exclude systemd because it cannot succeed on Centos 6: the image doesn't have the shared object required by
    # https://github.com/coreos/go-systemd/blob/c8cc474ba8655dfbdb0ac7fcc09b7faf5b643caf/sdjournal/functions.go#L46
    # This is OK because the test on systemd still runs on the debian image above
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4 --build-exclude=systemd

# run tests for eBPF code
run_tests_ebpf:
  stage: source_test
  needs: ["fail_on_non_triggered_tag", "build_libbcc_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_BUILDIMAGES
  before_script:
    - cd $SRC_PATH
    - pip3 install distro -c requirements.txt # needed for some of our invoke tasks until the builders image contain it
    - inv -e deps --verbose --dep-vendor-only
    # Retrieve libbcc from S3
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-amd64.tar.xz /tmp/libbcc.tar.xz
    - mkdir /opt/libbcc
    - tar -xvf /tmp/libbcc.tar.xz -C /opt/libbcc
  tags: [ "runner:main", "size:large" ]
  script:
    # For now only check bpf bytes since we don't have a way to run eBPF tests without mounting a debugfs
    - CGO_CFLAGS='-I/opt/libbcc/include' CGO_LDFLAGS='-Wl,-rpath,/opt/libbcc/lib -L/opt/libbcc/lib' inv -e system-probe.test --only-check-bpf-bytes

# scan the dependencies for security vulnerabilities with snyk
run_security_scan_test:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/snyk:latest
  tags: ["runner:main", "size:large"]
  only:
    - master
  before_script:
    # this image isn't built in the datadog-agent-builders repo
    # it doesn't have invoke so we install the dependencies without invoke
    - mkdir -p $GOPATH/src/github.com/DataDog/datadog-agent
    - rsync -azr --delete ./ $GOPATH/src/github.com/DataDog/datadog-agent
    - cd $GOPATH/src/github.com/DataDog/datadog-agent
    - pip install -r requirements.txt
    - inv -e deps --dep-vendor-only
  script:
    - set +x     # don't print the api key to the logs
    # send the list of the dependencies to snyk
    - SNYK_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.snyk_token --with-decryption --query "Parameter.Value" --out text)
      snyk monitor --project-name=datadog-agent-requirements.txt --file=requirements.txt --package-manager=pip
    - SNYK_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.snyk_token --with-decryption --query "Parameter.Value" --out text)
      snyk monitor --project-name=datadog-agent-gopkg.lock --file=Gopkg.lock

# check consistency of Gopkg.lock
run_dep_check_lock:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  before_script:
    - cd $SRC_PATH
    - pip install --upgrade --ignore-installed pip setuptools
    - pip install -r requirements.txt
    - inv -e deps --no-dep-ensure --no-checks
  script:
    # Print a message and fail if dep check fails
    - dep check --skip-vendor || (echo "Gopkg.lock is out of sync with Gopkg.toml and project imports. Please run 'inv deps' and commit the change on Gopkg.lock." && false)

#
# binary_build
#

# build dogstatsd static for deb-x64
build_dogstatsd_static-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --static --major-version 7
    - $S3_CP_CMD $SRC_PATH/$STATIC_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/static/dogstatsd

# build dogstatsd for deb-x64
build_dogstatsd-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --major-version 7
    - $S3_CP_CMD $SRC_PATH/$DOGSTATSD_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/dogstatsd/dogstatsd

# build dogstatsd static for deb-arm
build_dogstatsd_static-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --static --major-version 7
    - $S3_CP_CMD $SRC_PATH/$STATIC_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/static/dogstatsd.$ARCH

# build dogstatsd linked for deb-arm
build_dogstatsd-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --major-version 7
    - $S3_CP_CMD $SRC_PATH/$DOGSTATSD_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/dogstatsd/dogstatsd.$ARCH

# build puppy agent for deb-x64, to make sure the build is not broken because of build flags
build_puppy_agent-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  script:
    - inv -e agent.build --puppy --major-version 7
    - $S3_CP_CMD $SRC_PATH/$AGENT_BINARIES_DIR/agent $S3_ARTIFACTS_URI/puppy/agent

# build puppy agent for ARM, to make sure the build is not broken because of build targets
build_puppy_agent-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only --no-checks
  script:
    - GOOS=linux GOARCH=arm inv -e agent.build --puppy --major-version 7

.cluster_agent-build_common: &cluster_agent-build_common
  stage: binary_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock"]
  script:
    - inv -e cluster-agent.build
    - $S3_CP_CMD $SRC_PATH/$CLUSTER_AGENT_BINARIES_DIR/datadog-cluster-agent $S3_ARTIFACTS_URI/datadog-cluster-agent.$ARCH
    - $S3_CP_CMD $SRC_PATH/Dockerfiles/cluster-agent/datadog-cluster.yaml $S3_ARTIFACTS_URI/datadog-cluster.yaml

# build cluster-agent bin
cluster_agent-build_amd64:
  <<: *cluster_agent-build_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  variables:
    ARCH: amd64
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only

cluster_agent-build_arm64:
  <<: *cluster_agent-build_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only



#
# integration_test
#

# run benchmarks on deb
# run_benchmarks-deb_x64:
#   stage: integration_test
#   image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
#   allow_failure: true  # FIXME: this was set to true to temporarily unblock the pipeline
#   tags: [ "runner:main", "size:large" ]
#   script:
#     - inv -e bench.aggregator
#     # FIXME: in our docker image, non ascii characters printed by the benchmark
#     # make invoke traceback. For now, the workaround is to call the benchmarks
#     # manually
#     - inv -e bench.build-dogstatsd

#     - set +x # make sure we don't output the creds to the build log
#     - DD_AGENT_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.dd_agent_api_key --with-decryption --query "Parameter.Value" --out text)

#     # dogstatsd validation - not really benchmarking: gitlab isn't the right place to do this.
#     - ./bin/benchmarks/dogstatsd -pps=20000 -dur 30 -ser 5 -branch $DD_REPO_BRANCH_NAME -api-key $DD_AGENT_API_KEY
#   artifacts:
#     expire_in: 2 weeks
#     paths:
#       - benchmarks

# check the size of the static dogstatsd binary
run_dogstatsd_size_test:
  stage: integration_test
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd_static-deb_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    # Disable global before_script
    - mkdir -p $STATIC_BINARIES_DIR
    - $S3_CP_CMD $S3_ARTIFACTS_URI/static/dogstatsd $STATIC_BINARIES_DIR/dogstatsd
  script:
    - inv -e dogstatsd.size-test --skip-build

# check the size of the static dogstatsd binary
run_dogstatsd_arm_size_test:
  stage: integration_test
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd_static-deb_arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Disable global before_script
    - mkdir -p $STATIC_BINARIES_DIR
    - $S3_CP_CMD $S3_ARTIFACTS_URI/static/dogstatsd.$ARCH $STATIC_BINARIES_DIR/dogstatsd
  script:
    - inv -e dogstatsd.size-test --skip-build

.system-probe_build_common:
  before_script:
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - '[[ "$ARCH" == arm64 ]] && cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog'
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only
    # Retrieve libbcc from S3
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-$ARCH.tar.xz /tmp/libbcc.tar.xz
    - mkdir -p /opt/datadog-agent/embedded
    - tar -xvf /tmp/libbcc.tar.xz -C /opt/datadog-agent/embedded

  script:
    - CGO_CFLAGS='-I/opt/datadog-agent/embedded/include' CGO_LDFLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib -L/opt/datadog-agent/embedded/lib' inv -e system-probe.build --go-version=1.10.1
    - $S3_CP_CMD $SRC_PATH/$SYSTEM_PROBE_BINARIES_DIR/system-probe $S3_ARTIFACTS_URI/system-probe.$ARCH

build_system-probe-x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["fail_on_non_triggered_tag", "build_libbcc_x64", "run_tests_deb-x64-py3"]
  tags: [ "runner:main", "size:large" ]
  extends: .system-probe_build_common
  variables:
    ARCH: amd64

build_system-probe-arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["fail_on_non_triggered_tag", "build_libbcc_arm64", "run_dep_check_lock"]
  tags: ["runner:docker-arm", "platform:arm64"]
  extends: .system-probe_build_common
  variables:
    ARCH: arm64

#
# package_build
#
#
.agent_build_common_deb: &agent_build_common_deb
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DEB
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent-dbg_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DBG_DEB
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-agent*_${PACKAGE_ARCH}.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Agent package for deb-x64
agent_deb-x64-a6:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py2", "run_tests_deb-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    CONDA_ENV: ddpy3
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
    DESTINATION_DEB: 'datadog-agent_6_amd64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_6_amd64.deb'
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_deb

agent_deb-x64-a7:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_deb-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    CONDA_ENV: ddpy3
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
    DESTINATION_DEB: 'datadog-agent_7_amd64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_7_amd64.deb'
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_deb

agent_deb-arm-a6:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: arm64
    DESTINATION_DEB: 'datadog-agent_6_arm64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_6_arm64.deb'
  before_script:
    - source /root/.bashrc
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_deb

agent_deb-arm-a7:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: arm64
    DESTINATION_DEB: 'datadog-agent_7_arm64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_7_arm64.deb'
  before_script:
    - source /root/.bashrc
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_deb

# build Agent package for deb-x64
puppy_deb-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "build_puppy_agent-deb_x64", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    PACKAGE_ARCH: amd64
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  <<: *skip_when_unwanted_on_7
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --puppy --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-puppy*_amd64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-puppy*_amd64.deb $S3_ARTIFACTS_URI/datadog-puppy_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-puppy*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

.agent_build_common_rpm: &agent_build_common_rpm
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # use --skip-deps since the deps are installed by `before_script`
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR  ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*.rpm' ! -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' rpm -i '{}'
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Agent package for rpm-x64
agent_rpm-x64-a6:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
    CONDA_ENV: ddpy3
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_rpm

# build Agent package for rpm-x64
agent_rpm-x64-a7:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
    CONDA_ENV: ddpy3
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_rpm

  # build Agent package for rpm-arm64
agent_rpm-arm-a6:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: arm64
  before_script:
    - source /root/.bashrc
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_rpm

# build Agent package for rpm-arm64
agent_rpm-arm-a7:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: arm64
  before_script:
    - source /root/.bashrc
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_rpm


.agent_build_common_suse_rpm: &agent_build_common_suse_rpm
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # use --skip-deps since the deps are installed by `before_script`
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' ! -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
    # FIXME: skip the installation step until we fix the preinst/postinst scripts in the rpm package
    # to also work with SUSE11
    # - rpm -i $OMNIBUS_PACKAGE_DIR_SUSE/*.rpm
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# build Agent package for suse-x64
agent_suse-x64-a6:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
  before_script:
    - export RELEASE_VERSION=$RELEASE_VERSION_6
    - inv -e deps --verbose --dep-vendor-only
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_suse_rpm

# build Agent package for suse-x64
agent_suse-x64-a7:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["fail_on_non_triggered_tag", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
  before_script:
    - export RELEASE_VERSION=$RELEASE_VERSION_7
    - inv -e deps --verbose --dep-vendor-only
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_suse_rpm

# cloudfoundry puppy build/windows
windows_zip_agent_binaries_x64:
  stage: package_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock"]
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    OMNIBUS_TARGET: agent_binaries
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_${ARCH}:$Env:DATADOG_AGENT_WINBUILDIMAGES c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\*.zip .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

##
## windows dockerized builds
##

.windows_msi_base:
  stage: package_build
  needs: ["fail_on_non_triggered_tag", "run_dep_check_lock"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  # Unavailable on gitlab < 12.3
  # timeout: 2h 00m
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e CI_JOB_ID=${CI_JOB_ID} -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_${ARCH}:$Env:DATADOG_AGENT_WINBUILDIMAGES c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\${CI_JOB_ID}\*.msi .omnibus\pkg
    - if (Test-Path build-out\${CI_JOB_ID}\*.zip) { copy build-out\${CI_JOB_ID}\*.zip .omnibus\pkg }
    - remove-item -recurse -force build-out\${CI_JOB_ID}
    - get-childitem build-out
    - get-childitem .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

.windows_main_agent_base:
  extends: .windows_msi_base
  variables:
    OMNIBUS_TARGET: main

windows_msi_x64-a7:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7

windows_msi_x86-a7:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *run_when_triggered_on_nightly_or_master

windows_msi_x64-a6:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6

windows_msi_x86-a6:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *run_when_triggered_on_nightly_or_master

.windows_puppy_agent_base:
  extends: .windows_msi_base
  variables:
    OMNIBUS_TARGET: puppy


# build dogstatsd package for Windows
windows_dsd_msi_x64:
  extends: .windows_msi_base
  variables:
    ARCH: "x64"
    PYTHON_RUNTIMES: ""
    AGENT_MAJOR_VERSION: '7'
    OMNIBUS_TARGET: dogstatsd
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7

# build Agent package for android
agent_android_apk:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/android_builder:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  <<: *skip_when_unwanted_on_7
  <<: *run_when_triggered_on_nightly_or_master
  before_script:
    - echo running android before_script
    - cd $SRC_PATH
    - pip install -U pip
    - pip install -r requirements.txt
    - inv -e deps --android --dep-vendor-only --no-checks
    # Some Android license has changed, we have to accept the new version.
    # But on top of that, there is a bug in sdkmanager not updating correctly
    # the existing license, so, we have to manually accept the new license.
    # https://issuetracker.google.com/issues/123054726
    # The real fix will be to change the builders
    - echo "24333f8a63b6825ea9c5514f83c2829b004d1fee" > "$ANDROID_HOME/licenses/android-sdk-license"
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # for now do the steps manually.  Should eventually move this to an invoke
    # task
    - inv -e android.build --major-version 7
    - mkdir -p $OMNIBUS_PACKAGE_DIR
    - cp ./bin/agent/ddagent-*-unsigned.apk $OMNIBUS_PACKAGE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstastd package for deb-x64
dogstatsd_deb-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-dogstatsd*_amd64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb $S3_ARTIFACTS_URI/datadog-dogstatsd_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstastd package for rpm-x64
dogstatsd_rpm-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR


# build Dogstastd package for rpm-x64
dogstatsd_suse-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# deploy debian packages to apt staging repo
deploy_deb_testing-a6:
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb

deploy_deb_testing-a7:
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb


# deploy rpm packages to yum staging repo
deploy_rpm_testing-a6:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_rpm-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/x86_64/
    - aws s3 sync s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID/6 ./rpmrepo/
    - cp $OMNIBUS_PACKAGE_DIR/datadog-*-6.*x86_64.rpm ./rpmrepo/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/x86_64
    - aws s3 sync ./rpmrepo/ s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID/6 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_rpm_testing-a7:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_rpm-x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/x86_64/
    - aws s3 sync s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID/7 ./rpmrepo/
    - cp $OMNIBUS_PACKAGE_DIR/datadog-*-7.*x86_64.rpm ./rpmrepo/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/x86_64
    - aws s3 sync ./rpmrepo/ s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID/7 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy rpm packages to yum staging repo
deploy_suse_rpm_testing-a6:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_suse-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/suse/x86_64/
    - aws s3 sync s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID/6 ./rpmrepo/suse
    - cp $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-6.*x86_64.rpm ./rpmrepo/suse/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/suse/x86_64
    - aws s3 sync ./rpmrepo/suse/ s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID/6 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_suse_rpm_testing-a7:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "agent_suse-x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/suse/x86_64/
    - aws s3 sync s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID/7 ./rpmrepo/suse
    - cp $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-7.*x86_64.rpm ./rpmrepo/suse/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/suse/x86_64
    - aws s3 sync ./rpmrepo/suse/ s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID/7 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy windows packages to our testing bucket
deploy_windows_testing-a6:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "windows_msi_x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6.*.msi" $OMNIBUS_PACKAGE_DIR s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET_A6 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_windows_testing-a7:
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["fail_on_non_triggered_tag", "windows_msi_x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7.*.msi" $OMNIBUS_PACKAGE_DIR s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET_A7 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

#
# Kitchen Test Common templates
#

.kitchen_common: &kitchen_common
  <<: *run_when_testkitchen_triggered
  stage: testkitchen_testing
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/dd-agent-testing:$DATADOG_AGENT_BUILDERS
  artifacts:
    expire_in: 2 weeks
    when: always
    paths:
      - $CI_PROJECT_DIR/kitchen_logs
  tags: [ "runner:main", "size:large" ]
  retry: 1


# Kitchen: agents
# ---------------

.kitchen_agent_a6: &kitchen_agent_a6
  <<: *kitchen_common
  <<: *skip_when_unwanted_on_6
  variables:
    AGENT_MAJOR_VERSION: 6
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6

.kitchen_agent_a7: &kitchen_agent_a7
  <<: *kitchen_common
  <<: *skip_when_unwanted_on_7
  variables:
    AGENT_MAJOR_VERSION: 7
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7


# Kitchen: OSes
# -------------

.kitchen_os_windows: &kitchen_os_windows
  before_script: # Note: if you are changing this, remember to also change .kitchen_test_windows_installer, which has a copy of this with less TEST_PLATFORMS defined.
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="win2008r2,id,/subscriptions/8c56d827-5f07-45ce-8f2b-6c5001db5c6f/resourceGroups/kitchen-test-images/providers/Microsoft.Compute/galleries/kitchenimages/images/Windows2008-R2-SP1/versions/1.0.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2012,urn,MicrosoftWindowsServer:WindowsServer:2012-Datacenter:3.127.20190603"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2012r2,urn,MicrosoftWindowsServer:WindowsServer:2012-R2-Datacenter:4.127.20190603"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2016,urn,MicrosoftWindowsServer:WindowsServer:2016-Datacenter-Server-Core:2016.127.20190603"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2019,urn,MicrosoftWindowsServer:WindowsServer:2019-Datacenter-Core:2019.0.20190603"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_centos: &kitchen_os_centos
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="centos-69,urn,OpenLogic:CentOS:6.9:6.9.20180530"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|centos-77,urn,OpenLogic:CentOS:7.7:7.7.20191209"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|rhel-81,urn,RedHat:RHEL:8.1:8.1.2020020415"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_suse: &kitchen_os_suse
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="sles-11,urn,SUSE:SLES-BYOS:11-SP4:2019.12.05"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|sles-12,urn,SUSE:SLES-BYOS:12-SP4:2019.11.13"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|sles-15,urn,SUSE:SLES-BYOS:15:2019.11.15"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_debian: &kitchen_os_debian
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="debian-8,urn,credativ:Debian:8:8.20190313.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|debian-9,urn,credativ:Debian:9:9.20190515.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|debian-10,urn,Debian:debian-10:10:0.20190709.401"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_ubuntu: &kitchen_os_ubuntu
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="ubuntu-14-04,urn,Canonical:UbuntuServer:14.04.5-LTS:14.04.201905140"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|ubuntu-16-04,urn,Canonical:UbuntuServer:16.04.0-LTS:16.04.201906170"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|ubuntu-18-04,urn,Canonical:UbuntuServer:18.04-LTS:18.04.201906040"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh



# Kitchen: tests
# --------------

.kitchen_test_chef: &kitchen_test_chef
  script:
    - AZURE_LOCATION='North Central US' bash -l tasks/run-test-kitchen.sh chef-test $AGENT_MAJOR_VERSION

.kitchen_test_step_by_step: &kitchen_test_step_by_step
  script:
    - AZURE_LOCATION='Central US' bash -l tasks/run-test-kitchen.sh step-by-step-test $AGENT_MAJOR_VERSION

.kitchen_test_install_script: &kitchen_test_install_script
  script:
    - AZURE_LOCATION='South Central US' bash -l tasks/run-test-kitchen.sh install-script-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade5: &kitchen_test_upgrade5
  script:
    - AZURE_LOCATION='Central US' bash -l tasks/run-test-kitchen.sh upgrade5-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade6: &kitchen_test_upgrade6
  script:
    - AZURE_LOCATION='South Central US' bash -l tasks/run-test-kitchen.sh upgrade6-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade7: &kitchen_test_upgrade7
  script:
    - AZURE_LOCATION='North Central US' bash -l tasks/run-test-kitchen.sh upgrade7-test $AGENT_MAJOR_VERSION

.kitchen_test_windows_installer: &kitchen_test_windows_installer
  before_script: # Override kitchen_os_windows default with a smaller set of TEST_PLATFORMS
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="win2012,urn,MicrosoftWindowsServer:WindowsServer:2012-Datacenter:3.127.20190603"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh
  script:
    - AZURE_LOCATION='North Central US' bash -l tasks/run-test-kitchen.sh windows-install-test $AGENT_MAJOR_VERSION



# Kitchen: scenarios (os * agent)
# -------------------------------

.kitchen_scenario_windows_a6: &kitchen_scenario_windows_a6
  <<: *kitchen_os_windows
  <<: *kitchen_agent_a6
  needs: ["fail_on_non_triggered_tag", "deploy_windows_testing-a6"]

.kitchen_scenario_windows_a7: &kitchen_scenario_windows_a7
  <<: *kitchen_os_windows
  <<: *kitchen_agent_a7
  needs: ["fail_on_non_triggered_tag", "deploy_windows_testing-a7"]

.kitchen_scenario_centos_a6: &kitchen_scenario_centos_a6
  <<: *kitchen_os_centos
  <<: *kitchen_agent_a6
  needs: ["fail_on_non_triggered_tag", "deploy_rpm_testing-a6"]

.kitchen_scenario_centos_a7: &kitchen_scenario_centos_a7
  <<: *kitchen_os_centos
  <<: *kitchen_agent_a7
  needs: ["fail_on_non_triggered_tag", "deploy_rpm_testing-a7"]

.kitchen_scenario_ubuntu_a6: &kitchen_scenario_ubuntu_a6
  <<: *kitchen_os_ubuntu
  <<: *kitchen_agent_a6
  needs: ["fail_on_non_triggered_tag", "deploy_deb_testing-a6"]

.kitchen_scenario_ubuntu_a7: &kitchen_scenario_ubuntu_a7
  <<: *kitchen_os_ubuntu
  <<: *kitchen_agent_a7
  needs: ["fail_on_non_triggered_tag", "deploy_deb_testing-a7"]

.kitchen_scenario_suse_a6: &kitchen_scenario_suse_a6
  <<: *kitchen_os_suse
  <<: *kitchen_agent_a6
  needs: ["fail_on_non_triggered_tag", "deploy_suse_rpm_testing-a6"]

.kitchen_scenario_suse_a7: &kitchen_scenario_suse_a7
  <<: *kitchen_os_suse
  <<: *kitchen_agent_a7
  needs: ["fail_on_non_triggered_tag", "deploy_suse_rpm_testing-a7"]

.kitchen_scenario_debian_a6: &kitchen_scenario_debian_a6
  <<: *kitchen_os_debian
  <<: *kitchen_agent_a6
  needs: ["fail_on_non_triggered_tag", "deploy_deb_testing-a6"]

.kitchen_scenario_debian_a7: &kitchen_scenario_debian_a7
  <<: *kitchen_os_debian
  <<: *kitchen_agent_a7
  needs: ["fail_on_non_triggered_tag", "deploy_deb_testing-a7"]



# Kitchen: final test matrix (tests * scenarios)
# ----------------------------------------------

# run dd-agent-testing for the windows installer
kitchen_windows_installer-a6:
  allow_failure: true
  <<: *kitchen_scenario_windows_a6
  <<: *kitchen_test_windows_installer
  retry: 0

kitchen_windows_installer-a7:
  allow_failure: true
  <<: *kitchen_scenario_windows_a7
  <<: *kitchen_test_windows_installer
  retry: 0

# run dd-agent-testing on windows
kitchen_windows_chef-a6:
  allow_failure: false
  <<: *kitchen_scenario_windows_a6
  <<: *kitchen_test_chef

kitchen_windows_chef-a7:
  allow_failure: false
  <<: *kitchen_scenario_windows_a7
  <<: *kitchen_test_chef

kitchen_windows_upgrade5-a6:
  allow_failure: false
  <<: *kitchen_scenario_windows_a6
  <<: *kitchen_test_upgrade5

kitchen_windows_upgrade5-a7:
  allow_failure: false
  <<: *kitchen_scenario_windows_a7
  <<: *kitchen_test_upgrade5

kitchen_windows_upgrade6-a6:
  allow_failure: false
  <<: *kitchen_scenario_windows_a6
  <<: *kitchen_test_upgrade6

kitchen_windows_upgrade6-a7:
  allow_failure: false
  <<: *kitchen_scenario_windows_a7
  <<: *kitchen_test_upgrade6

kitchen_windows_upgrade7-a7:
  allow_failure: false
  <<: *kitchen_scenario_windows_a7
  <<: *kitchen_test_upgrade7

# run dd-agent-testing on centos
kitchen_centos_chef-a6:
  allow_failure: false
  <<: *kitchen_scenario_centos_a6
  <<: *kitchen_test_chef

kitchen_centos_chef-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_chef

kitchen_centos_install_script-a6:
  allow_failure: false
  <<: *kitchen_scenario_centos_a6
  <<: *kitchen_test_install_script

kitchen_centos_install_script-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_install_script

kitchen_centos_step_by_step-a6:
  allow_failure: false
  <<: *kitchen_scenario_centos_a6
  <<: *kitchen_test_step_by_step

kitchen_centos_step_by_step-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_step_by_step

kitchen_centos_upgrade5-a6:
  allow_failure: false
  <<: *kitchen_scenario_centos_a6
  <<: *kitchen_test_upgrade5

kitchen_centos_upgrade5-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_upgrade5

kitchen_centos_upgrade6-a6:
  allow_failure: false
  <<: *kitchen_scenario_centos_a6
  <<: *kitchen_test_upgrade6

kitchen_centos_upgrade6-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_upgrade6

kitchen_centos_upgrade7-a7:
  allow_failure: false
  <<: *kitchen_scenario_centos_a7
  <<: *kitchen_test_upgrade7

# run dd-agent-testing on ubuntu
# Could fail if we encounter the issue with apt locks/azure agent, but should be investigated if that's the case
kitchen_ubuntu_chef-a6:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a6
  <<: *kitchen_test_chef

kitchen_ubuntu_chef-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_chef

kitchen_ubuntu_install_script-a6:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a6
  <<: *kitchen_test_install_script

kitchen_ubuntu_install_script-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_install_script

kitchen_ubuntu_step_by_step-a6:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a6
  <<: *kitchen_test_step_by_step

kitchen_ubuntu_step_by_step-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_step_by_step

kitchen_ubuntu_upgrade5-a6:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a6
  <<: *kitchen_test_upgrade5

kitchen_ubuntu_upgrade5-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_upgrade5

kitchen_ubuntu_upgrade6-a6:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a6
  <<: *kitchen_test_upgrade6

kitchen_ubuntu_upgrade6-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_upgrade6

kitchen_ubuntu_upgrade7-a7:
  allow_failure: false
  <<: *kitchen_scenario_ubuntu_a7
  <<: *kitchen_test_upgrade7

# run dd-agent-testing on suse
kitchen_suse_chef-a6:
  allow_failure: false
  <<: *kitchen_scenario_suse_a6
  <<: *kitchen_test_chef

kitchen_suse_chef-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_chef

kitchen_suse_install_script-a6:
  allow_failure: false
  <<: *kitchen_scenario_suse_a6
  <<: *kitchen_test_install_script

kitchen_suse_install_script-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_install_script

kitchen_suse_step_by_step-a6:
  allow_failure: false
  <<: *kitchen_scenario_suse_a6
  <<: *kitchen_test_step_by_step

kitchen_suse_step_by_step-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_step_by_step

kitchen_suse_upgrade5-a6:
  allow_failure: false
  <<: *kitchen_scenario_suse_a6
  <<: *kitchen_test_upgrade5

kitchen_suse_upgrade5-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_upgrade5

kitchen_suse_upgrade6-a6:
  allow_failure: false
  <<: *kitchen_scenario_suse_a6
  <<: *kitchen_test_upgrade6

kitchen_suse_upgrade6-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_upgrade6

kitchen_suse_upgrade7-a7:
  allow_failure: false
  <<: *kitchen_scenario_suse_a7
  <<: *kitchen_test_upgrade7

# run dd-agent-testing on debian
# Could fail if we encounter the issue with apt locks/azure agent, but should be investigated if that's the case
kitchen_debian_chef-a6:
  allow_failure: false
  <<: *kitchen_scenario_debian_a6
  <<: *kitchen_test_chef

kitchen_debian_chef-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_chef

kitchen_debian_install_script-a6:
  allow_failure: false
  <<: *kitchen_scenario_debian_a6
  <<: *kitchen_test_install_script

kitchen_debian_install_script-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_install_script

kitchen_debian_step_by_step-a6:
  allow_failure: false
  <<: *kitchen_scenario_debian_a6
  <<: *kitchen_test_step_by_step

kitchen_debian_step_by_step-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_step_by_step

kitchen_debian_upgrade5-a6:
  allow_failure: false
  <<: *kitchen_scenario_debian_a6
  <<: *kitchen_test_upgrade5

kitchen_debian_upgrade5-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_upgrade5

kitchen_debian_upgrade6-a6:
  allow_failure: false
  <<: *kitchen_scenario_debian_a6
  <<: *kitchen_test_upgrade6

kitchen_debian_upgrade6-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_upgrade6

kitchen_debian_upgrade7-a7:
  allow_failure: false
  <<: *kitchen_scenario_debian_a7
  <<: *kitchen_test_upgrade7


#
# pkg_metrics: send metrics about packages
#

send_pkg_size-a6:
  stage: pkg_metrics
  allow_failure: true
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  before_script:
    # tmp while we uppdate the base image
    - apt-get install -y wget rpm2cpio cpio
    - ls -l $OMNIBUS_PACKAGE_DIR
    - ls -l $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  script:
    - source /root/.bashrc && conda activate ddpy3
    - mkdir -p /tmp/deb/agent /tmp/deb/dogstatsd /tmp/deb/puppy
    - mkdir -p /tmp/rpm/agent /tmp/rpm/dogstatsd
    - mkdir -p /tmp/suse/agent /tmp/suse/dogstatsd

    # we silence dpkg and cpio output so we don't exceed gitlab log limit

    # debian
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-agent_6*_amd64.deb /tmp/deb/agent > /dev/null
    - DEB_AGENT_SIZE=$(du -sB1 /tmp/deb/agent | sed 's/\([0-9]\+\).\+/\1/')
    # centos
    - cd /tmp/rpm/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-agent-6.*.x86_64.rpm | cpio -idm > /dev/null
    - RPM_AGENT_SIZE=$(du -sB1 /tmp/rpm/agent | sed 's/\([0-9]\+\).\+/\1/')
    # suse
    - cd /tmp/suse/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-agent-6.*.x86_64.rpm | cpio -idm > /dev/null
    - SUSE_AGENT_SIZE=$(du -sB1 /tmp/suse/agent | sed 's/\([0-9]\+\).\+/\1/')

    - currenttime=$(date +%s)
    - DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key --with-decryption --query "Parameter.Value" --out text)
    - |
      curl --fail -X POST -H "Content-type: application/json" \
      -d "{\"series\":[
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_AGENT_SIZE]], \"tags\":[\"os:debian\", \"package:agent\", \"agent:6\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_AGENT_SIZE]], \"tags\":[\"os:centos\", \"package:agent\", \"agent:6\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_AGENT_SIZE]], \"tags\":[\"os:suse\", \"package:agent\", \"agent:6\"]}
          ]}" \
      "https://api.datadoghq.com/api/v1/series?api_key=$DD_API_KEY"

send_pkg_size-a7:
  stage: pkg_metrics
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  allow_failure: true
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  before_script:
    # tmp while we uppdate the base image
    - apt-get install -y wget rpm2cpio cpio
    - ls -l $OMNIBUS_PACKAGE_DIR
    - ls -l $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  script:
    - source /root/.bashrc && conda activate ddpy3
    - mkdir -p /tmp/deb/agent /tmp/deb/dogstatsd /tmp/deb/puppy
    - mkdir -p /tmp/rpm/agent /tmp/rpm/dogstatsd
    - mkdir -p /tmp/suse/agent /tmp/suse/dogstatsd

    # we silence dpkg and cpio output so we don't exceed gitlab log limit

    # debian
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-agent_7*_amd64.deb /tmp/deb/agent > /dev/null
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-puppy_7*_amd64.deb /tmp/deb/puppy > /dev/null
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-dogstatsd_7*_amd64.deb /tmp/deb/dogstatsd > /dev/null
    - DEB_AGENT_SIZE=$(du -sB1 /tmp/deb/agent | sed 's/\([0-9]\+\).\+/\1/')
    - DEB_DOGSTATSD_SIZE=$(du -sB1 /tmp/deb/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')
    - DEB_PUPPY_SIZE=$(du -sB1 /tmp/deb/puppy | sed 's/\([0-9]\+\).\+/\1/')
    # centos
    - cd /tmp/rpm/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/rpm/dogstatsd && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-dogstatsd-7.*.x86_64.rpm | cpio -idm > /dev/null
    - RPM_AGENT_SIZE=$(du -sB1 /tmp/rpm/agent | sed 's/\([0-9]\+\).\+/\1/')
    - RPM_DOGSTATSD_SIZE=$(du -sB1 /tmp/rpm/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')
    # suse
    - cd /tmp/suse/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/suse/dogstatsd && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-dogstatsd-7.*.x86_64.rpm | cpio -idm > /dev/null
    - SUSE_AGENT_SIZE=$(du -sB1 /tmp/suse/agent | sed 's/\([0-9]\+\).\+/\1/')
    - SUSE_DOGSTATSD_SIZE=$(du -sB1 /tmp/suse/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')

    - currenttime=$(date +%s)
    - DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key --with-decryption --query "Parameter.Value" --out text)
    - |
      curl --fail -X POST -H "Content-type: application/json" \
      -d "{\"series\":[
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_AGENT_SIZE]], \"tags\":[\"os:debian\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_DOGSTATSD_SIZE]], \"tags\":[\"os:debian\", \"package:dogstatsd\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_PUPPY_SIZE]], \"tags\":[\"os:debian\", \"package:puppy\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_AGENT_SIZE]], \"tags\":[\"os:centos\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_DOGSTATSD_SIZE]], \"tags\":[\"os:centos\", \"package:dogstatsd\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_AGENT_SIZE]], \"tags\":[\"os:suse\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_DOGSTATSD_SIZE]], \"tags\":[\"os:suse\", \"package:dogstatsd\", \"agent:7\"]}
          ]}" \
      "https://api.datadoghq.com/api/v1/series?api_key=$DD_API_KEY"


.kitchen_cleanup_s3_common: &kitchen_cleanup_s3_common
  script:
    - aws s3 rm s3://$DEB_TESTING_S3_BUCKET/dists/pipeline-$DD_PIPELINE_ID --recursive
    - aws s3 rm s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID --recursive
    - aws s3 rm s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID --recursive
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - aws s3 rm s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET --recursive
    - cd $OMNIBUS_PACKAGE_DIR
    - for deb in $(ls *amd64.deb); do aws s3 rm s3://$DEB_TESTING_S3_BUCKET/pool/d/da/$deb --recursive; done

# kitchen tests cleanup
testkitchen_cleanup_s3-a6:
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  variables:
    AGENT_MAJOR_VERSION: 6
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  before_script:
    - ls
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always
  <<: *kitchen_cleanup_s3_common

testkitchen_cleanup_s3-a7:
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  <<: *run_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  variables:
    AGENT_MAJOR_VERSION: 7
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  before_script:
    - ls
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always
  <<: *kitchen_cleanup_s3_common

# run dd-agent-testing
testkitchen_cleanup_azure-a6:
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/dd-agent-testing:$DATADOG_AGENT_BUILDERS
  <<: *run_when_testkitchen_triggered
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
  script:
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/clean.sh

testkitchen_cleanup_azure-a7:
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/dd-agent-testing:$DATADOG_AGENT_BUILDERS
  <<: *run_when_testkitchen_triggered
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
  script:
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/clean.sh

#
# image_build
#

.docker_build_job_definition: &docker_build_job_definition
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  dependencies: [] # Don't download Gitlab artifacts
  script:
    - aws s3 sync --only-show-errors $S3_ARTIFACTS_URI $BUILD_CONTEXT
    - TAG_SUFFIX=${TAG_SUFFIX:-}
    - BUILD_ARG=${BUILD_ARG:-}
    - TARGET_TAG=$IMAGE:v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}$TAG_SUFFIX-$ARCH
    # Pull base image(s) with content trust enabled
    - pip install -r requirements.txt
    - inv -e docker.pull-base-images --signed-pull $BUILD_CONTEXT/$ARCH/Dockerfile
    # Build testing stage if provided
    - test "$TESTING_ARG" && docker build --file $BUILD_CONTEXT/$ARCH/Dockerfile $TESTING_ARG $BUILD_CONTEXT
    # Build release stage and push to ECR
    - docker build $BUILD_ARG --file $BUILD_CONTEXT/$ARCH/Dockerfile --pull --tag $TARGET_TAG $BUILD_CONTEXT
    - docker push $TARGET_TAG

.docker_build_job_definition_amd64: &docker_build_job_definition_amd64
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker:v1907756-26d65dc-18.09.6
  tags: ["runner:docker", "size:large"]
  variables:
    ARCH: amd64

.docker_build_job_definition_arm64: &docker_build_job_definition_arm64
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker:v1903032-53399bc-18.09.6-arm64
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64

# build agent6 py2 image
build_agent6:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a6"]
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

build_agent6_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs: ["fail_on_non_triggered_tag", "agent_deb-arm-a6"]
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb

# build agent6 py2 jmx image
build_agent6_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a6"]
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    BUILD_ARTIFACT_GLOB: datadog-agent_6*_amd64.deb
    TAG_SUFFIX: -6-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

# build agent6 py2 jmx image
build_agent6_jmx_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs: ["fail_on_non_triggered_tag", "agent_deb-arm-a6"]
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    BUILD_ARTIFACT_GLOB: datadog-agent_6*arm64.deb
    TAG_SUFFIX: -6-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb

# TESTING ONLY: This image is for internal testing purposes, not customer facing.
# build agent6 jmx unified image (including python3)
build_agent6_py2py3_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a6"]
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6-py2py3-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

# build agent7 image
build_agent7:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a7"]
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb

build_agent7_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs: ["fail_on_non_triggered_tag", "agent_deb-arm-a7"]
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb

# build agent7 jmx image
build_agent7_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "agent_deb-x64-a7"]
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb

build_agent7_jmx_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs: ["fail_on_non_triggered_tag", "agent_deb-arm-a7"]
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb

# build agent7_windows image
build_agent7_windows:
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  needs: ["fail_on_non_triggered_tag", "windows_msi_x64-a7"]
  <<: *skip_when_unwanted_on_7
  tags: ["runner:windows-docker", "windowsversion:1809"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --build-arg BASE_IMAGE=mcr.microsoft.com/windows/servercore:1809 --build-arg WITH_JMX=true
  script:
    - $ErrorActionPreference = "Stop"
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $TARGET_TAG = "${IMAGE}:v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}${TAG_SUFFIX}-win1809-amd64"
    - cp ${OMNIBUS_PACKAGE_DIR}/datadog-agent-7*-x86_64.zip ${BUILD_CONTEXT}/datadog-agent-7-latest.amd64.zip
    - powershell -Command "docker build ${BUILD_ARG} --pull --file ${BUILD_CONTEXT}/windows/amd64/Dockerfile --tag ${TARGET_TAG} ${BUILD_CONTEXT}"
    - docker push ${TARGET_TAG}

# build the cluster-agent image
build_cluster_agent_amd64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "cluster_agent-build_amd64"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
    BUILD_CONTEXT: Dockerfiles/cluster-agent

build_cluster_agent_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs: ["fail_on_non_triggered_tag", "cluster_agent-build_arm64"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
    BUILD_CONTEXT: Dockerfiles/cluster-agent

# build the dogstatsd image
build_dogstatsd_amd64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs: ["fail_on_non_triggered_tag", "build_dogstatsd_static-deb_x64"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    BUILD_CONTEXT: Dockerfiles/dogstatsd/alpine

#
# Docker dev image deployments
#

twistlock_scan-6:
  <<: *skip_when_unwanted_on_6
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/twistlock-cli:2.5.121
  dependencies: [] # Don't download Gitlab artefacts
  allow_failure: true # Don't block the pipeline
  variables:
    SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - export DOCKER_CLIENT_ADDRESS=$DOCKER_HOST
    - TWISTLOCK_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.twistlock_password --with-decryption --query "Parameter.Value" --out text)
    - scan () { echo -e "\n==== Scanning $1 ====\n"; docker pull $1 > /dev/null; /twistcli images scan --address="$TWISTLOCK_URL" --user="$TWISTLOCK_USER" --password="$TWISTLOCK_PASS" --vulnerability-threshold=$THRESHOLD --details $1; }
  script:
    - scan ${SRC_AGENT}:${SRC_TAG}-6-amd64
    - scan ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64
    - scan ${SRC_DSD}:${SRC_TAG}-amd64
    - scan ${SRC_DCA}:${SRC_TAG}-amd64

twistlock_scan-7:
  <<: *skip_when_unwanted_on_7
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/twistlock-cli:2.5.121
  dependencies: [] # Don't download Gitlab artefacts
  allow_failure: true # Don't block the pipeline
  variables:
    SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - export DOCKER_CLIENT_ADDRESS=$DOCKER_HOST
    - TWISTLOCK_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.twistlock_password --with-decryption --query "Parameter.Value" --out text)
    - scan () { echo -e "\n==== Scanning $1 ====\n"; docker pull $1 > /dev/null; /twistcli images scan --address="$TWISTLOCK_URL" --user="$TWISTLOCK_USER" --password="$TWISTLOCK_PASS" --vulnerability-threshold=$THRESHOLD --details $1; }
  script:
    - scan ${SRC_AGENT}:${SRC_TAG}-7-amd64
    - scan ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64

.docker_hub_variables: &docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: docker_hub_login
  DOCKER_REGISTRY_PWD_SSM_KEY: docker_hub_pwd
  DELEGATION_KEY_SSM_KEY: docker_hub_signing_key
  DELEGATION_PASS_SSM_KEY: docker_hub_signing_pass
  DOCKER_REGISTRY_URL: docker.io
  SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
  SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
  SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent

.docker_tag_job_definition: &docker_tag_job_definition
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker-notary:v1912023-8c8dc1c-0.6.1
  variables:
    <<: *docker_hub_variables
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text | docker login --username "$DOCKER_REGISTRY_LOGIN" --password-stdin "$DOCKER_REGISTRY_URL"
    - pip install -r requirements.txt
    - if [[ -z "$DELEGATION_PASS_SSM_KEY" ]]; then echo "No signing key set"; exit 0; fi
    - echo "Importing delegation signing key"
    - export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_PASS_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - export NOTARY_AUTH=$(echo "$DOCKER_REGISTRY_LOGIN:$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text)" | base64)
    - export NOTARY_DELEGATION_PASSPHRASE="$DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE"
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_KEY_SSM_KEY --with-decryption --query "Parameter.Value" --out text > /tmp/docker.key
    - notary -d ~/.docker/trust key import /tmp/docker.key; rm /tmp/docker.key
  dependencies: [] # Don't download Gitlab artefacts

.quay_variables: &quay_variables
  <<: *docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: quay_login
  DOCKER_REGISTRY_PWD_SSM_KEY: quay_pwd
  DOCKER_REGISTRY_URL: quay.io

dev_branch_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
  - fail_on_non_triggered_tag
  - build_agent6
  - build_agent6_jmx
  - build_agent6_py2py3_jmx
  when: manual
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-py2py3-jmx-amd64  datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2py3-jmx

dev_branch_docker_hub-dogstatsd:
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_dogstatsd_amd64
  when: manual
  script:
  - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64                 datadog/dogstatsd-dev:${CI_COMMIT_REF_SLUG}

dev_branch_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_agent7
    - build_agent7_jmx
    - build_agent7_windows
  when: manual
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1809-amd64     datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-1809

dev_branch_multiarch_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_agent6
    - build_agent6_arm64
    - build_agent6_jmx
    - build_agent6_jmx_arm64
    - build_agent6_py2py3_jmx
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-jmx
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2-jmx
    # Other images
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-py2py3-jmx-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2py3-jmx
    # Manifests
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}           --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py2       --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-jmx       --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-jmx
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py2-jmx   --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2-jmx

dev_branch_multiarch_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_agent7
    - build_agent7_arm64
    - build_agent7_jmx
    - build_agent7_jmx_arm64
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3-jmx
    # Other images
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1809-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-1809
    # Manifests
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3       --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3-jmx   --template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3-jmx
    - inv -e docker.publish-manifest --signed-push --platform windows/amd64 --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3   --template datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-1809

dev_branch_multiarch_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_dogstatsd_amd64
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd-dev:${CI_COMMIT_REF_SLUG}

dev_master_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_agent6
    - build_agent6_jmx
    - build_agent6_py2py3_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-py2-jmx

dev_master_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_agent7
    - build_agent7_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64       datadog/agent-dev:master-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64   datadog/agent-dev:master-py3-jmx

dev_master_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - fail_on_non_triggered_tag
    - build_dogstatsd_amd64
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64           datadog/dogstatsd-dev:master

dca_dev_branch_docker_hub:
  <<: *docker_tag_job_definition
  needs: ["fail_on_non_triggered_tag", "build_cluster_agent_amd64"]
  when: manual
  except:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DCA}:${SRC_TAG}-amd64 datadog/cluster-agent-dev:${CI_COMMIT_REF_SLUG}

dca_dev_branch_multiarch_docker_hub:
  <<: *docker_tag_job_definition
  needs: ["fail_on_non_triggered_tag", "build_cluster_agent_amd64", "build_cluster_agent_arm64"]
  when: manual
  except:
    - master
  script:
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_DCA}:${SRC_TAG}-ARCH --dst-template datadog/cluster-agent-dev-ARCH:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/cluster-agent-dev --tag ${CI_COMMIT_REF_SLUG} --template datadog/cluster-agent-dev-ARCH:${CI_COMMIT_REF_SLUG}

dca_dev_master_docker_hub:
  <<: *docker_tag_job_definition
  needs: ["fail_on_non_triggered_tag", "build_cluster_agent_amd64"]
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DCA}:${SRC_TAG}-amd64 datadog/cluster-agent-dev:master

# deploys nightlies to agent-dev
dev_nightly_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_nightly
  needs:
    - fail_on_non_triggered_tag
    - build_agent6
    - build_agent6_jmx
    - build_agent6_py2py3_jmx
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py2-jmx

# deploys nightlies to agent-dev
dev_nightly_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_nightly
  needs:
    - fail_on_non_triggered_tag
    - build_agent7
    - build_agent7_jmx
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-jmx

# deploys nightlies to agent-dev
dev_nightly_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_nightly
  needs:
    - fail_on_non_triggered_tag
    - build_dogstatsd_amd64
  script:
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64           datadog/dogstatsd-dev:nightly-${CI_COMMIT_SHORT_SHA}
#
# Check Deploy
#

# Check that the current version hasn't already been deployed (we don't want to
# overwrite a public package). To update an erroneous package, first remove it
# from our S3 bucket.
check_already_deployed_version_6:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_6*_amd64.deb
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_6*_arm64.deb

check_already_deployed_version_7:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_7*_amd64.deb
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_7*_arm64.deb

# If we trigger a build only pipeline we stop here.
check_if_build_only:
  <<: *run_when_triggered
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - if [ "$DEB_RPM_BUCKET_BRANCH" == "none" ]; then echo "Stopping pipeline"; exit 1; fi

#
# deploy
#

# deploy debian packages to apt staging repo
deploy_deb-6:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    # We first check that the current version hasn't already been deployed
    # (same as the check_already_deployed_version). We do this twice to mitigate
    # races and issues with retries while failing early if there is an issue.
    - pushd $OMNIBUS_PACKAGE_DIR
    - /deploy_scripts/fail_deb_is_pkg_already_exists.sh *_6.*amd64.deb
    - popd
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    # Release the artifacts to the "6" component
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a arm64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*arm64.deb

deploy_deb-7:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    # We first check that the current version hasn't already been deployed
    # (same as the check_already_deployed_version). We do this twice to mitigate
    # races and issues with retries while failing early if there is an issue.
    - pushd $OMNIBUS_PACKAGE_DIR
    - /deploy_scripts/fail_deb_is_pkg_already_exists.sh *_7.*amd64.deb
    - popd
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    # Release the artifacts to the "7" component
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a arm64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*arm64.deb

# nightlies (6), deployed to bucket/master
deploy_windows_master-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies (7 and dogstatsd), deployed to bucket/master
deploy_windows_master-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-dogstatsd-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies latest (6), deployed to bucket/master
deploy_windows_master-latest-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-6*-x86_64.msi "s3://$WINDOWS_BUILDS_S3_BUCKET/master/datadog-agent-6-latest.amd64.msi" --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies latest (7), deployed to bucket/master
deploy_windows_master-latest-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-7*-x86_64.msi "s3://$WINDOWS_BUILDS_S3_BUCKET/master/datadog-agent-7-latest.amd64.msi" --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds (6), deployed to bucket/tagged
deploy_windows_tags-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_tag_6
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds (7), deployed to bucket/tagged
deploy_windows_tags-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_tag_7
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds latest (6, x64 only), deployed to bucket/tagged
deploy_windows_tags-latest-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_tag_6
  tags: [ "runner:main", "size:large" ]
  script:
    # By default we update the "latest" artifacts on our s3 bucket so the
    # staging box can pick it up. Allow the job to skip this step if needed
    # (when building a custom beta for example).
    - if [ "WINDOWS_DO_NOT_UPDATE_LATEST" != "true" ]; then $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-6*-x86_64.msi s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/datadog-agent-6-latest.amd64.msi --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732; fi

# triggered builds latest (7, x64 only), deployed to bucket/tagged
deploy_windows_tags-latest-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_tag_7
  tags: [ "runner:main", "size:large" ]
  script:
    # By default we update the "latest" artifacts on our s3 bucket so the
    # staging box can pick it up. Allow the job to skip this step if needed
    # (when building a custom beta for example).
    - if [ "WINDOWS_DO_NOT_UPDATE_LATEST" != "true" ]; then $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-7*-x86_64.msi s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/datadog-agent-7-latest.amd64.msi --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732; fi

# deploy android packages to a public s3 bucket when tagged
deploy_android_tags:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_when_triggered_on_tag_7
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "*.apk" $OMNIBUS_PACKAGE_DIR s3://$ANDROID_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy rpm packages to yum staging repo
deploy_rpm-6:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/6/x86_64/
    - mkdir -p ./rpmrepo/6/aarch64/
    - aws s3 sync --only-show-errors s3://$RPM_S3_BUCKET/$DEB_RPM_BUCKET_BRANCH/6/ ./rpmrepo/6/

    # add RPMs to new "6" branch
    - cp $OMNIBUS_PACKAGE_DIR/*-6.*x86_64.rpm ./rpmrepo/6/x86_64/
    - cp $OMNIBUS_PACKAGE_DIR/*-6.*aarch64.rpm ./rpmrepo/6/aarch64/
    - createrepo --update -v --checksum sha ./rpmrepo/6/x86_64
    - createrepo --update -v --checksum sha ./rpmrepo/6/aarch64

    # sync to S3
    - aws s3 sync --only-show-errors ./rpmrepo/6/ s3://$RPM_S3_BUCKET/$DEB_RPM_BUCKET_BRANCH/6/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_rpm-7:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/7/x86_64/
    - mkdir -p ./rpmrepo/7/aarch64/
    - aws s3 sync --only-show-errors s3://$RPM_S3_BUCKET/$DEB_RPM_BUCKET_BRANCH/7/ ./rpmrepo/7/

    # add RPMs to new "7" branch
    - cp $OMNIBUS_PACKAGE_DIR/*-7.*x86_64.rpm ./rpmrepo/7/x86_64/
    - cp $OMNIBUS_PACKAGE_DIR/*-7.*aarch64.rpm ./rpmrepo/7/aarch64/
    - createrepo --update -v --checksum sha ./rpmrepo/7/x86_64
    - createrepo --update -v --checksum sha ./rpmrepo/7/aarch64

    # sync to S3
    - aws s3 sync --only-show-errors ./rpmrepo/7/ s3://$RPM_S3_BUCKET/$DEB_RPM_BUCKET_BRANCH/7/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy suse rpm packages to yum staging repo
# NOTE: no SuSE ARM builds currently.
deploy_suse_rpm-6:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/6/x86_64/
    - aws s3 sync --only-show-errors s3://$RPM_S3_BUCKET/suse/$DEB_RPM_BUCKET_BRANCH/6/ ./rpmrepo/6/

    # add RPMs to new "6" branch
    - cp $OMNIBUS_PACKAGE_DIR_SUSE/*-6.*x86_64.rpm ./rpmrepo/6/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/6/x86_64

    # sync to S3
    - aws s3 sync --only-show-errors ./rpmrepo/6/ s3://$RPM_S3_BUCKET/suse/$DEB_RPM_BUCKET_BRANCH/6/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_suse_rpm-7:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - mkdir -p ./rpmrepo/7/x86_64/
    - aws s3 sync --only-show-errors s3://$RPM_S3_BUCKET/suse/$DEB_RPM_BUCKET_BRANCH/7/ ./rpmrepo/7/

    # add RPMs to new "7" branch
    - cp $OMNIBUS_PACKAGE_DIR_SUSE/*-7.*x86_64.rpm ./rpmrepo/7/x86_64/
    - createrepo --update -v --checksum sha ./rpmrepo/7/x86_64

    # sync to S3
    - aws s3 sync --only-show-errors ./rpmrepo/7/ s3://$RPM_S3_BUCKET/suse/$DEB_RPM_BUCKET_BRANCH/7/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy dsd binary to staging bucket
deploy_dsd:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD $S3_ARTIFACTS_URI/dogstatsd/dogstatsd ./dogstatsd
    - export PACKAGE_VERSION=$(inv agent.version --url-safe --major-version 7)
    - aws s3 cp --region us-east-1 ./dogstatsd $S3_DSD6_URI/linux/dogstatsd-$PACKAGE_VERSION --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy puppy binary to staging bucket
deploy_puppy:
  <<: *run_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD $S3_ARTIFACTS_URI/puppy/agent ./agent
    - export PACKAGE_VERSION=$(inv agent.version --url-safe --major-version 7)
    - aws s3 cp --region us-east-1 ./agent $S3_DSD6_URI/linux/puppy/agent-$PACKAGE_VERSION --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy agent windows zip to the staging bucket, currently used for cloudfoundry bosh
deploy_datadog_agent_windows_zip:
  <<: *run_when_triggered_on_tag_7
  stage: deploy7
  needs: [ "windows_msi_x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7.*.zip" $OMNIBUS_PACKAGE_DIR $S3_DSD6_URI/windows/agent7/bosh/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy datadog agent windows binaries to staging bucket. Currently used for cloudfoundry builpack
deploy_datadog_agent_windows_binaries_zip:
  <<: *run_when_triggered_on_tag_7
  stage: deploy7
  needs: [ "windows_zip_agent_binaries_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "agent-binaries-7.*.zip" $OMNIBUS_PACKAGE_DIR $S3_DSD6_URI/windows/agent7/buildpack/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy process agent and system-probe to staging bucket
deploy_process_and_sysprobe:
  stage: internal_deploy
  when: manual
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - cd $OMNIBUS_PACKAGE_DIR
    - ls
  tags: [ "runner:main", "size:large" ]
  script:
    # The shell expansion `datadog-agent_*_amd64.deb` might return multiple
    # entries, so we sort them and get the first one.
    - dpkg -x $(ls -1 datadog-agent_*_amd64.deb | sort -V | head -n 1) ./out
    # Use tag or shortened branch with short commit hash to identify the binary
    - export SHORT_REF=$(echo $CI_COMMIT_REF_NAME | cut -d'/' -f2- | cut -c -10 | sed -E 's/[^[:alnum:]]+/-/g')
    - export NAME="${CI_COMMIT_TAG:-$SHORT_REF}-${CI_COMMIT_SHA:0:7}"
    - echo "Uploading with name=$NAME"
    - $S3_CP_CMD ./out/opt/datadog-agent/embedded/bin/process-agent s3://$PROCESS_S3_BUCKET/process-agent-amd64-$NAME --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=612548d92af7fa77f7ad7bcab230494f7310438ac6332e904a8fb2e6daa5cb23
    - $S3_CP_CMD ./out/opt/datadog-agent/embedded/bin/system-probe s3://$PROCESS_S3_BUCKET/system-probe-amd64-$NAME --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=612548d92af7fa77f7ad7bcab230494f7310438ac6332e904a8fb2e6daa5cb23

#
# Docker releases
#

tag_release_6:
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_tag_6
  stage: deploy6
  when: manual
  script:
    - VERSION=$(inv -e agent.version --major-version 6)
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-ARCH:${VERSION}-jmx
    # Manifests
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag ${VERSION}      --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag ${VERSION}-jmx  --template datadog/agent-ARCH:${VERSION}-jmx

tag_release_7:
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_tag_7
  stage: deploy7
  when: manual
  script:
    - VERSION=$(inv -e agent.version --major-version 7)
    # Images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-ARCH      --dst-template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-ARCH  --dst-template datadog/agent-ARCH:${VERSION}-jmx
    # Other
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:${VERSION}
    # Manifests
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag ${VERSION}      --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag ${VERSION}-jmx  --template datadog/agent-ARCH:${VERSION}-jmx

latest_release_6:
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_tag_6
  stage: deploy6
  when: manual
  script:
    - VERSION=$(inv -e agent.version --major-version 6)
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-py2        --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-py2-jmx    --template datadog/agent-ARCH:${VERSION}-jmx
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag 6                 --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag 6-jmx             --template datadog/agent-ARCH:${VERSION}-jmx

latest_release_7:
  <<: *docker_tag_job_definition
  <<: *run_when_triggered_on_tag_7
  stage: deploy7
  when: manual
  script:
    - VERSION=$(inv -e agent.version --major-version 7)
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest      --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-jmx  --template datadog/agent-ARCH:${VERSION}-jmx
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag 7           --template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag 7-jmx       --template datadog/agent-ARCH:${VERSION}-jmx
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:latest
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:7

#
# Use these steps to revert the latest tags to a previous release
# while maintaining content trust signatures
# - remove the leading dot from the name
# - set the RELEASE envvar
# - in the gitlab pipeline view, trigger the step (in the first column)
#

.latest_revert_to_previous_release_6:
  <<: *docker_tag_job_definition
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    RELEASE: ""  # tag name of the non-jmx version, for example "6.9.0"
  script:
    - if [[ -z "$RELEASE" ]]; then echo "Need release version to revert to"; exit 1; fi
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-py2      --template datadog/agent-ARCH:${RELEASE}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-py2-jmx  --template datadog/agent-ARCH:${RELEASE}-jmx

.latest_revert_to_previous_release_7:
  <<: *docker_tag_job_definition
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    RELEASE: ""  # tag name of the non-jmx version, for example "6.9.0"
  script:
    - if [[ -z "$RELEASE" ]]; then echo "Need release version to revert to"; exit 1; fi
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest      --template datadog/agent-ARCH:${RELEASE}
    - inv -e docker.publish-manifest --signed-push --platform linux/amd64 --platform linux/arm64 --name datadog/agent --tag latest-jmx  --template datadog/agent-ARCH:${RELEASE}-jmx
    - inv -e docker.publish --signed-pull --signed-push datadog/dogstatsd:${RELEASE} datadog/dogstatsd:latest

#
# Use this step to delete a tag of a given image
# We call the Docker Hub API because docker cli doesn't support deleting tags
# - remove the leading dot from the name
# - set the IMAGE and TAG envvars
# - in the gitlab pipeline view, trigger the step (in the first column)
#
.delete_docker_tag:
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker-notary:0.6.1
  before_script:
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - pip install -r requirements.txt
    - |
      export DOCKER_TOKEN=`curl -s -H "Content-Type: application/json" -X POST -d '{"username": "'$DOCKER_REGISTRY_LOGIN'", "password": "'$PASS'"}' https://hub.docker.com/v2/users/login/ | python -c 'import sys, json; print(json.load(sys.stdin)["token"].strip())'`
  dependencies: [] # Don't download Gitlab artefacts
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    IMAGE: ""  # image name, for example "agent"
    TAG: ""  # tag name, for example "6.9.0"
    ORGANIZATION: "datadog"
  script:
    - if [[ -z "$IMAGE" ]]; then echo "Need an image"; exit 1; fi
    - if [[ -z "$TAG" ]]; then echo "Need a tag to delete"; exit 1; fi
    - inv -e docker.delete ${ORGANIZATION} ${IMAGE} ${TAG} ${DOCKER_TOKEN} &>/dev/null

#
# Cloudfront cache invalidation:
# Duplicated in 2 jobs: one that runs "on success" of the previous stage, and one that runs "on failure" of previous stages.
# Compared to having 1 single job that runs "always", this setup guarantees that if earlier stages first failed and were
# then retried successfully, the cloudfront invalidation will also run after the successful retry.
#
.deploy_cloudfront_invalidate: &deploy_cloudfront_invalidate
  <<: *run_when_triggered
  stage: deploy_invalidate
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - cd /deploy_scripts/cloudfront-invalidation
    - "REPO=apt PATTERN_SUBSTRING=/$DEB_RPM_BUCKET_BRANCH/ ./invalidate.sh"
    - "REPO=yum PATTERN_SUBSTRING=/$DEB_RPM_BUCKET_BRANCH/ ./invalidate.sh"

deploy_cloudfront_invalidate_on_success:
  <<: *deploy_cloudfront_invalidate
  when: on_success

deploy_cloudfront_invalidate_on_failure:
  <<: *deploy_cloudfront_invalidate
  when: on_failure

#
# end to end
#

.pupernetes_template: &pupernetes_template
  stage: e2e
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  before_script:
  - cd $SRC_PATH
  - pip install --upgrade --ignore-installed pip setuptools
  - pip install -r requirements.txt # Override top level entry
  script:
  - inv -e e2e-tests --image=datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2
  - inv -e e2e-tests --image=datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3

pupernetes-dev:
  <<: *pupernetes_template
  when: manual
  except:
    - master
    - tags

pupernetes-master:
  <<: *pupernetes_template
  only:
    - master
  script:
  - inv -e e2e-tests --image=datadog/agent-dev:master-py2
  - inv -e e2e-tests --image=datadog/agent-dev:master-py3

pupernetes-tags-6:
  <<: *pupernetes_template
  <<: *run_when_triggered_on_tag_6
  when: manual
  script:
  - VERSION=$(inv -e agent.version --major-version 6)
  - inv -e e2e-tests --image=datadog/agent:${VERSION}

pupernetes-tags-7:
  <<: *pupernetes_template
  <<: *run_when_triggered_on_tag_7
  when: manual
  script:
  - VERSION=$(inv -e agent.version --major-version 7)
  - inv -e e2e-tests --image=datadog/agent:${VERSION}

notify-on-failure:
  extends: .slack-notifier.on-failure
  before_script: ["# noop"]
  only:
    - master
    - triggers
  script: |
    BUILD_URL="$CI_PROJECT_URL/pipelines/$CI_PIPELINE_ID"
    COMMIT_URL="$CI_PROJECT_URL/commit/$CI_COMMIT_SHA"

    COMMIT_AUTHOR=$(git show -s --format="%an" HEAD)

    MESSAGE_TEXT=":host-red: $CI_PROJECT_NAME: Pipeline <$BUILD_URL|$CI_PIPELINE_ID> for $CI_COMMIT_REF_NAME failed.
    $CI_COMMIT_TITLE (<$COMMIT_URL|$CI_COMMIT_SHORT_SHA>) by $COMMIT_AUTHOR"
    postmessage "#datadog-agent-pipelines" "$MESSAGE_TEXT"
