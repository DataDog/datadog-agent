include: 'https://gitlab-templates.ddbuild.io/slack-notifier/v1/template.yml'

default:
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
      - unknown_failure
      - api_failure

stages:
  - fail_on_tag
  - deps_build
  - source_test
  - binary_build
  - integration_test
  - package_build
  - internal_deploy
  - check_deploy
  - testkitchen_deploy
  - testkitchen_testing
  - pkg_metrics
  - image_build
  - image_deploy
  - deploy6
  - deploy7
  - deploy7-manifests
  - deploy_invalidate
  - trigger_release
  - e2e
  - testkitchen_cleanup
  - notify

variables:
  # The SRC_PATH is in the GOPATH of the builders which
  # currently is /go
  SRC_PATH: /go/src/github.com/DataDog/datadog-agent
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /.omnibus
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR: $CI_PROJECT_DIR/.omnibus/pkg/
  # Directory in which we execute the omnibus build for SUSE
  # as we want to separate the RPM built for this distro.
  OMNIBUS_BASE_DIR_SUSE: /.omnibus/suse
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR_SUSE: $CI_PROJECT_DIR/.omnibus/suse/pkg
  OMNIBUS_BASE_DIR_WIN: c:\omni-base\$CI_RUNNER_ID
  OMNIBUS_BASE_DIR_WIN_OMNIBUS: c:/omni-base/$CI_RUNNER_ID
  DD_AGENT_TESTING_DIR: $CI_PROJECT_DIR/test/kitchen
  STATIC_BINARIES_DIR: bin/static
  DOGSTATSD_BINARIES_DIR: bin/dogstatsd
  AGENT_BINARIES_DIR: bin/agent
  CLUSTER_AGENT_BINARIES_DIR: bin/datadog-cluster-agent
  CLUSTER_AGENT_CLOUDFOUNDRY_BINARIES_DIR: bin/datadog-cluster-agent-cloudfoundry
  SYSTEM_PROBE_BINARIES_DIR: bin/system-probe
  DEB_S3_BUCKET: apt.datad0g.com
  RPM_S3_BUCKET: yum.datad0g.com
  WIN_S3_BUCKET: dd-agent-mstesting
  PROCESS_S3_BUCKET: datad0g-process-agent
  ANDROID_S3_BUCKET: dd-agent-androidtesting
  DEB_RPM_BUCKET_BRANCH: nightly  # branch of the DEB_S3_BUCKET and RPM_S3_BUCKET repos to release to, 'nightly' or 'beta'
  DEB_TESTING_S3_BUCKET: apttesting.datad0g.com
  RPM_TESTING_S3_BUCKET: yumtesting.datad0g.com
  WINDOWS_TESTING_S3_BUCKET_A6: pipelines/A6/$CI_PIPELINE_ID
  WINDOWS_TESTING_S3_BUCKET_A7: pipelines/A7/$CI_PIPELINE_ID
  WINDOWS_BUILDS_S3_BUCKET: $WIN_S3_BUCKET/builds
  ANDROID_BUILDS_S3_BUCKET: $ANDROID_S3_BUCKET/builds
  DEB_RPM_TESTING_BUCKET_BRANCH: testing  # branch of the DEB_TESTING_S3_BUCKET and RPM_TESTING_S3_BUCKET repos to release to, 'testing'
  DD_REPO_BRANCH_NAME: $CI_COMMIT_REF_NAME
  S3_CP_OPTIONS: --only-show-errors --region us-east-1 --sse AES256
  S3_CP_CMD: aws s3 cp $S3_CP_OPTIONS
  S3_ARTIFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME/$CI_PIPELINE_ID
## comment out both lines below (S3_OMNIBUS_CACHE_BUCKET and USE_S3_CACHING) to allow
## build to succeed with S3 caching disabled.
  S3_OMNIBUS_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-cache-build-stable
  USE_S3_CACHING: --omnibus-s3-cache
  S3_DSD6_URI: s3://dsd6-staging
  RELEASE_VERSION_6: nightly
  RELEASE_VERSION_7: nightly-a7
  DATADOG_AGENT_BUILDIMAGES: v2424505-0439a40
  DATADOG_AGENT_BUILDERS: v2448672-5304c3c
  DATADOG_AGENT_WINBUILDIMAGES: v2468030-cbaf3fe
  DATADOG_AGENT_WINBUILDERS: v2348149-ba6640d
  DATADOG_AGENT_ARMBUILDIMAGES: v2424505-0439a40
  DATADOG_AGENT_SYSPROBE_BUILDIMAGES: v2424505-0439a40
  BCC_VERSION: v0.12.0
  SYSTEM_PROBE_GO_VERSION: 1.13.8

#
# Trigger conditions
#

# run job only when triggered by an external tool (ex: Jenkins). This is used
# for jobs that run both on nightlies and tags
.run_only_when_triggered: &run_only_when_triggered
  only:
    - triggers


# anchor to trigger test kitchen setup, run, and cleanup (so all stages
# are run if one stage is run).  Triggers as defined:
# - master
# - tags (a tagged build)
# - triggers (as above, when triggered by an external tool like jenkins)
# - web (when the build is triggered by a specific build request through the
#        web interface.  This way, if a kitchen run is desired on a specific branch,
#        it can be triggered by requesting a specific build)
#
.run_only_when_testkitchen_triggered: &run_only_when_testkitchen_triggered
  only:
    - master
    - tags
    - triggers
    - web

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is NOT "nightly". In this setting we are building either a
# new tagged version of the agent (an RC for example). In both cases the
# artifacts should be uploaded to our staging repository.

.run_only_when_triggered_on_tag_6: &run_only_when_triggered_on_tag_6
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_6 == "" # no  RELEASE_VERSION means a nightly build for omnibus

.run_only_when_triggered_on_tag_7: &run_only_when_triggered_on_tag_7
  only:
    refs:
      - triggers
  except: # we have to use except since gitlab doens't handle '!=' operator
    variables:
      - $RELEASE_VERSION_7 == "nightly-a7"
      - $RELEASE_VERSION_7 == "" # no  RELEASE_VERSION means a nightly build for omnibus

# run job only when triggered by an external tool (ex: Jenkins) and when
# RELEASE_VERSION_X is "nightly". In this setting we build from master and update
# the nightly build for windows, linux and docker.

.run_only_when_triggered_on_nightly: &run_only_when_triggered_on_nightly
  only:
    refs:
      - triggers
    variables:
      - $RELEASE_VERSION_6 == "nightly"
      - $RELEASE_VERSION_7 == "nightly-a7"

# run when not triggered (for jobs we don't want to run on release pipelines)
.skip_when_triggered: &skip_when_triggered
  # TODO (with rules?): exclude triggered pipelines but not nightlies
  except:
    refs:
      - triggers

# Skip job only when RELEASE_VERSION_X is not set
.skip_when_unwanted_on_6: &skip_when_unwanted_on_6
  except:
    variables:
      - $RELEASE_VERSION_6 == ""

.skip_when_unwanted_on_7: &skip_when_unwanted_on_7
  except:
    variables:
      - $RELEASE_VERSION_7 == ""

# Fail if we're running a pipeline on a non-triggered tag build
fail_on_non_triggered_tag:
  stage: fail_on_tag
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  script:
    - echo CI_PIPELINE_SOURCE=$CI_PIPELINE_SOURCE CI_COMMIT_TAG=$CI_COMMIT_TAG
    - '[[ $CI_COMMIT_TAG == dca-* || $CI_COMMIT_TAG == "" || $CI_PIPELINE_SOURCE != "push" ]]'

#
# deps_build
#
#

# build libbcc
.build_libbcc_common:
  stage: deps_build
  needs: ["fail_on_non_triggered_tag"]
  script:
    - git clone -b "$BCC_VERSION" --depth=1 https://github.com/iovisor/bcc.git /tmp/bcc
    - mkdir /tmp/bcc/build
    - cd /tmp/bcc/build
    - cmake .. -DCMAKE_INSTALL_PREFIX=/opt/libbcc -DCMAKE_EXE_LINKER_FLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib' -DCMAKE_SHARED_LINKER_FLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib'
    - make -j 4 #"$(nproc)"
    - make install
    - cd /opt/libbcc
    - chmod go-rwx lib/libbcc*
    - rm share/bcc/introspection/bps
    - cp $(ldd lib/libbcc.so | awk '$1 ~ /^libtinfo/ {system("dirname " $3)}')/libtinfo* lib
    - tar cvaf /tmp/libbcc.tar.xz .
    - $S3_CP_CMD /tmp/libbcc.tar.xz $S3_ARTIFACTS_URI/libbcc-$ARCH.tar.xz

build_libbcc_x64:
  extends: .build_libbcc_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  variables:
    ARCH: amd64

build_libbcc_arm64:
  extends: .build_libbcc_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64


#
# source_test
#
#

# run tests for windows-64
.run_old_tests_windows_base:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  script:
    - docker run --rm -m 8192M -v "$(Get-Location):c:\mnt" -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e NEW_BUILDER="$NEW_BUILDER" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\unittests.bat
  variables:
    NEW_BUILDER: "false"

run_old_tests_windows-x64:
  # temporarily allow failure for tests
  extends: .run_old_tests_windows_base
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x64"

run_old_tests_windows-x86:
  <<: *skip_when_triggered
  # temporarily allow failure for tests
  extends: .run_old_tests_windows_base
  allow_failure: true
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x86"

.run_tests_windows_base:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  script:
    - docker run --rm -m 8192M -v "$(Get-Location):c:\mnt" -e AWS_NETWORKING=true -e SIGN_WINDOWS=true -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e NEW_BUILDER="$NEW_BUILDER" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/windows_1809_${ARCH}:$Env:DATADOG_AGENT_WINBUILDIMAGES c:\mnt\tasks\winbuildscripts\unittests.bat
  variables:
    NEW_BUILDER: "true"

run_tests_windows-x64:
  # temporarily allow failure for tests
  extends: .run_tests_windows_base
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x64"

run_tests_windows-x86:
  <<: *skip_when_triggered
  # temporarily allow failure for tests
  extends: .run_tests_windows_base
  allow_failure: true
  variables:
    PYTHON_RUNTIMES: 3
    ARCH: "x86"

.run_tests_preparation: &run_tests_preparation
  needs: ["fail_on_non_triggered_tag"]
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - pip install wheel
    - pip install -r requirements.txt
    - GO111MODULE=off go get gopkg.in/yaml.v2
    - GO111MODULE=off go get github.com/stretchr/testify
    - inv -e rtloader.make --install-prefix=$SRC_PATH/dev --python-runtimes "$PYTHON_RUNTIMES"
    - inv -e rtloader.install
    - inv -e rtloader.format --raise-if-changed
    - inv -e rtloader.test
    - inv -e deps --verbose --dep-vendor-only

# run tests for deb-x64
run_tests_deb-x64-py2:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '2'
    CONDA_ENV: ddpy2
  <<: *run_tests_preparation
  script:
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4

run_tests_deb-x64-py3:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '3'
    CONDA_ENV: ddpy3
  <<: *run_tests_preparation
  script:
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4

# run tests for rpm-x64
run_tests_rpm-x64-py2:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '2'
    CONDA_ENV: ddpy2
  <<: *run_tests_preparation
  script:
    # Exclude systemd because it cannot succeed on Centos 6: the image doesn't have the shared object required by
    # https://github.com/coreos/go-systemd/blob/c8cc474ba8655dfbdb0ac7fcc09b7faf5b643caf/sdjournal/functions.go#L46
    # This is OK because the test on systemd still runs on the debian image above
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4 --build-exclude=systemd

run_tests_rpm-x64-py3:
  stage: source_test
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    PYTHON_RUNTIMES: '3'
    CONDA_ENV: ddpy3
  <<: *run_tests_preparation
  script:
    # Exclude systemd because it cannot succeed on Centos 6: the image doesn't have the shared object required by
    # https://github.com/coreos/go-systemd/blob/c8cc474ba8655dfbdb0ac7fcc09b7faf5b643caf/sdjournal/functions.go#L46
    # This is OK because the test on systemd still runs on the debian image above
    - inv -e test --race --profile --python-runtimes "$PYTHON_RUNTIMES" --cpus 4 --build-exclude=systemd

# run tests for eBPF code
run_tests_ebpf:
  stage: source_test
  needs: ["build_libbcc_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  before_script:
    - mkdir -p $CI_PROJECT_DIR/.tmp/binary-ebpf
    - cd $SRC_PATH
    - pip3 install -r requirements.txt
    - inv -e deps --verbose --dep-vendor-only --no-checks
    # Retrieve libbcc from S3
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-amd64.tar.xz /tmp/libbcc.tar.xz
    - mkdir /opt/libbcc
    - tar -xvf /tmp/libbcc.tar.xz -C /opt/libbcc
  after_script:
    - cd $SRC_PATH
    - cp ./pkg/ebpf/c/tracer-ebpf.o  $CI_PROJECT_DIR/.tmp/binary-ebpf/tracer-ebpf.o
    - cp ./pkg/ebpf/c/tracer-ebpf-debug.o  $CI_PROJECT_DIR/.tmp/binary-ebpf/tracer-ebpf-debug.o
  tags: [ "runner:main", "size:large" ]
  script:
    # For now only check bpf bytes since we don't have a way to run eBPF tests without mounting a debugfs
    - CGO_CFLAGS='-I/opt/libbcc/include' CGO_LDFLAGS='-Wl,-rpath,/opt/libbcc/lib -L/opt/libbcc/lib' inv -e system-probe.test --only-check-bpf-bytes

  artifacts:
    when: always
    paths:
      - $CI_PROJECT_DIR/.tmp/binary-ebpf

# scan the dependencies for security vulnerabilities with snyk
run_security_scan_test:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/snyk:latest
  tags: ["runner:main", "size:large"]
  only:
    - master
  before_script:
    # this image isn't built in the datadog-agent-builders repo
    # it doesn't have invoke so we install the dependencies without invoke
    - mkdir -p $GOPATH/src/github.com/DataDog/datadog-agent
    - rsync -azr --delete ./ $GOPATH/src/github.com/DataDog/datadog-agent
    - cd $GOPATH/src/github.com/DataDog/datadog-agent
    - pip install -r requirements.txt
    - inv -e deps --dep-vendor-only
  script:
    - set +x     # don't print the api key to the logs
    # send the list of the dependencies to snyk
    - SNYK_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.snyk_token --with-decryption --query "Parameter.Value" --out text)
      snyk monitor --project-name=datadog-agent-requirements.txt --file=requirements.txt --package-manager=pip
    - SNYK_TOKEN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.snyk_token --with-decryption --query "Parameter.Value" --out text)
      snyk monitor --project-name=datadog-agent-go.sum --file=go.mod

# check consistency of go.mod file with project imports
run_go_tidy_check:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  before_script:
    - cd $SRC_PATH
    - pip install --upgrade --ignore-installed pip setuptools
    - pip install -r requirements.txt
    - inv -e deps --no-dep-ensure --no-checks
  script:
    # Print a message and fail if "go mod tidy" modifies go.mod
    - go mod tidy
    - git diff-files --exit-code go.mod || (echo "go.mod is out of sync with project imports. Please run 'inv deps' and commit the changes on go.mod/go.sum." && false)

run_shell_script_lint:
  stage: source_test
  needs: ["fail_on_non_triggered_tag"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/mars_jenkins_scripts:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  script:
    - shellcheck --version
    #Excludes:
    #SC2028: echo may not expand escape sequences. Use printf.
    #SC2059: Don't use variables in the printf format string. Use printf "..%s.." "$foo".
    - shellcheck --severity=info -e SC2059 -e SC2028 --shell=bash ./cmd/**/*.sh ./omnibus/package-scripts/*/*

#
# binary_build
#

# build dogstatsd static for deb-x64
build_dogstatsd_static-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --static --major-version 7
    - $S3_CP_CMD $SRC_PATH/$STATIC_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/static/dogstatsd

# build dogstatsd for deb-x64
build_dogstatsd-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --major-version 7
    - $S3_CP_CMD $SRC_PATH/$DOGSTATSD_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/dogstatsd/dogstatsd

# build dogstatsd static for deb-arm
build_dogstatsd_static-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --static --major-version 7
    - $S3_CP_CMD $SRC_PATH/$STATIC_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/static/dogstatsd.$ARCH

# build dogstatsd linked for deb-arm
build_dogstatsd-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    - inv -e dogstatsd.build --major-version 7
    - $S3_CP_CMD $SRC_PATH/$DOGSTATSD_BINARIES_DIR/dogstatsd $S3_ARTIFACTS_URI/dogstatsd/dogstatsd.$ARCH

# build iot agent for deb-x64, to make sure the build is not broken because of build flags
build_iot_agent-deb_x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["run_tests_deb-x64-py3"]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  script:
    - inv -e agent.build --iot --major-version 7
    - $S3_CP_CMD $SRC_PATH/$AGENT_BINARIES_DIR/agent $S3_ARTIFACTS_URI/iot/agent

# build iot agent for ARM, to make sure the build is not broken because of build targets
build_iot_agent-deb_arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["run_tests_deb-x64-py3"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only --no-checks
  script:
    - inv -e agent.build --iot --major-version 7

.cluster_agent-build_common: &cluster_agent-build_common
  stage: binary_build
  needs: ["run_go_tidy_check"]
  script:
    - inv -e cluster-agent.build
    - $S3_CP_CMD $SRC_PATH/$CLUSTER_AGENT_BINARIES_DIR/datadog-cluster-agent $S3_ARTIFACTS_URI/datadog-cluster-agent.$ARCH
    - $S3_CP_CMD $SRC_PATH/Dockerfiles/cluster-agent/datadog-cluster.yaml $S3_ARTIFACTS_URI/datadog-cluster.yaml

# build cluster-agent bin
cluster_agent-build_amd64:
  <<: *cluster_agent-build_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  variables:
    ARCH: amd64
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only

cluster_agent-build_arm64:
  <<: *cluster_agent-build_common
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_BUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    - cd $SRC_PATH
    - inv -e deps --no-checks --verbose --dep-vendor-only

# build cluster-agent-cloudfoundry bin
cluster_agent_cloudfoundry-build_amd64:
  <<: *skip_when_unwanted_on_7
  stage: binary_build
  needs: ["run_go_tidy_check"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR
  variables:
    ARCH: amd64
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    - inv -e cluster-agent-cloudfoundry.build
    - cd $SRC_PATH/$CLUSTER_AGENT_CLOUDFOUNDRY_BINARIES_DIR
    - mkdir -p $OMNIBUS_PACKAGE_DIR
    - export PACKAGE_VERSION=$(inv agent.version --url-safe --major-version 7)
    - tar cf $OMNIBUS_PACKAGE_DIR/datadog-cluster-agent-cloudfoundry-$PACKAGE_VERSION-$ARCH.tar.xz datadog-cluster-agent-cloudfoundry

#
# integration_test
#

# run benchmarks on deb
# run_benchmarks-deb_x64:
#   stage: integration_test
#   image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
#   allow_failure: true  # FIXME: this was set to true to temporarily unblock the pipeline
#   tags: [ "runner:main", "size:large" ]
#   script:
#     - inv -e bench.aggregator
#     # FIXME: in our docker image, non ascii characters printed by the benchmark
#     # make invoke traceback. For now, the workaround is to call the benchmarks
#     # manually
#     - inv -e bench.build-dogstatsd

#     - set +x # make sure we don't output the creds to the build log
#     - DD_AGENT_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.dd_agent_api_key --with-decryption --query "Parameter.Value" --out text)

#     # dogstatsd validation - not really benchmarking: gitlab isn't the right place to do this.
#     - ./bin/benchmarks/dogstatsd -pps=20000 -dur 30 -ser 5 -branch $DD_REPO_BRANCH_NAME -api-key $DD_AGENT_API_KEY
#   artifacts:
#     expire_in: 2 weeks
#     paths:
#       - benchmarks

# check the size of the static dogstatsd binary
run_dogstatsd_size_test:
  stage: integration_test
  needs: ["build_dogstatsd_static-deb_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    # Disable global before_script
    - mkdir -p $STATIC_BINARIES_DIR
    - $S3_CP_CMD $S3_ARTIFACTS_URI/static/dogstatsd $STATIC_BINARIES_DIR/dogstatsd
  script:
    - inv -e dogstatsd.size-test --skip-build

# check the size of the static dogstatsd binary
run_dogstatsd_arm_size_test:
  stage: integration_test
  needs: ["build_dogstatsd_static-deb_arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64
  before_script:
    - source /root/.bashrc
    # Disable global before_script
    - mkdir -p $STATIC_BINARIES_DIR
    - $S3_CP_CMD $S3_ARTIFACTS_URI/static/dogstatsd.$ARCH $STATIC_BINARIES_DIR/dogstatsd
  script:
    - inv -e dogstatsd.size-test --skip-build

.system-probe_build_common:
  before_script:
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - '[[ "$ARCH" == arm64 ]] && cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog'
    - cd $SRC_PATH
    - inv -e deps --no-checks --verbose --dep-vendor-only

  script:
    - inv -e system-probe.build --go-version=$SYSTEM_PROBE_GO_VERSION --no-with-bcc
    - inv -e system-probe.test --only-check-bpf-bytes
    - $S3_CP_CMD $SRC_PATH/$SYSTEM_PROBE_BINARIES_DIR/system-probe $S3_ARTIFACTS_URI/system-probe.$ARCH

build_system-probe-x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["run_tests_deb-x64-py3"]
  tags: [ "runner:main", "size:large" ]
  extends: .system-probe_build_common
  variables:
    ARCH: amd64

build_system-probe-arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["run_go_tidy_check"]
  tags: ["runner:docker-arm", "platform:arm64"]
  extends: .system-probe_build_common
  variables:
    ARCH: arm64

.system-probe_with-bcc_build_common:
  before_script:
    # Hack to work around the cloning issue with arm runners
    - mkdir -p $GOPATH/src/github.com/DataDog
    - '[[ "$ARCH" == arm64 ]] && cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog'
    - cd $SRC_PATH
    - inv -e deps --no-checks --verbose --dep-vendor-only
    # Retrieve libbcc from S3
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-$ARCH.tar.xz /tmp/libbcc.tar.xz
    - mkdir -p /opt/datadog-agent/embedded
    - tar -xvf /tmp/libbcc.tar.xz -C /opt/datadog-agent/embedded

  script:
    - CGO_CFLAGS='-I/opt/datadog-agent/embedded/include' CGO_LDFLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib -L/opt/datadog-agent/embedded/lib' inv -e system-probe.build --go-version=$SYSTEM_PROBE_GO_VERSION
    - CGO_CFLAGS='-I/opt/datadog-agent/embedded/include' CGO_LDFLAGS='-Wl,-rpath,/opt/datadog-agent/embedded/lib -L/opt/datadog-agent/embedded/lib' inv -e system-probe.test --only-check-bpf-bytes
    - $S3_CP_CMD $SRC_PATH/$SYSTEM_PROBE_BINARIES_DIR/system-probe $S3_ARTIFACTS_URI/system-probe.with-bcc.$ARCH

build_system-probe_with-bcc-x64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["build_libbcc_x64", "run_tests_deb-x64-py3"]
  tags: [ "runner:main", "size:large" ]
  extends: .system-probe_with-bcc_build_common
  variables:
    ARCH: amd64

build_system-probe_with-bcc-arm64:
  stage: binary_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  needs: ["build_libbcc_arm64", "run_go_tidy_check"]
  tags: ["runner:docker-arm", "platform:arm64"]
  extends: .system-probe_with-bcc_build_common
  variables:
    ARCH: arm64

#
# package_build
#
#
.agent_build_common_deb: &agent_build_common_deb
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --no-with-bcc
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DEB
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent-dbg_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DBG_DEB
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-agent*_${PACKAGE_ARCH}.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

.agent_with-bcc_build_common_deb: &agent_with-bcc_build_common_deb
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.with-bcc.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --libbcc-tarball=/tmp/libbcc.tar.xz
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DEB
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-agent-dbg_*_${PACKAGE_ARCH}.deb $S3_ARTIFACTS_URI/$DESTINATION_DBG_DEB
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-agent*_${PACKAGE_ARCH}.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Agent package for deb-x64
agent_deb-x64-a6:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["run_tests_deb-x64-py2", "run_tests_deb-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    CONDA_ENV: ddpy3
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
    DESTINATION_DEB: 'datadog-agent_6_amd64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_6_amd64.deb'
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_deb

agent_deb-x64-a7:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["run_tests_deb-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    CONDA_ENV: ddpy3
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
    DESTINATION_DEB: 'datadog-agent_7_amd64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_7_amd64.deb'
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_deb

agent_with-bcc_deb-x64-a7:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["run_tests_deb-x64-py3", "build_system-probe_with-bcc-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    CONDA_ENV: ddpy3
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
    DESTINATION_DEB: 'datadog-agent-with-bcc_7_amd64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-with-bcc-dbg_7_amd64.deb'
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_deb

agent_deb-arm-a6:
  stage: package_build
  needs: ["run_go_tidy_check", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: arm64
    DESTINATION_DEB: 'datadog-agent_6_arm64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_6_arm64.deb'
  before_script:
    - source /root/.bashrc
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_deb

agent_deb-arm-a7:
  stage: package_build
  needs: ["run_go_tidy_check", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: arm64
    DESTINATION_DEB: 'datadog-agent_7_arm64.deb'
    DESTINATION_DBG_DEB: 'datadog-agent-dbg_7_arm64.deb'
  before_script:
    - source /root/.bashrc
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_deb

# build Agent package for deb-x64
iot_agent_deb-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["build_iot_agent-deb_x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    PACKAGE_ARCH: amd64
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  <<: *skip_when_unwanted_on_7
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-iot-agent*_amd64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-iot-agent*_amd64.deb $S3_ARTIFACTS_URI/datadog-iot-agent_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-iot-agent*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

iot_agent_deb-arm64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["build_iot_agent-deb_arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - source /root/.bashrc
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-iot-agent*_arm64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-iot-agent*_arm64.deb $S3_ARTIFACTS_URI/datadog-iot-agent_arm64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-iot-agent*_arm64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

.agent_build_common_rpm: &agent_build_common_rpm
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x

    # use --skip-deps since the deps are installed by `before_script`
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    # - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR  ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --no-with-bcc #--libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*.rpm' ! -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' rpm -i '{}'
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Agent package for rpm-x64
agent_rpm-x64-a6:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
    CONDA_ENV: ddpy3
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_rpm

# build Agent package for rpm-x64
agent_rpm-x64-a7:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["run_tests_rpm-x64-py3", "build_system-probe-x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
    CONDA_ENV: ddpy3
  before_script:
    - source /root/.bashrc && conda activate $CONDA_ENV
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_rpm

# build Agent package for rpm-arm64
agent_rpm-arm-a6:
  stage: package_build
  needs: ["run_go_tidy_check", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: arm64
  before_script:
    - source /root/.bashrc
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_rpm

# build Agent package for rpm-arm64
agent_rpm-arm-a7:
  stage: package_build
  needs: ["run_go_tidy_check", "build_system-probe-arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: arm64
  before_script:
    - source /root/.bashrc
    - inv -e deps --no-checks --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_rpm

iot_agent_rpm-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["build_iot_agent-deb_x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  <<: *skip_when_unwanted_on_7
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x

    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

iot_agent_rpm-arm64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_arm64:$DATADOG_AGENT_ARMBUILDIMAGES
  tags: ["runner:docker-arm", "platform:arm64"]
  needs: ["build_iot_agent-deb_arm64"]
  variables:
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - source /root/.bashrc
    # Hack to work around the cloning issue with arm runners
    # - mkdir -p $GOPATH/src/github.com/DataDog
    # - cp -R $GOPATH/src/github.com/*/*/DataDog/datadog-agent $GOPATH/src/github.com/DataDog
    # - cd $SRC_PATH
    - inv -e deps --verbose --dep-vendor-only
    - export RELEASE_VERSION=$RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  script:
    - echo "About to build iot agent for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x

    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - ls $OMNIBUS_BASE_DIR/pkg/
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

.agent_build_common_suse_rpm: &agent_build_common_suse_rpm
  script:
    - echo "About to build for $RELEASE_VERSION"
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # use --skip-deps since the deps are installed by `before_script`
    - $S3_CP_CMD $S3_ARTIFACTS_URI/system-probe.${PACKAGE_ARCH} /tmp/system-probe
    - chmod 755 /tmp/system-probe
    # - $S3_CP_CMD $S3_ARTIFACTS_URI/libbcc-${PACKAGE_ARCH}.tar.xz /tmp/libbcc.tar.xz
    - inv -e agent.omnibus-build --release-version "$RELEASE_VERSION" --major-version "$AGENT_MAJOR_VERSION" --python-runtimes "$PYTHON_RUNTIMES" --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps --system-probe-bin=/tmp/system-probe --no-with-bcc #--libbcc-tarball=/tmp/libbcc.tar.xz
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' ! -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*dbg*.rpm' -print0 | xargs -0 -I '{}' zypper in '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
    # FIXME: skip the installation step until we fix the preinst/postinst scripts in the rpm package
    # to also work with SUSE11
    # - rpm -i $OMNIBUS_PACKAGE_DIR_SUSE/*.rpm
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# build Agent package for suse-x64
agent_suse-x64-a6:
  stage: package_build
  needs: ["run_tests_rpm-x64-py2", "run_tests_rpm-x64-py3", "build_system-probe-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
    PACKAGE_ARCH: amd64
  before_script:
    - export RELEASE_VERSION=$RELEASE_VERSION_6
    - inv -e deps --no-checks --verbose --dep-vendor-only
  <<: *skip_when_unwanted_on_6
  <<: *agent_build_common_suse_rpm

# build Agent package for suse-x64
agent_suse-x64-a7:
  stage: package_build
  needs: ["run_tests_rpm-x64-py3", "build_system-probe-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
    PACKAGE_ARCH: amd64
  before_script:
    - export RELEASE_VERSION=$RELEASE_VERSION_7
    - inv -e deps --no-checks --verbose --dep-vendor-only
  <<: *skip_when_unwanted_on_7
  <<: *agent_build_common_suse_rpm

iot_agent_suse-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:2xlarge" ]
  needs: ["build_iot_agent-deb_x64"]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --verbose --dep-vendor-only --no-checks
  <<: *skip_when_unwanted_on_7
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase_e09422b3 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    - inv -e agent.omnibus-build --iot --log-level debug --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR --skip-deps
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# cloudfoundry iot build/windows
windows_zip_agent_binaries_x64-a7:
  stage: package_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["run_go_tidy_check"]
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    OMNIBUS_TARGET: agent_binaries
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e AWS_NETWORKING=true -e SIGN_WINDOWS=true 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDIMAGES} c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\*.zip .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg
  <<: *skip_when_unwanted_on_7

##
## windows dockerized builds
##

.windows_old_msi_base:
  stage: package_build
  needs: ["run_go_tidy_check"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  # Unavailable on gitlab < 12.3
  # timeout: 2h 00m
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e CI_JOB_ID=${CI_JOB_ID} -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true -e TARGET_ARCH="$ARCH" -e NEW_BUILDER=false 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\oldbuildwin.bat
    - copy build-out\${CI_JOB_ID}\*.msi .omnibus\pkg
    - if (Test-Path build-out\${CI_JOB_ID}\*.zip) { copy build-out\${CI_JOB_ID}\*.zip .omnibus\pkg }
    - remove-item -recurse -force build-out\${CI_JOB_ID}
    - get-childitem build-out
    - get-childitem .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg
  <<: *skip_when_triggered
  allow_failure: true

.windows_old_main_agent_base:
  extends: .windows_old_msi_base
  variables:
    OMNIBUS_TARGET: main

windows_old_msi_x64-a7:
  extends: .windows_old_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7

windows_old_msi_x64-a6:
  extends: .windows_old_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6

.windows_msi_base:
  stage: package_build
  needs: ["run_go_tidy_check"]
  tags: ["runner:windows-docker", "windowsversion:1809"]
  # Unavailable on gitlab < 12.3
  # timeout: 2h 00m
  script:
    - if (Test-Path .omnibus) { remove-item -recurse -force .omnibus }
    - if (Test-Path build-out) { remove-item -recurse -force build-out }
    - mkdir .omnibus\pkg
    - docker run --rm -m 4096M -v "$(Get-Location):c:\mnt" -e CI_JOB_ID=${CI_JOB_ID} -e OMNIBUS_TARGET=${OMNIBUS_TARGET} -e WINDOWS_BUILDER=true -e RELEASE_VERSION="$RELEASE_VERSION" -e MAJOR_VERSION="$AGENT_MAJOR_VERSION" -e PY_RUNTIMES="$PYTHON_RUNTIMES" -e AWS_NETWORKING=true -e SIGN_WINDOWS=true -e TARGET_ARCH="$ARCH" -e NEW_BUILDER=true 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDIMAGES} c:\mnt\tasks\winbuildscripts\buildwin.bat
    - copy build-out\${CI_JOB_ID}\*.msi .omnibus\pkg
    - if (Test-Path build-out\${CI_JOB_ID}\*.zip) { copy build-out\${CI_JOB_ID}\*.zip .omnibus\pkg }
    - remove-item -recurse -force build-out\${CI_JOB_ID}
    - get-childitem build-out
    - get-childitem .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg

.windows_main_agent_base:
  extends: .windows_msi_base
  variables:
    OMNIBUS_TARGET: main

windows_msi_x64-a7:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7

windows_msi_x86-a7:
  extends: .windows_main_agent_base
  allow_failure: true
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 7
    PYTHON_RUNTIMES: '3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7
  <<: *skip_when_triggered

windows_msi_x64-a6:
  extends: .windows_main_agent_base
  variables:
    ARCH: "x64"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6

windows_msi_x86-a6:
  extends: .windows_main_agent_base
  allow_failure: true
  variables:
    ARCH: "x86"
    AGENT_MAJOR_VERSION: 6
    PYTHON_RUNTIMES: '2,3'
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_6
  <<: *skip_when_unwanted_on_6
  <<: *skip_when_triggered

# build dogstatsd package for Windows
windows_dsd_msi_x64-a7:
  extends: .windows_msi_base
  variables:
    ARCH: "x64"
    PYTHON_RUNTIMES: ""
    AGENT_MAJOR_VERSION: '7'
    OMNIBUS_TARGET: dogstatsd
  before_script:
    - set RELEASE_VERSION $RELEASE_VERSION_7
  <<: *skip_when_unwanted_on_7

windows_choco_online_7_x64:
  stage: image_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["windows_msi_x64-a7"]
  variables:
    ARCH: "x64"
  script:
    - $ErrorActionPreference = "Stop"
    - docker run --rm -v "$(Get-Location):c:\mnt" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopack.bat online
    - copy build-out\*.nupkg .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg
  <<: *skip_when_unwanted_on_7

windows_choco_offline_7_x64:
  stage: image_build
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["windows_msi_x64-a7"]
  variables:
    ARCH: "x64"
  script:
    - $ErrorActionPreference = "Stop"
    - Get-ChildItem .omnibus\pkg
    - copy .omnibus\pkg\*.msi .\chocolatey\tools-offline\
    - docker run --rm -v "$(Get-Location):c:\mnt" 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopack.bat offline
    - copy build-out\*.nupkg .omnibus\pkg
  artifacts:
    expire_in: 2 weeks
    paths:
      - .omnibus/pkg
  when: manual
  <<: *skip_when_unwanted_on_7

publish_choco_7_x64:
  stage: image_deploy
  tags: ["runner:windows-docker", "windowsversion:1809"]
  needs: ["windows_choco_online_7_x64"]
  variables:
    ARCH: "x64"
  before_script:
    - $chocolateyApiKey = (aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.chocolatey_api_key --with-decryption --query "Parameter.Value" --out text)
  script:
    - $ErrorActionPreference = "Stop"
    - Get-ChildItem .omnibus\pkg
    - if (Test-Path nupkg) { remove-item -recurse -force nupkg }
    - mkdir nupkg
    - copy .omnibus\pkg\*.nupkg nupkg\
    - Get-ChildItem nupkg
    - docker run --rm -v "$(Get-Location):c:\mnt" -e CHOCOLATEY_API_KEY=${chocolateyApiKey} 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_1809_${ARCH}:${Env:DATADOG_AGENT_WINBUILDERS} c:\mnt\tasks\winbuildscripts\chocopush.bat
  when: manual
  <<: *skip_when_unwanted_on_7

# build Agent package for android
agent_android_apk:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/android_builder:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  <<: *skip_when_unwanted_on_7
  <<: *skip_when_triggered
  before_script:
    - echo running android before_script
    - cd $SRC_PATH
    - pip install -U pip
    - pip install -r requirements.txt
    - inv -e deps --android --dep-vendor-only --no-checks
    # Some Android license has changed, we have to accept the new version.
    # But on top of that, there is a bug in sdkmanager not updating correctly
    # the existing license, so, we have to manually accept the new license.
    # https://issuetracker.google.com/issues/123054726
    # The real fix will be to change the builders
    - echo "24333f8a63b6825ea9c5514f83c2829b004d1fee" > "$ANDROID_HOME/licenses/android-sdk-license"
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # for now do the steps manually.  Should eventually move this to an invoke
    # task
    - inv -e android.build --major-version 7
    - mkdir -p $OMNIBUS_PACKAGE_DIR
    - cp ./bin/agent/ddagent-*-unsigned.apk $OMNIBUS_PACKAGE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstastd package for deb-x64
dogstatsd_deb-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus in a neutral directory.
    # Thus, we move the artifacts at the end in a gitlab-friendly dir.
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -name "datadog-dogstatsd*_amd64.deb" -exec dpkg -c {} \;
    - $S3_CP_CMD $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb $S3_ARTIFACTS_URI/datadog-dogstatsd_amd64.deb
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/datadog-dogstatsd*_amd64.deb{,.metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR

# build Dogstastd package for rpm-x64
dogstatsd_rpm-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/rpm_x64:$DATADOG_AGENT_BUILDIMAGES
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - source /root/.bashrc && conda activate ddpy3
    - inv -e deps --no-checks --verbose --dep-vendor-only
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR && cp $OMNIBUS_BASE_DIR/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR


# build Dogstastd package for rpm-x64
dogstatsd_suse-x64:
  stage: package_build
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/suse_x64:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  needs: ["build_dogstatsd-deb_x64"]
  <<: *skip_when_unwanted_on_7
  variables:
    AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: /credentials
  before_script:
    - inv -e deps --no-checks --dep-vendor-only
  script:
    # remove artifacts from previous pipelines that may come from the cache
    - rm -rf $OMNIBUS_PACKAGE_DIR_SUSE/*
    # Artifacts and cache must live within project directory but we run omnibus
    # from the GOPATH (see above). We then call `invoke` passing --base-dir,
    # pointing to a gitlab-friendly location.
    - set +x
    - RPM_GPG_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_private_key --with-decryption --query "Parameter.Value" --out text)
    - printf -- "$RPM_GPG_KEY" | gpg --import --batch
    - export RPM_SIGNING_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.rpm_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)
    - set -x
    # Use --skip-deps since the deps are installed by `before_script`.
    - inv -e dogstatsd.omnibus-build --release-version "$RELEASE_VERSION_7" --major-version 7 --base-dir $OMNIBUS_BASE_DIR_SUSE ${USE_S3_CACHING} --skip-deps
    - find $OMNIBUS_BASE_DIR_SUSE/pkg -type f -name '*.rpm' -print0 | sort -z | xargs -0 -I '{}' rpm -i '{}'
    - mkdir -p $OMNIBUS_PACKAGE_DIR_SUSE && cp $OMNIBUS_BASE_DIR_SUSE/pkg/*.{rpm,metadata.json} $OMNIBUS_PACKAGE_DIR_SUSE
  # TODO: enabling the cache cause builds to be slower and slower on `master`. Re-enable once this is investigated/fixed
  # cache:
  #   # cache per branch
  #   key: $CI_COMMIT_REF_NAME
  #   paths:
  #     - $OMNIBUS_BASE_DIR_SUSE
  artifacts:
    expire_in: 2 weeks
    paths:
      - $OMNIBUS_PACKAGE_DIR_SUSE

# deploy debian packages to apt staging repo
deploy_deb_testing-a6:
  stage: testkitchen_deploy
  needs: ["agent_deb-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 6 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_6*amd64.deb

deploy_deb_testing-a7:
  stage: testkitchen_deploy
  needs: ["agent_deb-x64-a7", "iot_agent_deb-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c "pipeline-$DD_PIPELINE_ID" -m 7 -b $DEB_TESTING_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/datadog-*_7*amd64.deb

# deploy rpm packages to yum staging repo
deploy_rpm_testing-a6:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["agent_rpm-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "pipeline-$DD_PIPELINE_ID/6/x86_64/" $OMNIBUS_PACKAGE_DIR/datadog-*-6.*x86_64.rpm

deploy_rpm_testing-a7:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["agent_rpm-x64-a7", "iot_agent_rpm-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "pipeline-$DD_PIPELINE_ID/7/x86_64/" $OMNIBUS_PACKAGE_DIR/datadog-*-7.*x86_64.rpm

# deploy rpm packages to yum staging repo
deploy_suse_rpm_testing-a6:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["agent_suse-x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "suse/pipeline-$DD_PIPELINE_ID/6/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-6.*x86_64.rpm

deploy_suse_rpm_testing-a7:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["agent_suse-x64-a7", "iot_agent_suse-x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_TESTING_S3_BUCKET -p "suse/pipeline-$DD_PIPELINE_ID/7/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/datadog-*-7.*x86_64.rpm

# deploy windows packages to our testing bucket
deploy_windows_testing-a6:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  stage: testkitchen_deploy
  needs: ["windows_msi_x64-a6"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6.*.msi" $OMNIBUS_PACKAGE_DIR s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET_A6 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_windows_testing-a7:
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_7
  stage: testkitchen_deploy
  needs: ["windows_msi_x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7.*.msi" $OMNIBUS_PACKAGE_DIR s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET_A7 --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

#
# Kitchen Test Common templates
#

.kitchen_common: &kitchen_common
  <<: *run_only_when_testkitchen_triggered
  stage: testkitchen_testing
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/dd-agent-testing:$DATADOG_AGENT_BUILDERS
  artifacts:
    expire_in: 2 weeks
    when: always
    paths:
      - $CI_PROJECT_DIR/kitchen_logs
  tags: [ "runner:main", "size:large" ]
  retry: 1


# Kitchen: agents
# ---------------

.kitchen_agent_a6: &kitchen_agent_a6
  <<: *kitchen_common
  <<: *skip_when_unwanted_on_6
  variables:
    AGENT_MAJOR_VERSION: 6
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6

.kitchen_agent_a7: &kitchen_agent_a7
  <<: *kitchen_common
  <<: *skip_when_unwanted_on_7
  variables:
    AGENT_MAJOR_VERSION: 7
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7


# Kitchen: OSes
# -------------

.kitchen_os_windows: &kitchen_os_windows
  before_script: # Note: if you are changing this, remember to also change .kitchen_test_windows_installer, which has a copy of this with less TEST_PLATFORMS defined.
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="win2008r2,id,/subscriptions/8c56d827-5f07-45ce-8f2b-6c5001db5c6f/resourceGroups/kitchen-test-images/providers/Microsoft.Compute/galleries/kitchenimages/images/Windows2008-R2-SP1/versions/1.0.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2012,urn,MicrosoftWindowsServer:WindowsServer:2012-Datacenter:3.127.20190410"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2012r2,urn,MicrosoftWindowsServer:WindowsServer:2012-R2-Datacenter:4.127.20190416"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2016,urn,MicrosoftWindowsServer:WindowsServer:2016-Datacenter-Server-Core:2016.127.20190603"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|win2019,urn,MicrosoftWindowsServer:WindowsServer:2019-Datacenter-Core:2019.0.20190603"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_centos: &kitchen_os_centos
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="centos-69,urn,OpenLogic:CentOS:6.9:6.9.20180530"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|centos-77,urn,OpenLogic:CentOS:7.7:7.7.201912090"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|rhel-81,urn,RedHat:RHEL:8.1:8.1.2020020415"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_suse: &kitchen_os_suse
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="sles-11,urn,SUSE:SLES-BYOS:11-SP4:2019.12.05"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|sles-12,urn,SUSE:SLES-BYOS:12-SP4:2019.11.13"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|sles-15,urn,SUSE:SLES-BYOS:15:2019.11.15"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_debian: &kitchen_os_debian
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="debian-8,urn,credativ:Debian:8:8.20190313.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|debian-9,urn,credativ:Debian:9:9.20190515.0"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|debian-10,urn,Debian:debian-10:10:0.20190709.401"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

.kitchen_os_ubuntu: &kitchen_os_ubuntu
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="ubuntu-14-04,urn,Canonical:UbuntuServer:14.04.5-LTS:14.04.201905140"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|ubuntu-16-04,urn,Canonical:UbuntuServer:16.04.0-LTS:16.04.201906170"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|ubuntu-18-04,urn,Canonical:UbuntuServer:18.04-LTS:18.04.201906040"
    - export TEST_PLATFORMS="$TEST_PLATFORMS|ubuntu-20-04,urn,Canonical:0001-com-ubuntu-server-focal:20_04-lts:20.04.202004230"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh

# Kitchen: tests
# --------------

.kitchen_test_chef:
  script:
    - bash -l tasks/run-test-kitchen.sh chef-test $AGENT_MAJOR_VERSION

.kitchen_test_step_by_step:
  script:
    - bash -l tasks/run-test-kitchen.sh step-by-step-test $AGENT_MAJOR_VERSION

.kitchen_test_install_script:
  script:
    - bash -l tasks/run-test-kitchen.sh install-script-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade5:
  script:
    - bash -l tasks/run-test-kitchen.sh upgrade5-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade6:
  script:
    - bash -l tasks/run-test-kitchen.sh upgrade6-test $AGENT_MAJOR_VERSION

.kitchen_test_upgrade7:
  script:
    - bash -l tasks/run-test-kitchen.sh upgrade7-test $AGENT_MAJOR_VERSION

.kitchen_test_windows_installer:
  before_script: # Override kitchen_os_windows default with a smaller set of TEST_PLATFORMS
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - rsync -azr --delete ./ $SRC_PATH
    - export TEST_PLATFORMS="win2012,urn,MicrosoftWindowsServer:WindowsServer:2012-Datacenter:3.127.20190410"
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/kitchen_setup.sh
  script:
    - bash -l tasks/run-test-kitchen.sh windows-install-test $AGENT_MAJOR_VERSION

# Kitchen: Agent flavor locations
# -------------------------------

.kitchen_datadog_agent_flavor:
  variables:
    AGENT_FLAVOR: "datadog-agent"

.kitchen_datadog_iot_agent_flavor:
  variables:
    AGENT_FLAVOR: "datadog-iot-agent"

# Kitchen: Azure locations
# -------------------------------

.kitchen_azure_location_north_central_us:
  variables:
    AZURE_LOCATION: "North Central US"

.kitchen_azure_location_west_central_us:
  variables:
    AZURE_LOCATION: "West Central US"

.kitchen_azure_location_central_us:
  variables:
    AZURE_LOCATION: "Central US"

.kitchen_azure_location_south_central_us:
  variables:
    AZURE_LOCATION: "South Central US"

# Kitchen: Test types (test suite * agent flavor + azure location)
# -------------------------------

.kitchen_test_chef_agent:
  extends:
    - .kitchen_test_chef
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_north_central_us

.kitchen_test_step_by_step_agent:
  extends:
    - .kitchen_test_step_by_step
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_central_us

.kitchen_test_install_script_agent:
  extends:
    - .kitchen_test_install_script
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_south_central_us

.kitchen_test_install_script_iot_agent:
  extends:
    - .kitchen_test_install_script
    - .kitchen_datadog_iot_agent_flavor
    - .kitchen_azure_location_west_central_us

.kitchen_test_upgrade5_agent:
  extends:
    - .kitchen_test_upgrade5
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_central_us

.kitchen_test_upgrade6_agent:
  extends:
    - .kitchen_test_upgrade6
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_south_central_us

.kitchen_test_upgrade7_agent:
  extends:
    - .kitchen_test_upgrade7
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_north_central_us

.kitchen_test_windows_installer_agent:
  extends:
    - .kitchen_test_windows_installer
    - .kitchen_datadog_agent_flavor
    - .kitchen_azure_location_north_central_us


# Kitchen: scenarios (os * agent)
# -------------------------------

.kitchen_scenario_windows_a6:
  extends:
    - .kitchen_os_windows
    - .kitchen_agent_a6
  needs: ["deploy_windows_testing-a6"]

.kitchen_scenario_windows_a7:
  extends:
    - .kitchen_os_windows
    - .kitchen_agent_a7
  needs: ["deploy_windows_testing-a7"]

.kitchen_scenario_centos_a6:
  extends:
    - .kitchen_os_centos
    - .kitchen_agent_a6
  needs: ["deploy_rpm_testing-a6"]

.kitchen_scenario_centos_a7:
  extends:
    - .kitchen_os_centos
    - .kitchen_agent_a7
  needs: ["deploy_rpm_testing-a7"]

.kitchen_scenario_ubuntu_a6:
  extends:
    - .kitchen_os_ubuntu
    - .kitchen_agent_a6
  needs: ["deploy_deb_testing-a6"]

.kitchen_scenario_ubuntu_a7:
  extends:
    - .kitchen_os_ubuntu
    - .kitchen_agent_a7
  needs: ["deploy_deb_testing-a7"]

.kitchen_scenario_suse_a6:
  extends:
    - .kitchen_os_suse
    - .kitchen_agent_a6
  needs: ["deploy_suse_rpm_testing-a6"]

.kitchen_scenario_suse_a7:
  extends:
    - .kitchen_os_suse
    - .kitchen_agent_a7
  needs: ["deploy_suse_rpm_testing-a7"]

.kitchen_scenario_debian_a6:
  extends:
    - .kitchen_os_debian
    - .kitchen_agent_a6
  needs: ["deploy_deb_testing-a6"]

.kitchen_scenario_debian_a7:
  extends:
    - .kitchen_os_debian
    - .kitchen_agent_a7
  needs: ["deploy_deb_testing-a7"]


# Kitchen: final test matrix (tests * scenarios)
# ----------------------------------------------

# run dd-agent-testing for the windows installer
kitchen_windows_installer_agent-a6:
  allow_failure: true
  extends:
    - .kitchen_scenario_windows_a6
    - .kitchen_test_windows_installer_agent
  retry: 0

kitchen_windows_installer_agent-a7:
  allow_failure: true
  extends:
    - .kitchen_scenario_windows_a7
    - .kitchen_test_windows_installer_agent
  retry: 0

# run dd-agent-testing on windows
kitchen_windows_chef_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a6
    - .kitchen_test_chef_agent

kitchen_windows_chef_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a7
    - .kitchen_test_chef_agent

kitchen_windows_upgrade5_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a6
    - .kitchen_test_upgrade5_agent

kitchen_windows_upgrade5_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a7
    - .kitchen_test_upgrade5_agent

kitchen_windows_upgrade6_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a6
    - .kitchen_test_upgrade6_agent

kitchen_windows_upgrade6_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a7
    - .kitchen_test_upgrade6_agent

kitchen_windows_upgrade7_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_windows_a7
    - .kitchen_test_upgrade7_agent

# run dd-agent-testing on centos
kitchen_centos_chef_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a6
    - .kitchen_test_chef_agent

kitchen_centos_chef_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_chef_agent

kitchen_centos_install_script_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a6
    - .kitchen_test_install_script_agent

kitchen_centos_install_script_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_install_script_agent

kitchen_centos_install_script_iot_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_install_script_iot_agent

kitchen_centos_step_by_step_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a6
    - .kitchen_test_step_by_step_agent

kitchen_centos_step_by_step_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_step_by_step_agent

kitchen_centos_upgrade5_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a6
    - .kitchen_test_upgrade5_agent

kitchen_centos_upgrade5_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_upgrade5_agent

kitchen_centos_upgrade6_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a6
    - .kitchen_test_upgrade6_agent

kitchen_centos_upgrade6_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_upgrade6_agent

kitchen_centos_upgrade7_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_centos_a7
    - .kitchen_test_upgrade7_agent

# run dd-agent-testing on ubuntu
# Could fail if we encounter the issue with apt locks/azure agent, but should be investigated if that's the case
kitchen_ubuntu_chef_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a6
    - .kitchen_test_chef_agent

kitchen_ubuntu_chef_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_chef_agent

kitchen_ubuntu_install_script_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a6
    - .kitchen_test_install_script_agent

kitchen_ubuntu_install_script_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_install_script_agent

kitchen_ubuntu_install_script_iot_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_install_script_iot_agent

kitchen_ubuntu_step_by_step_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a6
    - .kitchen_test_step_by_step_agent

kitchen_ubuntu_step_by_step_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_step_by_step_agent

kitchen_ubuntu_upgrade5_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a6
    - .kitchen_test_upgrade5_agent

kitchen_ubuntu_upgrade5_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_upgrade5_agent

kitchen_ubuntu_upgrade6_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a6
    - .kitchen_test_upgrade6_agent

kitchen_ubuntu_upgrade6_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_upgrade6_agent

kitchen_ubuntu_upgrade7_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_ubuntu_a7
    - .kitchen_test_upgrade7_agent

# run dd-agent-testing on suse
kitchen_suse_chef_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a6
    - .kitchen_test_chef_agent

kitchen_suse_chef_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_chef_agent

kitchen_suse_install_script_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a6
    - .kitchen_test_install_script_agent

kitchen_suse_install_script_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_install_script_agent

kitchen_suse_install_script_iot_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_install_script_iot_agent

kitchen_suse_step_by_step_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a6
    - .kitchen_test_step_by_step_agent

kitchen_suse_step_by_step_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_step_by_step_agent

kitchen_suse_upgrade5_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a6
    - .kitchen_test_upgrade5_agent

kitchen_suse_upgrade5_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_upgrade5_agent

kitchen_suse_upgrade6_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a6
    - .kitchen_test_upgrade6_agent

kitchen_suse_upgrade6_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_upgrade6_agent

kitchen_suse_upgrade7_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_suse_a7
    - .kitchen_test_upgrade7_agent

# run dd-agent-testing on debian
# Could fail if we encounter the issue with apt locks/azure agent, but should be investigated if that's the case
kitchen_debian_chef_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a6
    - .kitchen_test_chef_agent

kitchen_debian_chef_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_chef_agent

kitchen_debian_install_script_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a6
    - .kitchen_test_install_script_agent

kitchen_debian_install_script_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_install_script_agent

kitchen_debian_install_script_iot_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_install_script_iot_agent

kitchen_debian_step_by_step_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a6
    - .kitchen_test_step_by_step_agent

kitchen_debian_step_by_step_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_step_by_step_agent

kitchen_debian_upgrade5_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a6
    - .kitchen_test_upgrade5_agent

kitchen_debian_upgrade5_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_upgrade5_agent

kitchen_debian_upgrade6_agent-a6:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a6
    - .kitchen_test_upgrade6_agent

kitchen_debian_upgrade6_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_upgrade6_agent

kitchen_debian_upgrade7_agent_agent-a7:
  allow_failure: false
  extends:
    - .kitchen_scenario_debian_a7
    - .kitchen_test_upgrade7_agent

.kitchen_cleanup_s3_common: &kitchen_cleanup_s3_common
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  <<: *run_only_when_testkitchen_triggered
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  script:
    - aws s3 rm s3://$DEB_TESTING_S3_BUCKET/dists/pipeline-$DD_PIPELINE_ID --recursive
    - aws s3 rm s3://$RPM_TESTING_S3_BUCKET/pipeline-$DD_PIPELINE_ID --recursive
    - aws s3 rm s3://$RPM_TESTING_S3_BUCKET/suse/pipeline-$DD_PIPELINE_ID --recursive
    - if [ $AGENT_MAJOR_VERSION == "7" ]; then export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A7; else export WINDOWS_TESTING_S3_BUCKET=$WINDOWS_TESTING_S3_BUCKET_A6; fi
    - aws s3 rm s3://$WIN_S3_BUCKET/$WINDOWS_TESTING_S3_BUCKET --recursive
    - cd $OMNIBUS_PACKAGE_DIR
    - for deb in $(ls *amd64.deb); do aws s3 rm s3://$DEB_TESTING_S3_BUCKET/pool/d/da/$deb --recursive; done
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always

# kitchen tests cleanup
testkitchen_cleanup_s3-a6:
  variables:
    AGENT_MAJOR_VERSION: 6
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  dependencies:
    - agent_deb-x64-a6
  <<: *kitchen_cleanup_s3_common

testkitchen_cleanup_s3-a7:
  variables:
    AGENT_MAJOR_VERSION: 7
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  dependencies:
    - agent_deb-x64-a7
  <<: *kitchen_cleanup_s3_common

.kitchen_cleanup_azure_common: &kitchen_cleanup_azure_common
  stage: testkitchen_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/dd-agent-testing:$DATADOG_AGENT_BUILDERS
  <<: *run_only_when_testkitchen_triggered
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  before_script:
    - rsync -azr --delete ./ $SRC_PATH
  script:
    - cd $DD_AGENT_TESTING_DIR
    - bash -l tasks/clean.sh
  # even if this fails, it shouldn't block the pipeline.
  allow_failure: true
  when: always

testkitchen_cleanup_azure-a6:
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a6
  <<: *kitchen_cleanup_azure_common

testkitchen_cleanup_azure-a7:
  variables:
    DD_PIPELINE_ID: $CI_PIPELINE_ID-a7
  <<: *kitchen_cleanup_azure_common

#
# pkg_metrics: send metrics about packages
#

send_pkg_size-a6:
  stage: pkg_metrics
  allow_failure: true
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  before_script:
    # FIXME: tmp while we uppdate the base image
    - apt-get install -y wget rpm2cpio cpio
    - ls -l $OMNIBUS_PACKAGE_DIR
    - ls -l $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a6
    - agent_rpm-x64-a6
    - agent_suse-x64-a6
  script:
    - source /root/.bashrc && conda activate ddpy3
    - mkdir -p /tmp/deb/agent
    - mkdir -p /tmp/rpm/agent
    - mkdir -p /tmp/suse/agent

    # we silence dpkg and cpio output so we don't exceed gitlab log limit

    # debian
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-agent_6*_amd64.deb /tmp/deb/agent > /dev/null
    - DEB_AGENT_SIZE=$(du -sB1 /tmp/deb/agent | sed 's/\([0-9]\+\).\+/\1/')
    # centos
    - cd /tmp/rpm/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-agent-6.*.x86_64.rpm | cpio -idm > /dev/null
    - RPM_AGENT_SIZE=$(du -sB1 /tmp/rpm/agent | sed 's/\([0-9]\+\).\+/\1/')
    # suse
    - cd /tmp/suse/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-agent-6.*.x86_64.rpm | cpio -idm > /dev/null
    - SUSE_AGENT_SIZE=$(du -sB1 /tmp/suse/agent | sed 's/\([0-9]\+\).\+/\1/')

    - currenttime=$(date +%s)
    - DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key --with-decryption --query "Parameter.Value" --out text)
    - |
      curl --fail -X POST -H "Content-type: application/json" \
      -d "{\"series\":[
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_AGENT_SIZE]], \"tags\":[\"os:debian\", \"package:agent\", \"agent:6\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_AGENT_SIZE]], \"tags\":[\"os:centos\", \"package:agent\", \"agent:6\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_AGENT_SIZE]], \"tags\":[\"os:suse\", \"package:agent\", \"agent:6\"]}
          ]}" \
      "https://api.datadoghq.com/api/v1/series?api_key=$DD_API_KEY"

send_pkg_size-a7:
  stage: pkg_metrics
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  allow_failure: true
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/deb_x64:$DATADOG_AGENT_BUILDIMAGES
  before_script:
    # FIXME: tmp while we uppdate the base image
    - apt-get install -y wget rpm2cpio cpio
    - ls -l $OMNIBUS_PACKAGE_DIR
    - ls -l $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a7
    - iot_agent_deb-x64
    - dogstatsd_deb-x64
    - agent_rpm-x64-a7
    - iot_agent_rpm-x64
    - dogstatsd_rpm-x64
    - agent_suse-x64-a7
    - dogstatsd_suse-x64
    - iot_agent_suse-x64
  script:
    - source /root/.bashrc && conda activate ddpy3
    - mkdir -p /tmp/deb/agent /tmp/deb/dogstatsd /tmp/deb/iot-agent
    - mkdir -p /tmp/rpm/agent /tmp/rpm/dogstatsd /tmp/rpm/iot-agent
    - mkdir -p /tmp/suse/agent /tmp/suse/dogstatsd /tmp/suse/iot-agent

    # We silence dpkg and cpio output so we don't exceed gitlab log limit

    # debian
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-agent_7*_amd64.deb /tmp/deb/agent > /dev/null
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-iot-agent_7*_amd64.deb /tmp/deb/iot-agent > /dev/null
    - dpkg -x $OMNIBUS_PACKAGE_DIR/datadog-dogstatsd_7*_amd64.deb /tmp/deb/dogstatsd > /dev/null
    - DEB_AGENT_SIZE=$(du -sB1 /tmp/deb/agent | sed 's/\([0-9]\+\).\+/\1/')
    - DEB_DOGSTATSD_SIZE=$(du -sB1 /tmp/deb/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')
    - DEB_IOT_AGENT_SIZE=$(du -sB1 /tmp/deb/iot-agent | sed 's/\([0-9]\+\).\+/\1/')
    # centos
    - cd /tmp/rpm/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/rpm/dogstatsd && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-dogstatsd-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/rpm/iot-agent && rpm2cpio $OMNIBUS_PACKAGE_DIR/datadog-iot-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - RPM_AGENT_SIZE=$(du -sB1 /tmp/rpm/agent | sed 's/\([0-9]\+\).\+/\1/')
    - RPM_DOGSTATSD_SIZE=$(du -sB1 /tmp/rpm/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')
    - RPM_IOT_AGENT_SIZE=$(du -sB1 /tmp/rpm/iot-agent | sed 's/\([0-9]\+\).\+/\1/')
    # suse
    - cd /tmp/suse/agent && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/suse/dogstatsd && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-dogstatsd-7.*.x86_64.rpm | cpio -idm > /dev/null
    - cd /tmp/suse/iot-agent && rpm2cpio $OMNIBUS_PACKAGE_DIR_SUSE/datadog-iot-agent-7.*.x86_64.rpm | cpio -idm > /dev/null
    - SUSE_AGENT_SIZE=$(du -sB1 /tmp/suse/agent | sed 's/\([0-9]\+\).\+/\1/')
    - SUSE_DOGSTATSD_SIZE=$(du -sB1 /tmp/suse/dogstatsd | sed 's/\([0-9]\+\).\+/\1/')
    - SUSE_IOT_AGENT_SIZE=$(du -sB1 /tmp/suse/iot-agent | sed 's/\([0-9]\+\).\+/\1/')

    - currenttime=$(date +%s)
    - DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key --with-decryption --query "Parameter.Value" --out text)
    - |
      curl --fail -X POST -H "Content-type: application/json" \
      -d "{\"series\":[
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_AGENT_SIZE]], \"tags\":[\"os:debian\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_DOGSTATSD_SIZE]], \"tags\":[\"os:debian\", \"package:dogstatsd\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $DEB_IOT_AGENT_SIZE]], \"tags\":[\"os:debian\", \"package:iot-agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_AGENT_SIZE]], \"tags\":[\"os:centos\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_DOGSTATSD_SIZE]], \"tags\":[\"os:centos\", \"package:dogstatsd\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $RPM_IOT_AGENT_SIZE]], \"tags\":[\"os:centos\", \"package:iot-agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_AGENT_SIZE]], \"tags\":[\"os:suse\", \"package:agent\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_DOGSTATSD_SIZE]], \"tags\":[\"os:suse\", \"package:dogstatsd\", \"agent:7\"]},
            {\"metric\":\"datadog.agent.package.size\",\"points\":[[$currenttime, $SUSE_IOT_AGENT_SIZE]], \"tags\":[\"os:suse\", \"package:iot-agent\", \"agent:7\"]}
          ]}" \
      "https://api.datadoghq.com/api/v1/series?api_key=$DD_API_KEY"

#
# image_build
#

.docker_build_job_definition: &docker_build_job_definition
  stage: image_build
  script:
    - aws s3 sync --only-show-errors $S3_ARTIFACTS_URI $BUILD_CONTEXT
    - TAG_SUFFIX=${TAG_SUFFIX:-}
    - BUILD_ARG=${BUILD_ARG:-}
    - TARGET_TAG=$IMAGE:v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}$TAG_SUFFIX-$ARCH
    # Pull base image(s) with content trust enabled
    - pip install -r requirements.txt
    - inv -e docker.pull-base-images --signed-pull $BUILD_CONTEXT/$ARCH/Dockerfile
    # Build testing stage if provided
    - test "$TESTING_ARG" && docker build --file $BUILD_CONTEXT/$ARCH/Dockerfile $TESTING_ARG $BUILD_CONTEXT
    # Build release stage and push to ECR
    - docker build $BUILD_ARG --file $BUILD_CONTEXT/$ARCH/Dockerfile --pull --tag $TARGET_TAG $BUILD_CONTEXT
    - docker push $TARGET_TAG

.docker_build_job_definition_amd64: &docker_build_job_definition_amd64
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker:v1907756-26d65dc-18.09.6
  tags: ["runner:docker", "size:large"]
  variables:
    ARCH: amd64

.docker_build_job_definition_arm64: &docker_build_job_definition_arm64
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker:v1903032-53399bc-18.09.6-arm64
  tags: ["runner:docker-arm", "platform:arm64"]
  variables:
    ARCH: arm64

# build agent6 py2 image
docker_build_agent6:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: agent_deb-x64-a6
      artifacts: false
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

docker_build_agent6_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs:
    - job: agent_deb-arm-a6
      artifacts: false
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb

# build agent6 py2 jmx image
docker_build_agent6_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: agent_deb-x64-a6
      artifacts: false
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    BUILD_ARTIFACT_GLOB: datadog-agent_6*_amd64.deb
    TAG_SUFFIX: -6-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

# build agent6 py2 jmx image
docker_build_agent6_jmx_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs:
    - job: agent_deb-arm-a6
      artifacts: false
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    BUILD_ARTIFACT_GLOB: datadog-agent_6*arm64.deb
    TAG_SUFFIX: -6-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=2 --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*arm64.deb

# TESTING ONLY: This image is for internal testing purposes, not customer facing.
# build agent6 jmx unified image (including python3)
docker_build_agent6_py2py3_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: agent_deb-x64-a6
      artifacts: false
  <<: *skip_when_unwanted_on_6
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -6-py2py3-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg DD_AGENT_ARTIFACT=datadog-agent_6*_amd64.deb

# build agent7 image
docker_build_agent7:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: agent_deb-x64-a7
      artifacts: false
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb

docker_build_agent7_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs:
    - job: agent_deb-arm-a7
      artifacts: false
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --target release --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb
    TESTING_ARG:  --target testing --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb

# build agent7 jmx image
docker_build_agent7_jmx:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: agent_deb-x64-a7
      artifacts: false
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_amd64.deb

docker_build_agent7_jmx_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs:
    - job: agent_deb-arm-a7
      artifacts: false
  <<: *skip_when_unwanted_on_7
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --target release --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb
    TESTING_ARG:  --target testing --build-arg WITH_JMX=true --build-arg PYTHON_VERSION=3 --build-arg DD_AGENT_ARTIFACT=datadog-agent_7*_arm64.deb

# build agent7_windows image
docker_build_agent7_windows1809:
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  needs:
    - windows_msi_x64-a7
  <<: *skip_when_unwanted_on_7
  tags: ["runner:windows-docker", "windowsversion:1809"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --build-arg BASE_IMAGE=mcr.microsoft.com/powershell:windowsservercore-1809 --build-arg WITH_JMX=false
  script:
    - $ErrorActionPreference = "Stop"
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $TARGET_TAG = "${IMAGE}:v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}${TAG_SUFFIX}-win1809-amd64"
    - cp ${OMNIBUS_PACKAGE_DIR}/datadog-agent-7*-x86_64.zip ${BUILD_CONTEXT}/datadog-agent-7-latest.amd64.zip
    - powershell -Command "docker build ${BUILD_ARG} --pull --file ${BUILD_CONTEXT}/windows/amd64/Dockerfile --tag ${TARGET_TAG} ${BUILD_CONTEXT}"
    - docker push ${TARGET_TAG}
    - docker rmi ${TARGET_TAG}
  after_script:
    - docker image prune -f # Dangling images
    - docker builder prune -a -f # Build cache

docker_build_agent7_windows1809_jmx:
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  needs:
    - windows_msi_x64-a7
  <<: *skip_when_unwanted_on_7
  tags: ["runner:windows-docker", "windowsversion:1809"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --build-arg BASE_IMAGE=mcr.microsoft.com/powershell:windowsservercore-1809 --build-arg WITH_JMX=true
  script:
    - $ErrorActionPreference = "Stop"
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $TARGET_TAG = "${IMAGE}:v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}${TAG_SUFFIX}-win1809-amd64"
    - cp ${OMNIBUS_PACKAGE_DIR}/datadog-agent-7*-x86_64.zip ${BUILD_CONTEXT}/datadog-agent-7-latest.amd64.zip
    - powershell -Command "docker build ${BUILD_ARG} --pull --file ${BUILD_CONTEXT}/windows/amd64/Dockerfile --tag ${TARGET_TAG} ${BUILD_CONTEXT}"
    - docker push ${TARGET_TAG}
    - docker rmi ${TARGET_TAG}
  after_script:
    - docker image prune -f # Dangling images
    - docker builder prune -a -f # Build cache

# build agent7_windows image
docker_build_agent7_windows1909:
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  needs:
    - windows_msi_x64-a7
  <<: *skip_when_unwanted_on_7
  tags: ["runner:windows-docker", "windowsversion:1909"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7
    BUILD_ARG: --build-arg BASE_IMAGE=mcr.microsoft.com/powershell:windowsservercore-1909 --build-arg WITH_JMX=false
  script:
    - $ErrorActionPreference = "Stop"
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $TARGET_TAG = "${IMAGE}:v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}${TAG_SUFFIX}-win1909-amd64"
    - cp ${OMNIBUS_PACKAGE_DIR}/datadog-agent-7*-x86_64.zip ${BUILD_CONTEXT}/datadog-agent-7-latest.amd64.zip
    - powershell -Command "docker build ${BUILD_ARG} --pull --file ${BUILD_CONTEXT}/windows/amd64/Dockerfile --tag ${TARGET_TAG} ${BUILD_CONTEXT}"
    - docker push ${TARGET_TAG}
    - docker rmi ${TARGET_TAG}
  after_script:
    - docker image prune -f # Dangling images
    - docker builder prune -a -f # Build cache

docker_build_agent7_windows1909_jmx:
  stage: image_build
  before_script: [ "# noop" ] # Override top level entry
  needs:
    - windows_msi_x64-a7
  <<: *skip_when_unwanted_on_7
  tags: ["runner:windows-docker", "windowsversion:1909"]
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    BUILD_CONTEXT: Dockerfiles/agent
    TAG_SUFFIX: -7-jmx
    BUILD_ARG: --build-arg BASE_IMAGE=mcr.microsoft.com/powershell:windowsservercore-1909 --build-arg WITH_JMX=true
  script:
    - $ErrorActionPreference = "Stop"
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $TARGET_TAG = "${IMAGE}:v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}${TAG_SUFFIX}-win1909-amd64"
    - cp ${OMNIBUS_PACKAGE_DIR}/datadog-agent-7*-x86_64.zip ${BUILD_CONTEXT}/datadog-agent-7-latest.amd64.zip
    - powershell -Command "docker build ${BUILD_ARG} --pull --file ${BUILD_CONTEXT}/windows/amd64/Dockerfile --tag ${TARGET_TAG} ${BUILD_CONTEXT}"
    - docker push ${TARGET_TAG}
    - docker rmi ${TARGET_TAG}
  after_script:
    - docker image prune -f # Dangling images
    - docker builder prune -a -f # Build cache

# build the cluster-agent image
build_cluster_agent_amd64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: cluster_agent-build_amd64
      artifacts: false
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
    BUILD_CONTEXT: Dockerfiles/cluster-agent

build_cluster_agent_arm64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_arm64
  needs:
    - job: cluster_agent-build_arm64
      artifacts: false
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
    BUILD_CONTEXT: Dockerfiles/cluster-agent

# build the dogstatsd image
docker_build_dogstatsd_amd64:
  <<: *docker_build_job_definition
  extends: .docker_build_job_definition_amd64
  needs:
    - job: build_dogstatsd_static-deb_x64
      artifacts: false
  variables:
    IMAGE: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    BUILD_CONTEXT: Dockerfiles/dogstatsd/alpine

#
# Docker dev image deployments
#

twistlock_scan-6:
  <<: *skip_when_unwanted_on_6
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/twistlock-cli:2.5.121
  dependencies: [] # Don't download Gitlab artefacts
  allow_failure: true # Don't block the pipeline
  variables:
    SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - export DOCKER_CLIENT_ADDRESS=$DOCKER_HOST
    - TWISTLOCK_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.twistlock_password --with-decryption --query "Parameter.Value" --out text)
    - scan () { echo -e "\n==== Scanning $1 ====\n"; docker pull $1 > /dev/null; /twistcli images scan --address="$TWISTLOCK_URL" --user="$TWISTLOCK_USER" --password="$TWISTLOCK_PASS" --vulnerability-threshold=$THRESHOLD --details $1; }
  script:
    - scan ${SRC_AGENT}:${SRC_TAG}-6-amd64
    - scan ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64
    - scan ${SRC_DSD}:${SRC_TAG}-amd64
    - scan ${SRC_DCA}:${SRC_TAG}-amd64

twistlock_scan-7:
  <<: *skip_when_unwanted_on_7
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/twistlock-cli:2.5.121
  dependencies: [] # Don't download Gitlab artefacts
  allow_failure: true # Don't block the pipeline
  variables:
    SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
    SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
    SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - export DOCKER_CLIENT_ADDRESS=$DOCKER_HOST
    - TWISTLOCK_PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.twistlock_password --with-decryption --query "Parameter.Value" --out text)
    - scan () { echo -e "\n==== Scanning $1 ====\n"; docker pull $1 > /dev/null; /twistcli images scan --address="$TWISTLOCK_URL" --user="$TWISTLOCK_USER" --password="$TWISTLOCK_PASS" --vulnerability-threshold=$THRESHOLD --details $1; }
  script:
    - scan ${SRC_AGENT}:${SRC_TAG}-7-amd64
    - scan ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64

.docker_hub_variables: &docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: docker_hub_login
  DOCKER_REGISTRY_PWD_SSM_KEY: docker_hub_pwd
  DELEGATION_KEY_SSM_KEY: docker_hub_signing_key
  DELEGATION_PASS_SSM_KEY: docker_hub_signing_pass
  DOCKER_REGISTRY_URL: docker.io
  SRC_AGENT: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/agent
  SRC_DSD: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/dogstatsd
  SRC_DCA: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent/cluster-agent

.quay_variables: &quay_variables
  <<: *docker_hub_variables
  DOCKER_REGISTRY_LOGIN_SSM_KEY: quay_login
  DOCKER_REGISTRY_PWD_SSM_KEY: quay_pwd
  DOCKER_REGISTRY_URL: quay.io

.docker_tag_job_definition: &docker_tag_job_definition
  stage: image_deploy
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker-notary:v1912023-8c8dc1c-0.6.1
  variables:
    <<: *docker_hub_variables
  before_script:
    - export SRC_TAG=v$CI_PIPELINE_ID-${CI_COMMIT_SHA:0:7}
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text | docker login --username "$DOCKER_REGISTRY_LOGIN" --password-stdin "$DOCKER_REGISTRY_URL"
    - pip install -r requirements.txt
    - if [[ -z "$DELEGATION_PASS_SSM_KEY" ]]; then echo "No signing key set"; exit 0; fi
    - echo "Importing delegation signing key"
    - export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_PASS_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - export NOTARY_AUTH=$(echo "$DOCKER_REGISTRY_LOGIN:$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text)" | base64)
    - export NOTARY_DELEGATION_PASSPHRASE="$DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE"
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DELEGATION_KEY_SSM_KEY --with-decryption --query "Parameter.Value" --out text > /tmp/docker.key
    - notary -d ~/.docker/trust key import /tmp/docker.key; rm /tmp/docker.key

.docker_tag_windows_job_definition: &docker_tag_windows_job_definition
  stage: image_deploy
  variables:
    <<: *docker_hub_variables
  before_script:
    - $SHORT_CI_COMMIT_SHA = ${CI_COMMIT_SHA}.Substring(0,7)
    - $SRC_TAG = "v${CI_PIPELINE_ID}-${SHORT_CI_COMMIT_SHA}"
    - mkdir ci-scripts
    - |
      @"
      Set-PSDebug -Trace 1
      `$ErrorActionPreference = "Stop"
      # ECR Login
      `$AWS_ECR_PASSWORD = aws ecr get-login-password --region us-east-1
      docker login --username AWS --password "`${AWS_ECR_PASSWORD}" 486234852809.dkr.ecr.us-east-1.amazonaws.com
      # DockerHub login
      `$DOCKER_REGISTRY_LOGIN = aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.${DOCKER_REGISTRY_LOGIN_SSM_KEY} --with-decryption --query "Parameter.Value" --out text
      `$DOCKER_REGISTRY_PWD = aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.${DOCKER_REGISTRY_PWD_SSM_KEY} --with-decryption --query "Parameter.Value" --out text
      docker login --username "`${DOCKER_REGISTRY_LOGIN}" --password "`${DOCKER_REGISTRY_PWD}" "${DOCKER_REGISTRY_URL}"
      # DockerHub image signing
      `$Env:DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE = aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.${DELEGATION_PASS_SSM_KEY} --with-decryption --query "Parameter.Value" --out text
      `$Env:NOTARY_DELEGATION_PASSPHRASE = `$Env:DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE
      `$Env:NOTARY_AUTH = "`${DOCKER_REGISTRY_LOGIN}:`${DOCKER_REGISTRY_PWD}"
      `$bytes = [System.Text.Encoding]::Unicode.GetBytes(`$Env:NOTARY_AUTH)
      `$Env:NOTARY_AUTH = [Convert]::ToBase64String(`$bytes)
      aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.${DELEGATION_KEY_SSM_KEY} --with-decryption --query "Parameter.Value" --out text | Set-Content -Encoding ASCII docker.key
      docker trust key load `$PWD\docker.key
      Remove-Item `$PWD\docker.key
      "@ | out-file ci-scripts/docker-publish.ps1
  after_script:
    - cat ci-scripts/docker-publish.ps1
    - docker run --rm -w C:\mnt -e IS_AWS_CONTAINER=true -e SIGN_WINDOWS=true -v "$(Get-Location):C:\mnt" -v \\.\pipe\docker_engine:\\.\pipe\docker_engine 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/windows_${Env:VARIANT}_x64:${Env:DATADOG_AGENT_WINBUILDERS} powershell -C C:\mnt\ci-scripts\docker-publish.ps1

dev_branch_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
  - docker_build_agent6
  - docker_build_agent6_jmx
  - docker_build_agent6_py2py3_jmx
  when: manual
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-py2py3-jmx-amd64  datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2py3-jmx

dev_branch_docker_hub-dogstatsd:
  <<: *docker_tag_job_definition
  needs:
    - docker_build_dogstatsd_amd64
  when: manual
  script:
  - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64                 datadog/dogstatsd-dev:${CI_COMMIT_REF_SLUG}

dev_branch_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - docker_build_agent7
    - docker_build_agent7_jmx
  when: manual
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64             datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64         datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx

dev_branch_docker_hub-a7-windows:
  <<: *skip_when_unwanted_on_7
  extends: .docker_tag_windows_job_definition
  variables:
    VARIANT: 1909
  tags: ["runner:windows-docker", "windowsversion:1909"]
  needs:
    - docker_build_agent7_windows1809
    - docker_build_agent7_windows1809_jmx
    - docker_build_agent7_windows1909
    - docker_build_agent7_windows1909_jmx
  when: manual
  script:
    - |
      @"
      # On newer Kernel we can pull/push older images even though these images won't run
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1809-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1809-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1909-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-win1909
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1909-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx-win1909

      inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3-win --image datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-win1809,windows/amd64 --image datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-win1909,windows/amd64
      inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3-jmx-win --image datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx-win1809,windows/amd64 --image datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3-jmx-win1909,windows/amd64
      "@ | Add-Content ci-scripts/docker-publish.ps1

dev_branch_multiarch_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
    - docker_build_agent6
    - docker_build_agent6_arm64
    - docker_build_agent6_jmx
    - docker_build_agent6_jmx_arm64
    - docker_build_agent6_py2py3_jmx
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-jmx
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py2-jmx
    # Other images
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-py2py3-jmx-amd64 datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2py3-jmx
    # Manifests
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG} --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG},linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py2 --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG}-py2,linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG}-py2,linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-jmx --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG}-jmx,linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG}-jmx,linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py2-jmx --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG}-py2-jmx,linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG}-py2-jmx,linux/arm64

dev_branch_multiarch_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - docker_build_agent7
    - docker_build_agent7_arm64
    - docker_build_agent7_jmx
    - docker_build_agent7_jmx_arm64
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-ARCH      --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-ARCH  --dst-template datadog/agent-dev-ARCH:${CI_COMMIT_REF_SLUG}-py3-jmx
    # Manifests
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3 --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG}-py3,linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG}-py3,linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag ${CI_COMMIT_REF_SLUG}-py3-jmx --image datadog/agent-dev-amd64:${CI_COMMIT_REF_SLUG}-py3-jmx,linux/amd64 --image datadog/agent-dev-arm64:${CI_COMMIT_REF_SLUG}-py3-jmx,linux/arm64

dev_branch_multiarch_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - docker_build_dogstatsd_amd64
  when: manual
  script:
    # Platform-specific agent images
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd-dev:${CI_COMMIT_REF_SLUG}

dev_master_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  needs:
    - docker_build_agent6
    - docker_build_agent6_jmx
    - docker_build_agent6_py2py3_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:master-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:master-py2-jmx

dev_master_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - docker_build_agent7
    - docker_build_agent7_jmx
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64       datadog/agent-dev:master-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64   datadog/agent-dev:master-py3-jmx

dev_master_docker_hub-a7-windows:
  <<: *skip_when_unwanted_on_7
  extends: .docker_tag_windows_job_definition
  variables:
    VARIANT: 1909
  tags: ["runner:windows-docker", "windowsversion:1909"]
  needs:
    - docker_build_agent7_windows1809
    - docker_build_agent7_windows1809_jmx
    - docker_build_agent7_windows1909
    - docker_build_agent7_windows1909_jmx
  only:
    - master
  script:
    - |
      @"
      # On newer Kernel we can pull/push older images even though these images won't run
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1809-amd64 datadog/agent-dev:master-py3-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1809-amd64 datadog/agent-dev:master-py3-jmx-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1909-amd64 datadog/agent-dev:master-py3-win1909
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1909-amd64 datadog/agent-dev:master-py3-jmx-win1909

      inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag datadog/agent-dev:master-py3-win --image datadog/agent-dev:master-py3-win1809,windows/amd64 --image datadog/agent-dev:master-py3-win1909,windows/amd64
      inv -e docker.publish-manifest --signed-push --name datadog/agent-dev --tag datadog/agent-dev:master-py3-jmx-win --image datadog/agent-dev:master-py3-jmx-win1809,windows/amd64 --image datadog/agent-dev:master-py3-jmx-win1909,windows/amd64
      "@ | Add-Content ci-scripts/docker-publish.ps1
    - cat ci-scripts/docker-publish.ps1

dev_master_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  needs:
    - docker_build_dogstatsd_amd64
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64           datadog/dogstatsd-dev:master

dca_dev_branch_docker_hub:
  <<: *docker_tag_job_definition
  needs:
    - build_cluster_agent_amd64
  when: manual
  except:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DCA}:${SRC_TAG}-amd64 datadog/cluster-agent-dev:${CI_COMMIT_REF_SLUG}

dca_dev_branch_multiarch_docker_hub:
  <<: *docker_tag_job_definition
  needs:
    - build_cluster_agent_amd64
    - build_cluster_agent_arm64
  when: manual
  except:
    - master
  script:
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_DCA}:${SRC_TAG}-ARCH --dst-template datadog/cluster-agent-dev-ARCH:${CI_COMMIT_REF_SLUG}
    - inv -e docker.publish-manifest --signed-push --name datadog/cluster-agent-dev --tag ${CI_COMMIT_REF_SLUG} --image datadog/cluster-agent-dev-amd64:${CI_COMMIT_REF_SLUG},linux/amd64 --image datadog/cluster-agent-dev-arm64:${CI_COMMIT_REF_SLUG},linux/arm64

dca_dev_master_docker_hub:
  <<: *docker_tag_job_definition
  needs: ["build_cluster_agent_amd64"]
  only:
    - master
  script:
    - inv -e docker.publish --signed-push ${SRC_DCA}:${SRC_TAG}-amd64 datadog/cluster-agent-dev:master

# deploys nightlies to agent-dev
dev_nightly_docker_hub-a6:
  <<: *skip_when_unwanted_on_6
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_nightly
  needs:
    - docker_build_agent6
    - docker_build_agent6_jmx
    - docker_build_agent6_py2py3_jmx
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py2
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-jmx
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-6-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py2-jmx

# deploys nightlies to agent-dev
dev_nightly_docker_hub-a7:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_nightly
  needs:
    - docker_build_agent7
    - docker_build_agent7_jmx
  script:
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-amd64       datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3
    - inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-amd64   datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-jmx

dev_nightly_docker_hub-a7-windows:
  <<: *skip_when_unwanted_on_7
  <<: *run_only_when_triggered_on_nightly
  extends: .docker_tag_windows_job_definition
  variables:
    VARIANT: 1909
  tags: ["runner:windows-docker", "windowsversion:1909"]
  needs:
    - docker_build_agent7_windows1809
    - docker_build_agent7_windows1809_jmx
    - docker_build_agent7_windows1909
    - docker_build_agent7_windows1909_jmx
  script:
    - |
      @"
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1809-amd64 datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1809-amd64 datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-jmx-win1809
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-win1909-amd64 datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-win1909
      inv -e docker.publish --signed-push ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1909-amd64 datadog/agent-dev:nightly-${CI_COMMIT_SHORT_SHA}-py3-jmx-win1909
      "@ | Add-Content ci-scripts/docker-publish.ps1

# deploys nightlies to agent-dev
dev_nightly_docker_hub-dogstatsd:
  <<: *skip_when_unwanted_on_7
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_nightly
  needs:
    - docker_build_dogstatsd_amd64
  script:
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64           datadog/dogstatsd-dev:nightly-${CI_COMMIT_SHORT_SHA}
#
# Check Deploy
#

# Check that the current version hasn't already been deployed (we don't want to
# overwrite a public package). To update an erroneous package, first remove it
# from our S3 bucket.
check_already_deployed_version_6:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a6
    - agent_deb-arm-a6
  script:
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_6*_amd64.deb
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_6*_arm64.deb

check_already_deployed_version_7:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a7
    - agent_deb-arm-a7
  script:
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_7*_amd64.deb
    - cd $OMNIBUS_PACKAGE_DIR && /deploy_scripts/fail_deb_is_pkg_already_exists.sh datadog-agent_7*_arm64.deb

# If we trigger a build only pipeline we stop here.
check_if_build_only:
  <<: *run_only_when_triggered
  stage: check_deploy
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  script:
    - if [ "$DEB_RPM_BUCKET_BRANCH" == "none" ]; then echo "Stopping pipeline"; exit 1; fi

#
# deploy
#

# deploy debian packages to apt staging repo
deploy_staging_deb-6:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  resource_group: deb_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a6
    - agent_deb-arm-a6
  script:
    # We first check that the current version hasn't already been deployed
    # (same as the check_already_deployed_version). We do this twice to mitigate
    # races and issues with retries while failing early if there is an issue.
    - pushd $OMNIBUS_PACKAGE_DIR
    - /deploy_scripts/fail_deb_is_pkg_already_exists.sh *_6.*amd64.deb
    - popd
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    # Release the artifacts to the "6" component
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 6 -b $DEB_S3_BUCKET -a arm64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_6.*arm64.deb

deploy_staging_deb-7:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  resource_group: deb_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a7
    - agent_deb-arm-a7
    - iot_agent_deb-x64
    - iot_agent_deb-arm64
    - dogstatsd_deb-x64
  script:
    # We first check that the current version hasn't already been deployed
    # (same as the check_already_deployed_version). We do this twice to mitigate
    # races and issues with retries while failing early if there is an issue.
    - pushd $OMNIBUS_PACKAGE_DIR
    - /deploy_scripts/fail_deb_is_pkg_already_exists.sh *_7.*amd64.deb
    - popd
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4

    - set +x # make sure we don't output the creds to the build log

    - APT_SIGNING_KEY_ID=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_id --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART1=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part1 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_PRIVATE_KEY_PART2=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_private_key_part2 --with-decryption --query "Parameter.Value" --out text)
    - APT_SIGNING_KEY_PASSPHRASE=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.apt_signing_key_passphrase --with-decryption --query "Parameter.Value" --out text)

    - echo "$APT_SIGNING_KEY_ID"
    - printf -- "$APT_SIGNING_PRIVATE_KEY_PART1\n$APT_SIGNING_PRIVATE_KEY_PART2\n" | gpg --import --batch

    # Release the artifacts to the "7" component
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a amd64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a x86_64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*amd64.deb
    - echo "$APT_SIGNING_KEY_PASSPHRASE" | deb-s3 upload -c $DEB_RPM_BUCKET_BRANCH -m 7 -b $DEB_S3_BUCKET -a arm64 --sign=$APT_SIGNING_KEY_ID --gpg_options="--passphrase-fd 0 --pinentry-mode loopback --batch --digest-algo SHA512" --preserve_versions --visibility public $OMNIBUS_PACKAGE_DIR/*_7.*arm64.deb

# nightlies (6), deployed to bucket/master
deploy_staging_windows_master-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a6
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies (7 and dogstatsd), deployed to bucket/master
deploy_staging_windows_master-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a7
    - windows_dsd_msi_x64-a7
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-dogstatsd-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/master/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies latest (6), deployed to bucket/master
deploy_staging_windows_master-latest-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_6
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a6
  script:
    - $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-6*-x86_64.msi "s3://$WINDOWS_BUILDS_S3_BUCKET/master/datadog-agent-6-latest.amd64.msi" --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# nightlies latest (7), deployed to bucket/master
deploy_staging_windows_master-latest-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_nightly
  <<: *skip_when_unwanted_on_7
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a7
    - windows_dsd_msi_x64-a7
  script:
    - $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-7*-x86_64.msi "s3://$WINDOWS_BUILDS_S3_BUCKET/master/datadog-agent-7-latest.amd64.msi" --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds (6), deployed to bucket/tagged
deploy_staging_windows_tags-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_tag_6
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a6
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-6*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds (7), deployed to bucket/tagged
deploy_staging_windows_tags-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_tag_7
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a7
    - windows_dsd_msi_x64-a7
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7*.msi" $OMNIBUS_PACKAGE_DIR s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# triggered builds latest (6, x64 only), deployed to bucket/tagged
deploy_staging_windows_tags-latest-a6:
  stage: deploy6
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_tag_6
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a6
  script:
    # By default we update the "latest" artifacts on our s3 bucket so the
    # staging box can pick it up. Allow the job to skip this step if needed
    # (when building a custom beta for example).
    - if [ "WINDOWS_DO_NOT_UPDATE_LATEST" != "true" ]; then $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-6*-x86_64.msi s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/datadog-agent-6-latest.amd64.msi --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732; fi

# triggered builds latest (7, x64 only), deployed to bucket/tagged
deploy_staging_windows_tags-latest-a7:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  <<: *run_only_when_triggered_on_tag_7
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - windows_msi_x64-a7
    - windows_dsd_msi_x64-a7
  script:
    # By default we update the "latest" artifacts on our s3 bucket so the
    # staging box can pick it up. Allow the job to skip this step if needed
    # (when building a custom beta for example).
    - if [ "WINDOWS_DO_NOT_UPDATE_LATEST" != "true" ]; then $S3_CP_CMD $OMNIBUS_PACKAGE_DIR/datadog-agent-7*-x86_64.msi s3://$WINDOWS_BUILDS_S3_BUCKET/tagged/datadog-agent-7-latest.amd64.msi --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732; fi

# deploy android packages to a public s3 bucket when tagged
deploy_staging_android_tags:
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  # This means this job is never run, but let's keep it around in case we need it one day
  <<: *run_only_when_triggered_on_tag_7
  <<: *skip_when_triggered
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_android_apk
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "*.apk" $OMNIBUS_PACKAGE_DIR s3://$ANDROID_BUILDS_S3_BUCKET/tagged/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy rpm packages to yum staging repo
deploy_staging_rpm-6:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  resource_group: rpm_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_rpm-x64-a6
    - agent_rpm-arm-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "$DEB_RPM_BUCKET_BRANCH/6/x86_64/" $OMNIBUS_PACKAGE_DIR/*-6.*x86_64.rpm
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "$DEB_RPM_BUCKET_BRANCH/6/aarch64/" $OMNIBUS_PACKAGE_DIR/*-6.*aarch64.rpm

deploy_staging_rpm-7:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  resource_group: rpm_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_rpm-x64-a7
    - agent_rpm-arm-a7
    - iot_agent_rpm-x64
    - iot_agent_rpm-arm64
    - dogstatsd_rpm-x64
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "$DEB_RPM_BUCKET_BRANCH/7/x86_64/" $OMNIBUS_PACKAGE_DIR/*-7.*x86_64.rpm
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "$DEB_RPM_BUCKET_BRANCH/7/aarch64/" $OMNIBUS_PACKAGE_DIR/*-7.*aarch64.rpm

# deploy suse rpm packages to yum staging repo
# NOTE: no SuSE ARM builds currently.
deploy_staging_suse_rpm-6:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_6
  stage: deploy6
  resource_group: suse_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_suse-x64-a6
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "suse/$DEB_RPM_BUCKET_BRANCH/6/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/*-6.*x86_64.rpm

deploy_staging_suse_rpm-7:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  resource_group: suse_bucket
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR_SUSE
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_suse-x64-a7
    - dogstatsd_suse-x64
    - iot_agent_suse-x64
  script:
    - source /usr/local/rvm/scripts/rvm
    - rvm use 2.4
    - rpm-s3 --verbose --visibility public-read -c "https://s3.amazonaws.com" -b $RPM_S3_BUCKET -p "suse/$DEB_RPM_BUCKET_BRANCH/7/x86_64/" $OMNIBUS_PACKAGE_DIR_SUSE/*-7.*x86_64.rpm

# deploy dsd binary to staging bucket
deploy_staging_dsd:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  script:
    - $S3_CP_CMD $S3_ARTIFACTS_URI/dogstatsd/dogstatsd ./dogstatsd
    - export PACKAGE_VERSION=$(inv agent.version --url-safe --major-version 7)
    - aws s3 cp --region us-east-1 ./dogstatsd $S3_DSD6_URI/linux/dogstatsd-$PACKAGE_VERSION --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy iot-agent binary to staging bucket
deploy_staging_iot_agent:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  script:
    - $S3_CP_CMD $S3_ARTIFACTS_URI/iot/agent ./agent
    - export PACKAGE_VERSION=$(inv agent.version --url-safe --major-version 7)
    - aws s3 cp --region us-east-1 ./agent $S3_DSD6_URI/linux/iot/agent-$PACKAGE_VERSION --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy agent windows zip to the staging bucket, currently used for cloudfoundry bosh
deploy_staging_datadog_agent_windows_zip:
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7
  dependencies: [ "windows_msi_x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-agent-7.*.zip" $OMNIBUS_PACKAGE_DIR $S3_DSD6_URI/windows/agent7/bosh/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

deploy_cluster_agent_cloudfoundry:
  <<: *run_only_when_triggered
  <<: *skip_when_unwanted_on_7
  stage: deploy7
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  dependencies:
    - cluster_agent_cloudfoundry-build_amd64
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "datadog-cluster-agent-cloudfoundry-*.tar.xz" $OMNIBUS_PACKAGE_DIR $S3_DSD6_URI/linux/cluster-agent-cloudfoundry/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy datadog agent windows binaries to staging bucket. Currently used for cloudfoundry builpack
deploy_staging_datadog_agent_windows_binaries_zip:
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7
  dependencies: [ "windows_zip_agent_binaries_x64-a7"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - ls $OMNIBUS_PACKAGE_DIR
  tags: [ "runner:main", "size:large" ]
  script:
    - $S3_CP_CMD --recursive --exclude "*" --include "agent-binaries-7.*.zip" $OMNIBUS_PACKAGE_DIR $S3_DSD6_URI/windows/agent7/buildpack/ --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=3a6e02b08553fd157ae3fb918945dd1eaae5a1aa818940381ef07a430cf25732

# deploy process agent and system-probe to staging bucket
deploy_staging_process_and_sysprobe:
  stage: internal_deploy
  when: manual
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  before_script:
    - cd $OMNIBUS_PACKAGE_DIR
    - ls
  tags: [ "runner:main", "size:large" ]
  dependencies:
    - agent_deb-x64-a7
  script:
    # The shell expansion `datadog-agent_*_amd64.deb` might return multiple
    # entries, so we sort them and get the first one.
    - dpkg -x $(ls -1 datadog-agent_*_amd64.deb | sort -V | head -n 1) ./out
    # Use tag or shortened branch with short commit hash to identify the binary
    - export SHORT_REF=$(echo $CI_COMMIT_REF_NAME | cut -d'/' -f2- | cut -c -10 | sed -E 's/[^[:alnum:]]+/-/g')
    - export NAME="${CI_COMMIT_TAG:-$SHORT_REF}-${CI_COMMIT_SHA:0:7}"
    - echo "Uploading with name=$NAME"
    - $S3_CP_CMD ./out/opt/datadog-agent/embedded/bin/process-agent s3://$PROCESS_S3_BUCKET/process-agent-amd64-$NAME --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=612548d92af7fa77f7ad7bcab230494f7310438ac6332e904a8fb2e6daa5cb23
    - $S3_CP_CMD ./out/opt/datadog-agent/embedded/bin/system-probe s3://$PROCESS_S3_BUCKET/system-probe-amd64-$NAME --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers full=id=612548d92af7fa77f7ad7bcab230494f7310438ac6332e904a8fb2e6daa5cb23

#
# Docker releases
#

tag_release_6:
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_tag_6
  stage: deploy6
  when: manual
  dependencies:
    - docker_build_agent6
    - docker_build_agent6_arm64
    - docker_build_agent6_jmx
    - docker_build_agent6_jmx_arm64
  script:
    - VERSION=$(inv -e agent.version --major-version 6)
    # Platform-specific agent images
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-ARCH      --dst-template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-6-jmx-ARCH  --dst-template datadog/agent-ARCH:${VERSION}-jmx
    # Manifests
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag ${VERSION} --image datadog/agent-amd64:${VERSION},linux/amd64 --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag ${VERSION}-jmx  --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64 --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64

latest_release_6:
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_tag_6
  stage: deploy6
  when: manual
  dependencies:
    - docker_build_agent6
    - docker_build_agent6_arm64
    - docker_build_agent6_jmx
    - docker_build_agent6_jmx_arm64
  script:
    - VERSION=$(inv -e agent.version --major-version 6)
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-py2 --image datadog/agent-amd64:${VERSION},linux/amd64 --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-py2-jmx --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64 --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag 6 --image datadog/agent-amd64:${VERSION},linux/amd64 --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag 6-jmx --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64 --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64

tag_release_7_linux:
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7
  when: manual
  dependencies:
    - docker_build_agent7
    - docker_build_agent7_arm64
    - docker_build_agent7_jmx
    - docker_build_agent7_jmx_arm64
    - docker_build_dogstatsd_amd64
  script:
    - VERSION=$(inv -e agent.version --major-version 7)
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-ARCH      --dst-template datadog/agent-ARCH:${VERSION}
    - inv -e docker.publish-bulk --signed-push --platform linux/amd64 --platform linux/arm64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-ARCH  --dst-template datadog/agent-ARCH:${VERSION}-jmx
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:${VERSION}

tag_release_7_windows:
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7
  when: manual
  extends: .docker_tag_windows_job_definition
  variables:
    VARIANT: 1909
  tags: ["runner:windows-docker", "windowsversion:1909"]
  dependencies:
    - docker_build_agent7_windows1809
    - docker_build_agent7_windows1809_jmx
    - docker_build_agent7_windows1909
    - docker_build_agent7_windows1909_jmx
  script:
    - |
      @"
      `$VERSION = inv -e agent.version --major-version 7
      inv -e docker.publish-bulk --signed-push --platform windows/amd64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-win1809-ARCH --dst-template datadog/agent-ARCH:`${VERSION}-win1809
      inv -e docker.publish-bulk --signed-push --platform windows/amd64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1809-ARCH --dst-template datadog/agent-ARCH:`${VERSION}-jmx-win1809
      inv -e docker.publish-bulk --signed-push --platform windows/amd64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-win1909-ARCH --dst-template datadog/agent-ARCH:`${VERSION}-win1909
      inv -e docker.publish-bulk --signed-push --platform windows/amd64 --src-template ${SRC_AGENT}:${SRC_TAG}-7-jmx-win1909-ARCH --dst-template datadog/agent-ARCH:`${VERSION}-jmx-win1909
      "@ | Add-Content ci-scripts/docker-publish.ps1

tag_release_7_manifests:
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7-manifests
  when: manual
  # HACK: a job should not depend on manual jobs, otherwise it blocks
  # the next stages of the pipeline until said manual jobs are run
  # (the job remains in a pending state until all its dependencies
  # are run).
  # However, this job implicitly still needs both of the below jobs,
  # and thus should be run after these two manual jobs.
  # needs:
  #   - tag_release_7_linux
  #   - tag_release_7_windows
  dependencies: []
  script:
    - VERSION=$(inv -e agent.version --major-version 7)
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag ${VERSION}
      --image datadog/agent-amd64:${VERSION},linux/amd64
      --image datadog/agent-amd64:${VERSION}-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag ${VERSION}-jmx
      --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64

latest_release_7:
  <<: *docker_tag_job_definition
  <<: *run_only_when_triggered_on_tag_7
  stage: deploy7
  when: manual
  dependencies:
    - docker_build_agent7
    - docker_build_agent7_arm64
    - docker_build_agent7_jmx
    - docker_build_agent7_jmx_arm64
    - docker_build_dogstatsd_amd64
    - docker_build_agent7_windows1809
    - docker_build_agent7_windows1809_jmx
    - docker_build_agent7_windows1909
    - docker_build_agent7_windows1909_jmx
  script:
    - VERSION=$(inv -e agent.version --major-version 7)
    # Dogstatsd
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:latest
    - inv -e docker.publish --signed-push ${SRC_DSD}:${SRC_TAG}-amd64 datadog/dogstatsd:7
    # Manifests
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest
      --image datadog/agent-amd64:${VERSION},linux/amd64
      --image datadog/agent-amd64:${VERSION}-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-jmx
      --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag 7
      --image datadog/agent-amd64:${VERSION},linux/amd64
      --image datadog/agent-amd64:${VERSION}-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag 7-jmx
      --image datadog/agent-amd64:${VERSION}-jmx,linux/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1809,windows/amd64
      --image datadog/agent-amd64:${VERSION}-jmx-win1909,windows/amd64
      --image datadog/agent-arm64:${VERSION}-jmx,linux/arm64

#
# Use these steps to revert the latest tags to a previous release
# while maintaining content trust signatures
# - remove the leading dot from the name
# - set the RELEASE envvar
# - in the gitlab pipeline view, trigger the step (in the first column)
#

.latest_revert_to_previous_release_6:
  <<: *docker_tag_job_definition
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    RELEASE: ""  # tag name of the non-jmx version, for example "6.9.0"
  script:
    - if [[ -z "$RELEASE" ]]; then echo "Need release version to revert to"; exit 1; fi
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-py2 --image datadog/agent-amd64:${RELEASE},linux/amd64 --image datadog/agent-arm64:${RELEASE},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-py2-jmx --image datadog/agent-amd64:${RELEASE}-jmx,linux/amd64 --image datadog/agent-arm64:${RELEASE}-jmx,linux/arm64

.latest_revert_to_previous_release_7:
  <<: *docker_tag_job_definition
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    RELEASE: ""  # tag name of the non-jmx version, for example "6.9.0"
  script:
    - if [[ -z "$RELEASE" ]]; then echo "Need release version to revert to"; exit 1; fi
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest --image datadog/agent-amd64:${RELEASE},linux/amd64 --image datadog/agent-arm64:${RELEASE},linux/arm64
    - inv -e docker.publish-manifest --signed-push --name datadog/agent --tag latest-jmx --image datadog/agent-amd64:${RELEASE}-jmx,linux/amd64 --image datadog/agent-arm64:${RELEASE}-jmx,linux/arm64
    - inv -e docker.publish --signed-pull --signed-push datadog/dogstatsd:${RELEASE} datadog/dogstatsd:latest

#
# Use this step to delete a tag of a given image
# We call the Docker Hub API because docker cli doesn't support deleting tags
# - remove the leading dot from the name
# - set the IMAGE and TAG envvars
# - in the gitlab pipeline view, trigger the step (in the first column)
#
.delete_docker_tag:
  tags: [ "runner:docker", "size:large" ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/docker-notary:0.6.1
  before_script:
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - PASS=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - pip install -r requirements.txt
    - |
      export DOCKER_TOKEN=`curl -s -H "Content-Type: application/json" -X POST -d '{"username": "'$DOCKER_REGISTRY_LOGIN'", "password": "'$PASS'"}' https://hub.docker.com/v2/users/login/ | python -c 'import sys, json; print(json.load(sys.stdin)["token"].strip())'`
  dependencies: [] # Don't download Gitlab artefacts
  stage: source_test
  when: manual
  variables:
    <<: *docker_hub_variables
    IMAGE: ""  # image name, for example "agent"
    TAG: ""  # tag name, for example "6.9.0"
    ORGANIZATION: "datadog"
  script:
    - if [[ -z "$IMAGE" ]]; then echo "Need an image"; exit 1; fi
    - if [[ -z "$TAG" ]]; then echo "Need a tag to delete"; exit 1; fi
    - inv -e docker.delete ${ORGANIZATION} ${IMAGE} ${TAG} ${DOCKER_TOKEN} &>/dev/null

#
# Cloudfront cache invalidation:
# Duplicated in 2 jobs: one that runs "on success" of the previous stage, and one that runs "on failure" of previous stages.
# Compared to having 1 single job that runs "always", this setup guarantees that if earlier stages first failed and were
# then retried successfully, the cloudfront invalidation will also run after the successful retry.
#
.deploy_cloudfront_invalidate: &deploy_cloudfront_invalidate
  <<: *run_only_when_triggered
  stage: deploy_invalidate
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  script:
    - cd /deploy_scripts/cloudfront-invalidation
    - "REPO=apt PATTERN_SUBSTRING=/$DEB_RPM_BUCKET_BRANCH/ ./invalidate.sh"
    - "REPO=yum PATTERN_SUBSTRING=/$DEB_RPM_BUCKET_BRANCH/ ./invalidate.sh"

deploy_cloudfront_invalidate_on_success:
  <<: *deploy_cloudfront_invalidate
  when: on_success

deploy_cloudfront_invalidate_on_failure:
  <<: *deploy_cloudfront_invalidate
  when: on_failure

#
# Trigger release pipelines
#

# The trigger jobs are always run (even on failing pipelines)
# because there's no way to retry a trigger job once it gets skipped
# because of a pipeline failure, even when retrying the pipeline.
trigger_release_7:
  <<: *run_only_when_triggered_on_tag_7
  stage: trigger_release
  variables:
    RELEASE_VERSION: $RELEASE_VERSION_7-1
  trigger:
    project: DataDog/agent-release-management
    branch: master
  when: always

trigger_release_6:
  <<: *run_only_when_triggered_on_tag_6
  stage: trigger_release
  variables:
    RELEASE_VERSION: $RELEASE_VERSION_6-1
  trigger:
    project: DataDog/agent-release-management
    branch: master
  when: always

#
# end to end
#

.pupernetes_template: &pupernetes_template
  stage: e2e
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-builders/deploy:$DATADOG_AGENT_BUILDERS
  tags: [ "runner:main", "size:large" ]
  dependencies: []
  before_script:
  - cd $SRC_PATH
  - pip install --upgrade --ignore-installed pip setuptools
  - pip install -r requirements.txt
  script:
  - inv -e e2e-tests --image=datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py2
  - inv -e e2e-tests --image=datadog/agent-dev:${CI_COMMIT_REF_SLUG}-py3

pupernetes-dev:
  <<: *pupernetes_template
  when: manual
  except:
    - master
    - tags

pupernetes-master:
  <<: *pupernetes_template
  only:
    - master
  script:
  - inv -e e2e-tests --image=datadog/agent-dev:master-py2
  - inv -e e2e-tests --image=datadog/agent-dev:master-py3

pupernetes-tags-6:
  <<: *pupernetes_template
  <<: *run_only_when_triggered_on_tag_6
  when: manual
  script:
  - VERSION=$(inv -e agent.version --major-version 6)
  - inv -e e2e-tests --image=datadog/agent:${VERSION}

pupernetes-tags-7:
  <<: *pupernetes_template
  <<: *run_only_when_triggered_on_tag_7
  when: manual
  script:
  - VERSION=$(inv -e agent.version --major-version 7)
  - inv -e e2e-tests --image=datadog/agent:${VERSION}

notify-on-failure:
  extends: .slack-notifier.on-failure
  dependencies: []
  only:
    - master
    - triggers
  script: |
    BUILD_URL="$CI_PROJECT_URL/pipelines/$CI_PIPELINE_ID"
    COMMIT_URL="$CI_PROJECT_URL/commit/$CI_COMMIT_SHA"

    COMMIT_AUTHOR=$(git show -s --format="%an" HEAD)

    MESSAGE_TEXT=":host-red: $CI_PROJECT_NAME: Pipeline <$BUILD_URL|$CI_PIPELINE_ID> for $CI_COMMIT_REF_NAME failed.
    $CI_COMMIT_TITLE (<$COMMIT_URL|$CI_COMMIT_SHORT_SHA>) by $COMMIT_AUTHOR"
    postmessage "#datadog-agent-pipelines" "$MESSAGE_TEXT"
