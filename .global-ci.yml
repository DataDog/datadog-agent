stages:
  - .pre
  - setup
  - maintenance_jobs
  - deps_build
  - deps_fetch
  - lint
  - source_test
  - source_test_stats
  - software_composition_analysis
  - binary_build
  - package_deps_build
  - kernel_matrix_testing_prepare
  - kernel_matrix_testing_system_probe
  - kernel_matrix_testing_security_agent
  - kernel_matrix_testing_cleanup
  - integration_test
  - benchmarks
  - package_build
  - packaging
  - pkg_metrics
  - container_build
  - container_scan
  - scan
  - check_deploy
  - dev_container_deploy
  - deploy_packages
  - choco_build
  - install_script_deploy
  - internal_image_deploy
  - e2e_deploy
  - install_script_testing
  - e2e_pre_test
  - e2e_init
  - e2e
  - e2e_cleanup
  - e2e_k8s
  - e2e_install_packages
  - functional_test
  - trigger_distribution
  - dynamic_test
  - junit_upload
  - internal_kubernetes_deploy
  - post_rc_build
  - check_merge
  - notify

variables:
  # Special variable that allows us to set the pipeline to compute the code coverage of the e2e tests. It will impact several jobs so that
  # the agent is build with a special flag that allow computing code coverage of the binary when it is running.
  E2E_COVERAGE_PIPELINE: false
  # Directory in which we execute the omnibus build.
  # For an unknown reason, it does not go well with
  # a ruby dependency if we build directly into $CI_PROJECT_DIR/.omnibus
  OMNIBUS_BASE_DIR: /omnibus
  # Directory in which we put the artifacts after the build
  # Must be in $CI_PROJECT_DIR
  OMNIBUS_PACKAGE_DIR: $CI_PROJECT_DIR/omnibus/pkg/
  # Directory in which we put the SUSE artifacts after the SUSE build
  # Must be in $CI_PROJECT_DIR
  # RPM builds and SUSE RPM builds create artifacts with the same name.
  # To differentiate them, we put them in different folders. That also
  # avoids accidentally overwriting files when downloading artifacts from
  # both RPM and SUSE rpm jobs.
  OMNIBUS_PACKAGE_DIR_SUSE: $CI_PROJECT_DIR/omnibus/suse/pkg
  DD_AGENT_TESTING_DIR: $CI_PROJECT_DIR/test/new-e2e/tests
  STATIC_BINARIES_DIR: bin/static
  DOGSTATSD_BINARIES_DIR: bin/dogstatsd
  AGENT_BINARIES_DIR: bin/agent
  CLUSTER_AGENT_BINARIES_DIR: bin/datadog-cluster-agent
  CWS_INSTRUMENTATION_BINARIES_DIR: bin/cws-instrumentation
  CLUSTER_AGENT_CLOUDFOUNDRY_BINARIES_DIR: bin/datadog-cluster-agent-cloudfoundry
  SYSTEM_PROBE_BINARIES_DIR: bin/system-probe
  DEB_S3_BUCKET: apt.datad0g.com
  RPM_S3_BUCKET: yum.datad0g.com
  MACOS_S3_BUCKET: dd-agent-macostesting
  WIN_S3_BUCKET: dd-agent-mstesting
  PROCESS_S3_BUCKET: datad0g-process-agent
  BUCKET_BRANCH: dev # path inside the staging s3 buckets to release to: 'dev', 'nightly', 'oldnightly', 'beta' or 'stable'
  DEB_TESTING_S3_BUCKET: apttesting.datad0g.com
  RPM_TESTING_S3_BUCKET: yumtesting.datad0g.com
  # note the name is TEST_KEYS_URL, not TESTING_KEYS_URL;
  # this is because TESTING_KEYS_URL is a variable used by the install script,
  # and we don't want to modify its behavior inadvertently
  TEST_KEYS_URL: apttesting.datad0g.com/test-keys
  INSTALLER_TESTING_S3_BUCKET: installtesting.datad0g.com
  WINDOWS_TESTING_S3_BUCKET: pipelines/A7/$CI_PIPELINE_ID
  WINDOWS_BUILDS_S3_BUCKET: $WIN_S3_BUCKET/builds
  WINDOWS_POWERSHELL_DIR: $CI_PROJECT_DIR/signed_scripts
  DEB_RPM_TESTING_BUCKET_BRANCH: testing # branch of the DEB_TESTING_S3_BUCKET and RPM_TESTING_S3_BUCKET repos to release to, 'testing'
  S3_CP_OPTIONS: --no-progress --region us-east-1 --sse AES256
  S3_CP_CMD: aws s3 cp $S3_CP_OPTIONS
  S3_ARTIFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME/$CI_PIPELINE_ID
  S3_PROJECT_ARTIFACTS_URI: s3://dd-ci-artefacts-build-stable/$CI_PROJECT_NAME
  S3_PERMANENT_ARTIFACTS_URI: s3://dd-ci-persistent-artefacts-build-stable/$CI_PROJECT_NAME
  S3_SBOM_STORAGE_URI: s3://sbom-root-us1-ddbuild-io/$CI_PROJECT_NAME/$CI_PIPELINE_ID
  S3_RELEASE_ARTIFACTS_URI: s3://dd-release-artifacts/$CI_PROJECT_NAME/$CI_PIPELINE_ID
  S3_RELEASE_INSTALLER_ARTIFACTS_URI: s3://dd-release-artifacts/datadog-installer/$CI_PIPELINE_ID
  ## comment out both lines below (S3_OMNIBUS_CACHE_BUCKET and USE_S3_CACHING) to allow
  ## build to succeed with S3 caching disabled.
  S3_OMNIBUS_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-cache-build-stable
  S3_OMNIBUS_GIT_CACHE_BUCKET: dd-ci-datadog-agent-omnibus-git-cache-build-stable
  # This value is not used on windows, a specific value is provided to
  # our build containers in the windows build jobs
  OMNIBUS_GIT_CACHE_DIR: /tmp/omnibus-git-cache
  ## comment out the line below to disable integration wheels cache
  INTEGRATION_WHEELS_CACHE_BUCKET: dd-agent-omnibus
  S3_DD_AGENT_OMNIBUS_LLVM_URI: s3://dd-agent-omnibus/llvm
  S3_DD_AGENT_OMNIBUS_BTFS_URI: s3://dd-agent-omnibus/btfs
  S3_DD_AGENT_OMNIBUS_JAVA_URI: s3://dd-agent-omnibus/openjdk
  BTFHUB_ARCHIVE_BRANCH: main
  COMPARE_TO_BRANCH: main
  GENERAL_ARTIFACTS_CACHE_BUCKET_URL: https://dd-agent-omnibus.s3.amazonaws.com
  S3_DSD6_URI: s3://dsd6-staging

  # Build images versions
  # To use images from datadog-agent-buildimages dev branches, set the corresponding
  # SUFFIX variable to
  CI_IMAGE_BTF_GEN: v84348379-5989c48d
  CI_IMAGE_BTF_GEN_SUFFIX: ""
  CI_IMAGE_DOCKER_X64: v84348379-5989c48d
  CI_IMAGE_DOCKER_X64_SUFFIX: ""
  CI_IMAGE_DOCKER_ARM64: v84348379-5989c48d
  CI_IMAGE_DOCKER_ARM64_SUFFIX: ""
  CI_IMAGE_GITLAB_AGENT_DEPLOY: v84348379-5989c48d
  CI_IMAGE_GITLAB_AGENT_DEPLOY_SUFFIX: ""
  CI_IMAGE_LINUX: v84348379-5989c48d
  CI_IMAGE_LINUX_SUFFIX: ""
  CI_IMAGE_RPM_X64: v84348379-5989c48d
  CI_IMAGE_RPM_X64_SUFFIX: ""
  CI_IMAGE_RPM_ARM64: v84348379-5989c48d
  CI_IMAGE_RPM_ARM64_SUFFIX: ""
  CI_IMAGE_RPM_ARMHF: v84348379-5989c48d
  CI_IMAGE_RPM_ARMHF_SUFFIX: ""
  CI_IMAGE_WIN_LTSC2022_X64: v84348379-5989c48d
  CI_IMAGE_WIN_LTSC2022_X64_SUFFIX: ""
  CI_IMAGE_WIN_LTSC2025_X64: v84348379-5989c48d
  CI_IMAGE_WIN_LTSC2025_X64_SUFFIX: ""

  DATADOG_AGENT_EMBEDDED_PATH: /opt/datadog-agent/embedded
  DEB_GPG_KEY_ID: c0962c7d
  DEB_GPG_KEY_NAME: "Datadog, Inc. APT key"
  RPM_GPG_KEY_ID: b01082d3
  RPM_GPG_KEY_NAME: "Datadog, Inc. RPM key"
  # note the unusual ID for a GPG key:
  # it's the path of a Vault key to be used with gpg-vault
  # (https://github.com/DataDog/dd-source/tree/main/domains/seceng/sit/apps/artifact-security/vault-gpg-client/gpg-vault)
  GPG_TEST_KEY_ID: crypto/k8s/keys/k8s_gitlab-runner-datadog-agent_datadog-agent_testing_signing-key
  DOCKER_REGISTRY_URL: docker.io
  KITCHEN_INFRASTRUCTURE_FLAKES_RETRY: 2
  CLANG_LLVM_VER: 12.0.1
  CLANG_BUILD_VERSION: "v60409452-ee70de70"
  KERNEL_MATRIX_TESTING_X86_AMI_ID: "ami-05b3973acf5422348"
  KERNEL_MATRIX_TESTING_ARM_AMI_ID: "ami-0b5f838a19d37fc61"
  RUN_E2E_TESTS: "auto" # Should be "off", "auto" or "on" it will change the trigger condition for new-e2e tests on branch != main
  RUN_KMT_TESTS: "auto" # Should be "auto" or "on". "on" forces all Kernel Matrix Testing jobs to run.
  RUN_UNIT_TESTS: "auto" # Should be "auto", "on", "off" it will change the trigger condition for unit tests on branch != main
  # skip known flaky tests by default
  GO_TEST_SKIP_FLAKE: "true"

  # Start aws ssm variables
  # They must be defined as environment variables in the GitLab CI/CD settings, to ease rotation if needed
  API_KEY_ORG2: ci.datadog-agent.datadog_api_key_org2 # agent-devx
  CHANGELOG_COMMIT_SHA: ci.datadog-agent.gitlab_changelog_commit_sha # agent-devx
  CHOCOLATEY_API_KEY: ci.datadog-agent.chocolatey_api_key # windows-products
  CODECOV_TOKEN: ci.datadog-agent.codecov_token # agent-devx
  DOCKER_REGISTRY_LOGIN: ci.datadog-agent.docker_hub_login # container-integrations
  DOCKER_REGISTRY_PWD: ci.datadog-agent.docker_hub_pwd # container-integrations
  VCPKG_BLOB_SAS_URL: ci.datadog-agent-buildimages.vcpkg_blob_sas_url # windows-products
  WINGET_PAT: ci.datadog-agent.winget_pat # windows-products
  # End aws ssm variables

  # Start vault variables
  AGENT_API_KEY_ORG2: agent-api-key-org-2 # agent-devx
  AGENT_APP_KEY_ORG2: agent-app-key-org-2 # agent-devx
  AGENT_GITHUB_APP: agent-github-app # agent-devx
  AGENT_QA_E2E: agent-qa-e2e # agent-devx
  ATLASSIAN_WRITE: atlassian-write # agent-devx
  CODECOV: codecov # agent-devx
  DOCKER_REGISTRY_RO: dockerhub-readonly # agent-delivery
  DYNAMIC_TESTS_BREAKGLASS: dynamic-tests-breakglass # agent-devx
  E2E_AZURE: e2e-azure # agent-devx
  E2E_GCP: e2e-gcp # agent-devx
  INSTALL_SCRIPT_API_KEY_ORG2: install-script-api-key-org-2 # agent-devx
  MACOS_GITHUB_APP_1: macos-github-app-one # agent-devx
  MACOS_GITHUB_APP_2: macos-github-app-two # agent-devx
  MACOS_APPLE_APPLICATION_SIGNING: apple-application-signing # agent-delivery
  MACOS_APPLE_DEVELOPER_ACCOUNT: apple-developer-account # agent-delivery
  MACOS_APPLE_INSTALLER_SIGNING: apple-installer-signing # agent-delivery
  MACOS_KEYCHAIN_PWD: ci-keychain # agent-delivery
  SLACK_AGENT: slack-agent-ci # agent-devx
  SMP_ACCOUNT: smp # single-machine-performance
  VIRUS_TOTAL: virus-total # windows-products
  # End vault variables

  # dda configuration variables
  DDA_CLIENT_TOKEN: dda-feature-flags-client-token # agent-devx
  DDA_FEATURE_FLAGS_CI_VAULT_KEY_MACOS: token
  DDA_FEATURE_FLAGS_CI_VAULT_PATH_MACOS: aws/arn:aws:iam::486234852809:role/ci-datadog-agent/$DDA_CLIENT_TOKEN
  DDA_FEATURE_FLAGS_CI_SSM_KEY_WINDOWS: ci.datadog-agent.dda-feature-flags-client-token
  DDA_FEATURE_FLAGS_CI_VAULT_KEY: token
  DDA_FEATURE_FLAGS_CI_VAULT_PATH: k8s/gitlab-runner-datadog-agent/datadog-agent/$DDA_CLIENT_TOKEN

  DD_PKG_VERSION: "0.6.0-beta.4"
  PIPELINE_KEY_ALIAS: "alias/ci_datadog-agent_pipeline-key"

  # Job cloning strategy
  GIT_STRATEGY: "s3"

  # Job stage attempts (see https://docs.gitlab.com/ee/ci/runners/configure_runners.html#job-stages-attempts)
  ARTIFACT_DOWNLOAD_ATTEMPTS: 2
  EXECUTOR_JOB_SECTION_ATTEMPTS: 2
  GET_SOURCES_ATTEMPTS: 2
  RESTORE_CACHE_ATTEMPTS: 2
  # Feature flags
  FF_CLEAN_UP_FAILED_CACHE_EXTRACT: true # Delete corrupted caches, see https://gitlab.com/gitlab-org/gitlab-runner/-/merge_requests/4565
  FF_SCRIPT_SECTIONS: 1 # Prevent multiline scripts log collapsing, see https://gitlab.com/gitlab-org/gitlab-runner/-/issues/3392
  FF_KUBERNETES_HONOR_ENTRYPOINT: true # Honor the entrypoint in the Docker image when running Kubernetes jobs
  FF_TIMESTAMPS: true
  FF_USE_FASTZIP: true
  CACHE_COMPRESSION_LEVEL: slowest
  # Force python to print to stdout immediately, otherwise gitlab sections might not be displayed properly and we can miss some logs
  PYTHONUNBUFFERED: 1
