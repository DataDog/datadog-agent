# --- Common scripts
.shared_filters_and_queries:
  - FILTER_TEAM="Name=tag:team,Values=ebpf-platform"
  - FILTER_MANAGED="Name=tag:managed-by,Values=pulumi"
  - FILTER_STATE="Name=instance-state-name,Values=running"
  - FILTER_PIPELINE="Name=tag:pipeline-id,Values=${CI_PIPELINE_ID}"
  - FILTER_ARCH="Name=tag:arch,Values=${ARCH}"
  - FILTER_INSTANCE_TYPE="Name=tag:instance-type,Values=${INSTANCE_TYPE}"
  - FILTER_TEST_COMPONENT="Name=tag:test-component,Values=${TEST_COMPONENT}"
  - QUERY_INSTANCE_IDS='Reservations[*].Instances[*].InstanceId'
  - QUERY_PRIVATE_IPS='Reservations[*].Instances[*].PrivateIpAddress'

.wait_for_instances:
  - !reference [.shared_filters_and_queries]
  - |
    COUNTER=0
    while [[ $(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE $FILTER_TEST_COMPONENT --output text --query $QUERY_INSTANCE_IDS  | wc -l ) != "2" && $COUNTER -le 40 ]]; do COUNTER=$[$COUNTER +1]; echo "[${COUNTER}] Waiting for instances"; sleep 30; done
    # check that 2 instances are ready, or fail
    if [ $(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE $FILTER_TEST_COMPONENT --output text --query $QUERY_INSTANCE_IDS | wc -l) -ne "2" ]; then
        echo "Both instances NOT found"
        "false"
    fi
    echo "Both Instances found"
    INSTANCE_IDS=$(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE $FILTER_TEST_COMPONENT --output text --query $QUERY_INSTANCE_IDS | tr '\n' ' ')
    aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS
    sleep 10

.write_ssh_key_file:
  - set +x
  - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.ssh_key --with-decryption --query "Parameter.Value" --out text > $AWS_EC2_SSH_KEY_FILE
  - set -x
  # Without the newline ssh silently fails and moves on to try other auth methods
  - echo "" >> $AWS_EC2_SSH_KEY_FILE
  - chmod 600 $AWS_EC2_SSH_KEY_FILE

# needs variables: ARCH, INSTANCE_TYPE
.get_instance_ip_by_type:
  - INSTANCE_IP=$(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE $FILTER_TEST_COMPONENT "Name=instance-type,Values=${INSTANCE_TYPE}" --output text --query $QUERY_PRIVATE_IPS)
  - echo "$ARCH-instance-ip" $INSTANCE_IP

# needs variables: INSTANCE_IP, AWS_EC2_SSH_KEY_FILE
.setup_ssh_config:
  - mkdir -p ~/.ssh && chmod 700 ~/.ssh
  - echo -e "Host metal_instance\nHostname $INSTANCE_IP\nUser ubuntu\nStrictHostKeyChecking no\nIdentityFile $AWS_EC2_SSH_KEY_FILE\n" | tee -a ~/.ssh/config
  - chmod 600 ~/.ssh/config

.kernel_matrix_testing_new_profile:
  - mkdir -p ~/.aws
  - set +x
  - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.agent-qa-profile --with-decryption --query "Parameter.Value" --out text >> ~/.aws/config
  - set -x
  - export AWS_PROFILE=agent-qa-ci

# --- Docker test images

.pull_test_dockers:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/docker_x64$DATADOG_AGENT_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_BUILDIMAGES
  needs: []
  tags: ["arch:amd64"]
  rules: !reference [.on_any_kmt_test_component_or_manual]
  stage: kernel_matrix_testing_prepare
  script:
    # DockerHub login for build to limit rate limit when pulling base images
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text | crane auth login --username "$DOCKER_REGISTRY_LOGIN" --password-stdin "$DOCKER_REGISTRY_URL"
    # Pull base images
    - mkdir $KMT_DOCKERS
    - inv -e system-probe.save-test-dockers --use-crane --output-dir $KMT_DOCKERS --arch $ARCH
  artifacts:
    expire_in: 1 day
    paths:
      - $KMT_DOCKERS
  variables:
    KMT_DOCKERS: $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH

pull_test_dockers_x64:
  extends: .pull_test_dockers
  variables:
    ARCH: amd64

pull_test_dockers_arm64:
  extends: .pull_test_dockers
  variables:
    ARCH: arm64

# -- Test dependencies

.package_dependencies:
  stage: kernel_matrix_testing_prepare
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  allow_failure: true
  before_script:
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
  tags: ["arch:amd64"]
  script:
    # upload dependencies
    - !reference [.wait_for_instances]
    - !reference [.get_instance_ip_by_type]
    - !reference [.setup_ssh_config]
    - scp $CI_PROJECT_DIR/test/new-e2e/system-probe/test/micro-vm-init.sh metal_instance:/opt/kernel-version-testing
    - tar czvf $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH.tar.gz $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH
    - scp $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH.tar.gz metal_instance:/opt/kernel-version-testing
  variables:
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key

# -- BTF
.upload_minimized_btfs:
  stage: kernel_matrix_testing_prepare
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:amd64"]
  allow_failure: true
  script:
    # Build dependencies directory
    - mkdir -p $DEPENDENCIES
    - pushd $DEPENDENCIES
    # download and copy btf files
    - mkdir -p $BTF_DIR
    - cp $CI_PROJECT_DIR/minimized-btfs.tar.xz $BTF_DIR/minimized-btfs.tar.xz
    # package all the dependencies
    - ls -la $DEPENDENCIES
    - pushd $DD_AGENT_TESTING_DIR/$ARCH
    - tar czvf ../$ARCHIVE_NAME btfs
    - popd
    # upload tests
    # Switch to new profile after the btfs have been downloaded. Switching before
    # causes permission issues.
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
    - !reference [.wait_for_instances]
    - !reference [.get_instance_ip_by_type]
    - !reference [.setup_ssh_config]
    - scp $DD_AGENT_TESTING_DIR/$ARCHIVE_NAME metal_instance:/opt/kernel-version-testing/
  variables:
    DEPENDENCIES: $DD_AGENT_TESTING_DIR/$ARCH/btfs
    BTF_DIR: opt/system-probe-tests/pkg/ebpf/bytecode/build/co-re/btf
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key

# -- Environment setup
.kernel_matrix_testing_setup_env:
  extends:
    - .kitchen_ec2_location_us_east_1
  stage: kernel_matrix_testing_prepare
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner$TEST_INFRA_DEFINITIONS_BUILDIMAGES_SUFFIX:$TEST_INFRA_DEFINITIONS_BUILDIMAGES
  needs: ["go_deps", "go_tools_deps"]
  tags: ["arch:amd64"]
  variables:
    AWS_REGION: us-east-1
    STACK_DIR: $CI_PROJECT_DIR/stack.dir
    # The ssh key is created by the pulumi scenario, to be used for creating
    # instances in the build-stable account. We reuse this file to ssh into
    # the instances in subsequent jobs.
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key
    AWS_EC2_SSH_KEY_NAME: datadog-agent-ci
    INFRA_ENV: "aws/agent-qa"
    PIPELINE_ID: $CI_PIPELINE_ID
    TEAM: "ebpf-platform"
    RESOURCE_TAGS: "instance-type:${INSTANCE_TYPE},arch:${ARCH},test-component:${TEST_COMPONENT}"
    KUBERNETES_MEMORY_REQUEST: "12Gi"
    KUBERNETES_MEMORY_LIMIT: "16Gi"
    VMCONFIG_FILE: "${CI_PROJECT_DIR}/vmconfig-${CI_PIPELINE_ID}-${ARCH}.json"
    TEST_SETS: "no_tracersuite,only_tracersuite"
  before_script:
    - set +x
    - export DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key_org2 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    - !reference [.retrieve_linux_go_deps]
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
  script:
    - echo "s3://dd-pulumi-state?region=us-east-1&awssdk=v2&profile=$AWS_PROFILE" > $STACK_DIR
    - pulumi login $(cat $STACK_DIR | tr -d '\n')
    - inv -e kmt.gen-config --ci --arch=$ARCH --output-file=$VMCONFIG_FILE --sets=$TEST_SETS
    - inv -e system-probe.start-microvms --provision --vmconfig=$VMCONFIG_FILE $INSTANCE_TYPE_ARG $AMI_ID_ARG --ssh-key-name=$AWS_EC2_SSH_KEY_NAME --ssh-key-path=$AWS_EC2_SSH_KEY_FILE --infra-env=$INFRA_ENV --stack-name=kernel-matrix-testing-${TEST_COMPONENT}-${ARCH}-${CI_PIPELINE_ID} --run-agent
    - cat $CI_PROJECT_DIR/stack.output
    - pulumi logout
  after_script:
    - export AWS_PROFILE=agent-qa-ci
    - !reference [.shared_filters_and_queries]
    - mkdir -p $CI_PROJECT_DIR/libvirt/log/$ARCH $CI_PROJECT_DIR/libvirt/xml/$ARCH
    - !reference [.get_instance_ip_by_type]
    - ssh -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP" "sudo virsh list --name | grep -v -E '^$' | xargs -I '{}' sh -c \"sudo virsh dumpxml '{}' > /tmp/ddvm-xml-'{}'.txt\""
    - scp -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP:/tmp/ddvm-*.log" $CI_PROJECT_DIR/libvirt/log/$ARCH
    - scp -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP:/tmp/ddvm-xml-*" $CI_PROJECT_DIR/libvirt/xml/$ARCH
  artifacts:
    when: always
    paths:
      - $CI_PROJECT_DIR/stack.output
      - $CI_PROJECT_DIR/libvirt
      - $VMCONFIG_FILE

.kernel_matrix_testing_cleanup:
  stage: kernel_matrix_testing_cleanup
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner$TEST_INFRA_DEFINITIONS_BUILDIMAGES_SUFFIX:$TEST_INFRA_DEFINITIONS_BUILDIMAGES
  when: always
  tags: ["arch:amd64"]
  before_script:
    - !reference [.kernel_matrix_testing_new_profile]
  script:
    - !reference [.shared_filters_and_queries]
    - aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_PIPELINE $FILTER_ARCH $FILTER_INSTANCE_TYPE $FILTER_TEST_COMPONENT --output json --query $QUERY_INSTANCE_IDS | tee -a instance.json
    - INSTANCE_ID="$(jq -r '.[0][0]' < instance.json)"
    - echo ${INSTANCE_ID}
    - |
      if [[ "${INSTANCE_ID}" != "" ]] && [[ "${INSTANCE_ID}" != "null" ]]; then
        aws ec2 terminate-instances --instance-ids "${INSTANCE_ID}"
      fi
