.pull_test_dockers:
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/docker_x64$DATADOG_AGENT_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_BUILDIMAGES
  needs: []
  tags: ["arch:amd64"]
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  stage: kernel_matrix_testing
  script:
    # DockerHub login for build to limit rate limit when pulling base images
    - DOCKER_REGISTRY_LOGIN=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_LOGIN_SSM_KEY --with-decryption --query "Parameter.Value" --out text)
    - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.$DOCKER_REGISTRY_PWD_SSM_KEY --with-decryption --query "Parameter.Value" --out text | crane auth login --username "$DOCKER_REGISTRY_LOGIN" --password-stdin "$DOCKER_REGISTRY_URL"
    # Pull base images
    - mkdir $KMT_DOCKERS
    - inv -e system-probe.save-test-dockers --use-crane --output-dir $KMT_DOCKERS --arch $ARCH
  artifacts:
    expire_in: 1 day
    paths:
      - $KMT_DOCKERS
  variables:
    KMT_DOCKERS: $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH

pull_test_dockers_x64:
  extends: .pull_test_dockers
  variables:
    ARCH: amd64

pull_test_dockers_arm64:
  extends: .pull_test_dockers
  variables:
    ARCH: arm64

.shared_filters_and_queries:
  - FILTER_TEAM="Name=tag:team,Values=ebpf-platform"
  - FILTER_MANAGED="Name=tag:managed-by,Values=pulumi"
  - FILTER_STATE="Name=instance-state-name,Values=running"
  - FILTER_PIPELINE="Name=tag:pipeline-id,Values=${CI_PIPELINE_ID}"
  - FILTER_ARCH="Name=tag:arch,Values=${ARCH}"
  - FILTER_INSTANCE_TYPE="Name=tag:instance-type,Values=${INSTANCE_TYPE}"
  - QUERY_INSTANCE_IDS='Reservations[*].Instances[*].InstanceId'
  - QUERY_PRIVATE_IPS='Reservations[*].Instances[*].PrivateIpAddress'

.wait_for_instances:
  - !reference [.shared_filters_and_queries]
  - |
    COUNTER=0
    while [[ $(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE  --output text --query $QUERY_INSTANCE_IDS  | wc -l ) != "2" && $COUNTER -le 40 ]]; do COUNTER=$[$COUNTER +1]; echo "[${COUNTER}] Waiting for instances"; sleep 30; done
    # check that 2 instances are ready, or fail
    if [ $(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE --output text --query $QUERY_INSTANCE_IDS | wc -l) -ne "2" ]; then
        echo "Both instances NOT found"
        "false"
    fi
    echo "Both Instances found"
    INSTANCE_IDS=$(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE --output text --query $QUERY_INSTANCE_IDS | tr '\n' ' ')
    aws ec2 wait instance-status-ok --instance-ids $INSTANCE_IDS
    sleep 10

.write_ssh_key_file:
  - set +x
  - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.ssh_key --with-decryption --query "Parameter.Value" --out text > $AWS_EC2_SSH_KEY_FILE
  - set -x
  # Without the newline ssh silently fails and moves on to try other auth methods
  - echo "" >> $AWS_EC2_SSH_KEY_FILE
  - chmod 600 $AWS_EC2_SSH_KEY_FILE

# needs variables: ARCH, INSTANCE_TYPE
.get_instance_ip_by_type:
  - INSTANCE_IP=$(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_STATE $FILTER_PIPELINE "Name=instance-type,Values=${INSTANCE_TYPE}" --output text --query $QUERY_PRIVATE_IPS)
  - echo "$ARCH-instance-ip" $INSTANCE_IP

# needs variables: INSTANCE_IP, AWS_EC2_SSH_KEY_FILE
.setup_ssh_config:
  - mkdir -p ~/.ssh && chmod 700 ~/.ssh
  - echo -e "Host metal_instance\nHostname $INSTANCE_IP\nUser ubuntu\nStrictHostKeyChecking no\nIdentityFile $AWS_EC2_SSH_KEY_FILE\n" | tee -a ~/.ssh/config
  - chmod 600 ~/.ssh/config

.package_dependencies:
  stage: kernel_matrix_testing
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  allow_failure: true
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  before_script:
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
  tags: ["arch:amd64"]
  script:
    # upload dependencies
    - !reference [.wait_for_instances]
    - !reference [.get_instance_ip_by_type]
    - !reference [.setup_ssh_config]
    - scp $CI_PROJECT_DIR/test/new-e2e/system-probe/test/micro-vm-init.sh metal_instance:/opt/kernel-version-testing
    - tar czvf $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH.tar.gz $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH
    - scp $DD_AGENT_TESTING_DIR/kmt-dockers-$ARCH.tar.gz metal_instance:/opt/kernel-version-testing
  variables:
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key

upload_dependencies_x64:
  extends:
    - .package_dependencies
  needs: ["pull_test_dockers_x64"]
  variables:
    ARCH: amd64
    INSTANCE_TYPE: m5d.metal

upload_dependencies_arm64:
  extends:
    - .package_dependencies
  needs: ["pull_test_dockers_arm64"]
  variables:
    ARCH: arm64
    INSTANCE_TYPE: m6gd.metal

.upload_system_probe_tests:
  stage: kernel_matrix_testing
  allow_failure: true
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  before_script:
    - !reference [.retrieve_linux_go_deps]
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
  script:
    # Build dependencies directory
    - mkdir -p $DEPENDENCIES
    - pushd $DEPENDENCIES
    # copy clang and llc bins
    - mkdir -p $EMBEDDED_BIN
    - cp $CLANG_BPF $EMBEDDED_BIN
    - cp $LLC_BPF $EMBEDDED_BIN
    - mkdir -p $EMBEDDED_INC
    # copy gotestsum and test2json
    - mkdir -p $GO_BIN
    - cp $GOTESTSUM $GO_BIN
    - cp $TEST2JSON $GO_BIN
    - mkdir junit
    - mkdir testjson
    - mkdir pkgjson
    - popd
    - pushd $CI_PROJECT_DIR/test/new-e2e/system-probe/test-runner && go build -o $DEPENDENCIES/test-runner && popd
    - pushd $CI_PROJECT_DIR/test/new-e2e/system-probe/test-json-review && go build -o $DEPENDENCIES/test-json-review && popd
    - cp $CI_PROJECT_DIR/test/new-e2e/system-probe/test-runner/files/*.json $DEPENDENCIES/
    # package all the dependencies
    - ls -la $DEPENDENCIES
    - pushd $DD_AGENT_TESTING_DIR/$ARCH
    - tar czvf ../$ARCHIVE_NAME dependencies
    - popd
    # copy system probe tests
    - mkdir -p $SYSTEM_PROBE_TESTS
    - cp -R $KITCHEN_TESTS $SYSTEM_PROBE_TESTS
    - pushd $DD_AGENT_TESTING_DIR/$ARCH
    - tar czvf ../$TEST_ARCHIVE_NAME tests
    - popd
    # upload tests
    - !reference [.wait_for_instances]
    - !reference [.get_instance_ip_by_type]
    - !reference [.setup_ssh_config]
    - scp $DD_AGENT_TESTING_DIR/$ARCHIVE_NAME metal_instance:/opt/kernel-version-testing/
    - scp $DD_AGENT_TESTING_DIR/$TEST_ARCHIVE_NAME metal_instance:/opt/kernel-version-testing/
    # build connector
    - pushd $CI_PROJECT_DIR/test/new-e2e
    - go build -o $CI_PROJECT_DIR/connector-${ARCH} $CI_PROJECT_DIR/test/new-e2e/system-probe/connector/main.go
    - popd
    # upload connector to metal instance
    - scp $CI_PROJECT_DIR/connector-${ARCH} metal_instance:/home/ubuntu/connector
  variables:
    DEPENDENCIES: $DD_AGENT_TESTING_DIR/$ARCH/dependencies
    EMBEDDED_BIN: opt/datadog-agent/embedded/bin
    EMBEDDED_INC: opt/datadog-agent/embedded/include
    CLANG_BPF: $DD_AGENT_TESTING_DIR/site-cookbooks/dd-system-probe-check/files/default/clang-bpf
    LLC_BPF: $DD_AGENT_TESTING_DIR/site-cookbooks/dd-system-probe-check/files/default/llc-bpf
    GO_BIN: go/bin
    GOTESTSUM: $DD_AGENT_TESTING_DIR/site-cookbooks/dd-system-probe-check/files/default/gotestsum
    TEST2JSON: $DD_AGENT_TESTING_DIR/site-cookbooks/dd-system-probe-check/files/default/test2json
    SYSTEM_PROBE_TESTS: $DD_AGENT_TESTING_DIR/$ARCH/tests/system-probe-tests
    KITCHEN_TESTS: $DD_AGENT_TESTING_DIR/site-cookbooks/dd-system-probe-check/files/default/tests/pkg
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key
    ARCHIVE_NAME: dependencies-$ARCH.tar.gz
    TEST_ARCHIVE_NAME: tests-$ARCH.tar.gz
  artifacts:
    when: always
    paths:
      - $CI_PROJECT_DIR/connector-${ARCH}

upload_system_probe_tests_x64:
  extends:
    - .upload_system_probe_tests
  needs: ["go_deps", "prepare_ebpf_functional_tests_x64", "tests_ebpf_x64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:amd64"]
  variables:
    ARCH: x86_64
    INSTANCE_TYPE: m5d.metal

upload_system_probe_tests_arm64:
  extends:
    - .upload_system_probe_tests
  needs: ["go_deps", "prepare_ebpf_functional_tests_arm64", "tests_ebpf_arm64"]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:arm64"]
  variables:
    ARCH: arm64
    INSTANCE_TYPE: m6gd.metal

.upload_minimized_btfs:
  stage: kernel_matrix_testing
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:amd64"]
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  allow_failure: true
  script:
    # Build dependencies directory
    - mkdir -p $DEPENDENCIES
    - pushd $DEPENDENCIES
    # download and copy btf files
    - mkdir -p $BTF_DIR
    - cp $CI_PROJECT_DIR/minimized-btfs.tar.xz $BTF_DIR/minimized-btfs.tar.xz
    # package all the dependencies
    - ls -la $DEPENDENCIES
    - pushd $DD_AGENT_TESTING_DIR/$ARCH
    - tar czvf ../$ARCHIVE_NAME btfs
    - popd
    # upload tests
    # Switch to new profile after the btfs have been downloaded. Switching before
    # causes permission issues.
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
    - !reference [.wait_for_instances]
    - !reference [.get_instance_ip_by_type]
    - !reference [.setup_ssh_config]
    - scp $DD_AGENT_TESTING_DIR/$ARCHIVE_NAME metal_instance:/opt/kernel-version-testing/
  variables:
    DEPENDENCIES: $DD_AGENT_TESTING_DIR/$ARCH/btfs
    BTF_DIR: opt/system-probe-tests/pkg/ebpf/bytecode/build/co-re/btf
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key

upload_minimized_btfs_x64:
  extends:
    - .upload_minimized_btfs
  needs: ["generate_minimized_btfs_x64"]
  variables:
    ARCHIVE_NAME: btfs-x86_64.tar.gz
    ARCH: x86_64
    INSTANCE_TYPE: m5d.metal

upload_minimized_btfs_arm64:
  extends:
    - .upload_minimized_btfs
  needs: ["generate_minimized_btfs_arm64"]
  variables:
    ARCHIVE_NAME: btfs-arm64.tar.gz
    ARCH: arm64
    INSTANCE_TYPE: m6gd.metal

.kernel_matrix_testing_new_profile:
  - mkdir -p ~/.aws
  - set +x
  - aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.agent-qa-profile --with-decryption --query "Parameter.Value" --out text >> ~/.aws/config
  - set -x
  - export AWS_PROFILE=agent-qa-ci

.kernel_matrix_testing_setup_env:
  extends:
    - .kitchen_ec2_location_us_east_1
  stage: kernel_matrix_testing
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner$TEST_INFRA_DEFINITIONS_BUILDIMAGES_SUFFIX:$TEST_INFRA_DEFINITIONS_BUILDIMAGES
  needs: ["go_deps", "go_tools_deps"]
  tags: ["arch:amd64"]
  variables:
    AWS_REGION: us-east-1
    STACK_DIR: $CI_PROJECT_DIR/stack.dir
    # The ssh key is created by the pulumi scenario, to be used for creating
    # instances in the build-stable account. We reuse this file to ssh into
    # the instances in subsequent jobs.
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key
    AWS_EC2_SSH_KEY_NAME: datadog-agent-ci
    INFRA_ENV: "aws/agent-qa"
    PIPELINE_ID: $CI_PIPELINE_ID
    TEAM: "ebpf-platform"
    RESOURCE_TAGS: "instance-type:${INSTANCE_TYPE},arch:${ARCH}"
    KUBERNETES_MEMORY_REQUEST: "12Gi"
    KUBERNETES_MEMORY_LIMIT: "16Gi"
    VMCONFIG_FILE: "${CI_PROJECT_DIR}/vmconfig-${CI_PIPELINE_ID}-${ARCH}.json"
    TEST_SETS: "no_tracersuite,only_tracersuite"
  before_script:
    - set +x
    - export DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key_org2 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    - !reference [.retrieve_linux_go_deps]
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
  script:
    - echo "s3://dd-pulumi-state?region=us-east-1&awssdk=v2&profile=$AWS_PROFILE" > $STACK_DIR
    - pulumi login $(cat $STACK_DIR | tr -d '\n')
    - inv -e kmt.gen-config --ci --arch=$ARCH --output-file=$VMCONFIG_FILE --sets=$TEST_SETS
    - inv -e system-probe.start-microvms --provision --vmconfig=$VMCONFIG_FILE $INSTANCE_TYPE_ARG $AMI_ID_ARG --ssh-key-name=$AWS_EC2_SSH_KEY_NAME --ssh-key-path=$AWS_EC2_SSH_KEY_FILE --infra-env=$INFRA_ENV --stack-name=kernel-matrix-testing-$ARCH-$CI_PIPELINE_ID --run-agent
    - jq -r '.' $CI_PROJECT_DIR/stack.output
    - pulumi logout
  after_script:
    - export AWS_PROFILE=agent-qa-ci
    - !reference [.shared_filters_and_queries]
    - mkdir -p $CI_PROJECT_DIR/libvirt/log/$ARCH $CI_PROJECT_DIR/libvirt/xml/$ARCH $CI_PROJECT_DIR/libvirt/qemu/$ARCH
    - !reference [.get_instance_ip_by_type]
    - ssh -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP" "sudo virsh list --name | grep -v -E '^$' | xargs -I '{}' sh -c \"sudo virsh dumpxml '{}' > /tmp/ddvm-xml-'{}'.txt\""
    - ssh -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP" "sudo virsh list --name | xargs -I '{}' sh -c \"sudo cp /var/log/libvirt/qemu/'{}'.log /tmp/ddvm-qemu-'{}'.log && sudo chown 1000:1000 /tmp/ddvm-qemu-*\""
    - scp -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP:/tmp/ddvm-*.log" $CI_PROJECT_DIR/libvirt/log/$ARCH
    - scp -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP:/tmp/ddvm-xml-*" $CI_PROJECT_DIR/libvirt/xml/$ARCH
    - scp -o StrictHostKeyChecking=no -i $AWS_EC2_SSH_KEY_FILE "ubuntu@$INSTANCE_IP:/tmp/ddvm-qemu-*" $CI_PROJECT_DIR/libvirt/qemu/$ARCH
  artifacts:
    when: always
    paths:
      - $CI_PROJECT_DIR/stack.output
      - $CI_PROJECT_DIR/libvirt
      - $VMCONFIG_FILE

kernel_matrix_testing_setup_env_arm64:
  extends:
    - .kernel_matrix_testing_setup_env
  variables:
    INSTANCE_TYPE: "m6gd.metal"
    INSTANCE_TYPE_ARG: "--instance-type-arm=$INSTANCE_TYPE"
    ARCH: arm64
    AMI_ID_ARG: "--arm-ami-id=$KERNEL_MATRIX_TESTING_ARM_AMI_ID"
    LibvirtSSHKey: $CI_PROJECT_DIR/libvirt_rsa-arm

kernel_matrix_testing_setup_env_x64:
  extends:
    - .kernel_matrix_testing_setup_env
  variables:
    INSTANCE_TYPE: "m5d.metal"
    INSTANCE_TYPE_ARG: "--instance-type-x86=$INSTANCE_TYPE"
    ARCH: x86_64
    AMI_ID_ARG: "--x86-ami-id=$KERNEL_MATRIX_TESTING_X86_AMI_ID"
    LibvirtSSHKey: $CI_PROJECT_DIR/libvirt_rsa-x86

.kernel_matrix_testing_run_tests:
  stage: kernel_matrix_testing
  allow_failure: true
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  variables:
    AWS_EC2_SSH_KEY_FILE: $CI_PROJECT_DIR/ssh_key
    RETRY: 2
  before_script:
    - set +x
    - export DD_API_KEY=$(aws ssm get-parameter --region us-east-1 --name ci.datadog-agent.datadog_api_key_org2 --with-decryption --query "Parameter.Value" --out text)
    - set -x
    - !reference [.kernel_matrix_testing_new_profile]
    - !reference [.write_ssh_key_file]
    - echo "CI_JOB_URL=${CI_JOB_URL}" >> $DD_AGENT_TESTING_DIR/job_env.txt
    - echo "CI_JOB_ID=${CI_JOB_ID}" >> $DD_AGENT_TESTING_DIR/job_env.txt
    - echo "CI_JOB_NAME=${CI_JOB_NAME}" >> $DD_AGENT_TESTING_DIR/job_env.txt
    - echo "CI_JOB_STAGE=${CI_JOB_STAGE}" >> $DD_AGENT_TESTING_DIR/job_env.txt
  script:
    - INSTANCE_IP=$(jq --exit-status --arg ARCH $ARCH -r '.[$ARCH].ip' $CI_PROJECT_DIR/stack.output)
    - !reference [.shared_filters_and_queries]
    - RUNNING_INSTANCES=$(aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_PIPELINE "Name=private-ip-address,Values=$INSTANCE_IP" --output text --query $QUERY_INSTANCE_IDS | wc -l )
    - |
      if [ $RUNNING_INSTANCES -eq "0" ]; then
        echo "These jobs do not permit retries. The go tests are retried a user-specified number of times automatically. In order to re-run the tests, you must trigger the pipeline again"
        'false'
      fi
    - MICRO_VM_IP=$(jq --exit-status --arg TAG $TAG --arg ARCH $ARCH --arg TEST_SET $TEST_SET -r '.[$ARCH].microvms | map(select(."vmset-tags"| index($TEST_SET))) | map(select(.tag==$TAG)) | .[].ip' $CI_PROJECT_DIR/stack.output)
    - MICRO_VM_NAME=$(jq --exit-status --arg TAG $TAG --arg ARCH $ARCH --arg TEST_SET $TEST_SET -r '.[$ARCH].microvms | map(select(."vmset-tags"| index($TEST_SET))) | map(select(.tag==$TAG)) | .[].id' $CI_PROJECT_DIR/stack.output)
    - GO_VERSION=$(inv go-version)
    - !reference [.setup_ssh_config]
    # ssh into each micro-vm and run initialization script. This script will also run the tests.
    - scp "$DD_AGENT_TESTING_DIR/job_env.txt" "metal_instance:/home/ubuntu/job_env-${ARCH}-${TAG}-${TEST_SET}.txt"
    - ssh metal_instance "scp /home/ubuntu/job_env-${ARCH}-${TAG}-${TEST_SET}.txt ${MICRO_VM_IP}:/job_env.txt"
    - NESTED_VM_CMD="/home/ubuntu/connector -host ${MICRO_VM_IP} -user root -ssh-file /home/kernel-version-testing/ddvm_rsa -vm-cmd '/root/fetch_dependencies.sh ${ARCH} && /opt/kernel-version-testing/micro-vm-init.sh ${RETRY} /${TEST_SET}.json'"
    - $CI_PROJECT_DIR/connector-$ARCH -host $INSTANCE_IP -user ubuntu -ssh-file $AWS_EC2_SSH_KEY_FILE -vm-cmd "${NESTED_VM_CMD}"
    - ssh metal_instance "ssh ${MICRO_VM_IP} '/test-json-review'"
  after_script:
    - MICRO_VM_IP=$(jq --exit-status --arg TAG $TAG --arg ARCH $ARCH --arg TEST_SET $TEST_SET -r '.[$ARCH].microvms | map(select(."vmset-tags"| index($TEST_SET))) | map(select(.tag==$TAG)) | .[].ip' $CI_PROJECT_DIR/stack.output)
    - ssh metal_instance "scp ${MICRO_VM_IP}:/ci-visibility/junit.tar.gz /home/ubuntu/junit-${ARCH}-${TAG}-${TEST_SET}.tar.gz"
    - scp "metal_instance:/home/ubuntu/junit-${ARCH}-${TAG}-${TEST_SET}.tar.gz" $DD_AGENT_TESTING_DIR/
    - ssh metal_instance "scp ${MICRO_VM_IP}:/ci-visibility/testjson.tar.gz /home/ubuntu/testjson-${ARCH}-${TAG}-${TEST_SET}.tar.gz"
    - scp "metal_instance:/home/ubuntu/testjson-${ARCH}-${TAG}-${TEST_SET}.tar.gz" $DD_AGENT_TESTING_DIR/
  artifacts:
    expire_in: 2 weeks
    when: always
    paths:
      - $DD_AGENT_TESTING_DIR/junit-$ARCH-$TAG-$TEST_SET.tar.gz
      - $DD_AGENT_TESTING_DIR/testjson-$ARCH-$TAG-$TEST_SET.tar.gz

kernel_matrix_testing_run_tests_x64:
  extends:
    - .kernel_matrix_testing_run_tests
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_x64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:amd64"]
  needs: ["kernel_matrix_testing_setup_env_x64", "upload_dependencies_x64", "upload_system_probe_tests_x64", "upload_minimized_btfs_x64"]
  timeout: 3h
  variables:
    ARCH: "x86_64"
  parallel:
    matrix:
      - TAG: ["ubuntu_16.04", "ubuntu_18.04", "ubuntu_20.04", "ubuntu_22.04", "ubuntu_23.10", "amzn_4.14", "amzn_5.4", "amzn_5.10", "fedora_37", "fedora_38", "debian_10", "debian_11", "debian_12", "centos_79", "centos_8"]
        TEST_SET: ["no_tracersuite", "only_tracersuite"]

kernel_matrix_testing_run_tests_arm64:
  extends:
    - .kernel_matrix_testing_run_tests
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/datadog-agent-buildimages/system-probe_arm64$DATADOG_AGENT_SYSPROBE_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_SYSPROBE_BUILDIMAGES
  tags: ["arch:arm64"]
  needs: ["kernel_matrix_testing_setup_env_arm64", "upload_dependencies_arm64", "upload_system_probe_tests_arm64", "upload_minimized_btfs_arm64"]
  timeout: 3h
  variables:
    ARCH: "arm64"
  parallel:
    matrix:
      - TAG: ["ubuntu_18.04", "ubuntu_20.04", "ubuntu_22.04", "ubuntu_23.10", "amzn_4.14", "amzn_5.4", "amzn_5.10", "fedora_37", "fedora_38", "debian_10", "debian_11", "debian_12", "centos_79", "centos_8"]
        TEST_SET: ["no_tracersuite", "only_tracersuite"]

.kernel_matrix_testing_cleanup:
  stage: kernel_matrix_testing
  image: 486234852809.dkr.ecr.us-east-1.amazonaws.com/ci/test-infra-definitions/runner$TEST_INFRA_DEFINITIONS_BUILDIMAGES_SUFFIX:$TEST_INFRA_DEFINITIONS_BUILDIMAGES
  when: always
  tags: ["arch:amd64"]
  rules:
    !reference [ .on_system_probe_or_e2e_changes_or_manual ]
  before_script:
    - !reference [.kernel_matrix_testing_new_profile]
  script:
    - !reference [.shared_filters_and_queries]
    - aws ec2 describe-instances --filters $FILTER_TEAM $FILTER_MANAGED $FILTER_PIPELINE $FILTER_ARCH $FILTER_INSTANCE_TYPE --output json --query $QUERY_INSTANCE_IDS | tee -a instance.json
    - INSTANCE_ID="$(jq -r '.[0][0]' < instance.json)"
    - echo ${INSTANCE_ID}
    - |
      if [[ "${INSTANCE_ID}" != "" ]] && [[ "${INSTANCE_ID}" != "null" ]]; then
        aws ec2 terminate-instances --instance-ids "${INSTANCE_ID}"
      fi

kernel_matrix_testing_cleanup_arm64:
  extends:
    - .kernel_matrix_testing_cleanup
  needs: ["kernel_matrix_testing_setup_env_arm64", "kernel_matrix_testing_run_tests_arm64"]
  variables:
    ARCH: arm64
    INSTANCE_TYPE: "m6gd.metal"

kernel_matrix_testing_cleanup_x64:
  extends:
    - .kernel_matrix_testing_cleanup
  needs: ["kernel_matrix_testing_setup_env_x64", "kernel_matrix_testing_run_tests_x64"]
  variables:
    ARCH: x86_64
    INSTANCE_TYPE: "m5d.metal"
