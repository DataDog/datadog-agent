single-machine-performance-regression_detector:
  stage: functional_test
  timeout: 1h10m
  rules:
    - !reference [.except_main_or_release_branch]
    - when: on_success
  image: registry.ddbuild.io/ci/datadog-agent-buildimages/docker_x64$DATADOG_AGENT_BUILDIMAGES_SUFFIX:$DATADOG_AGENT_BUILDIMAGES
  tags: ["arch:amd64"]
  needs:
    - job: single_machine_performance-amd64-a7
      artifacts: false
  artifacts:
    expire_in: 1 weeks
    paths:
      - submission_metadata # for provenance, debugging
      - ${CI_COMMIT_SHA}-baseline_sha # for provenance, debugging
      - outputs/report.md # for debugging, also on S3
      - outputs/regression_signal.json # for debugging, also on S3
      - outputs/bounds_check_signal.json # for debugging, also on S3
      - outputs/junit.xml # for debugging, also on S3
      - outputs/report.json # for debugging, also on S3
      - outputs/decision_record.md # for posterity, this is appended to final PR comment
    when: always
  variables:
    SMP_VERSION: 0.19.3
  # See 'decision_record.md' for the determination of whether this job passes or fails.
  allow_failure: false
  script:
    # `datadog-ci` relies on `DATADOG_API_KEY` so we get that here.
    - DATADOG_API_KEY="$("$CI_PROJECT_DIR"/tools/ci/fetch_secret.sh "$AGENT_API_KEY_ORG2" token)" || exit $?; export DATADOG_API_KEY
    # Start by tagging the failure mode as `unknown`. At each smp command we will catch any failure exit codes and update this tag properly.
    # If we successfully get to the end of the script with no failures we will update the `smp_failure_mode` tag to `none` to convey this.
    # Note, we cannot apply a tag for timeouts with this approach. In order to identify jobs failed by timing out you can filter by error type or duration.
    # Note, in situations where the job times out the value of `smp_failure_mode` tag will be `unknown`.
    - datadog-ci tag --level job --tags smp_failure_mode:"unknown"
    # Ensure output files exist for artifact downloads step
    - mkdir outputs # Also needed for smp job sync step
    # Compute merge base of current commit and `main`
    - git fetch origin
    - SMP_BASE_BRANCH=$(inv release.get-release-json-value base_branch --no-worktree)
    - echo "Looking for merge base for branch ${SMP_BASE_BRANCH}"
    - SMP_MERGE_BASE=$(git merge-base ${CI_COMMIT_SHA} origin/${SMP_BASE_BRANCH})
    - echo "Merge base is ${SMP_MERGE_BASE}"
    # Setup AWS credentials for single-machine-performance AWS account
    - AWS_NAMED_PROFILE="single-machine-performance"
    - SMP_ACCOUNT_ID=$($CI_PROJECT_DIR/tools/ci/fetch_secret.sh $SMP_ACCOUNT account_id) || exit $?
    - SMP_ECR_URL=${SMP_ACCOUNT_ID}.dkr.ecr.us-west-2.amazonaws.com
    - SMP_AGENT_TEAM_ID=$($CI_PROJECT_DIR/tools/ci/fetch_secret.sh $SMP_ACCOUNT agent_team_id) || exit $?
    - SMP_API=$($CI_PROJECT_DIR/tools/ci/fetch_secret.sh $SMP_ACCOUNT api_url) || exit $?
    - SMP_BOT_ID=$($CI_PROJECT_DIR/tools/ci/fetch_secret.sh $SMP_ACCOUNT bot_login) || exit $?
    - SMP_BOT_KEY=$($CI_PROJECT_DIR/tools/ci/fetch_secret.sh $SMP_ACCOUNT bot_token) || exit $?
    - aws configure set aws_access_key_id "$SMP_BOT_ID" --profile ${AWS_NAMED_PROFILE}
    - aws configure set aws_secret_access_key "$SMP_BOT_KEY" --profile ${AWS_NAMED_PROFILE}
    - aws configure set region us-west-2 --profile ${AWS_NAMED_PROFILE}
    # Download smp binary and prepare it for use
    - aws --profile single-machine-performance s3 cp s3://smp-cli-releases/v${SMP_VERSION}/x86_64-unknown-linux-gnu/smp smp
    - chmod +x smp
    - BASELINE_SHA="${SMP_MERGE_BASE}"
    - echo "Computing baseline..."
    - echo "Checking if commit ${BASELINE_SHA} is recent enough..."
    # Compute four days before now as UNIX timestamp in order to test against SMP ECR expiration policy;
    # add an hour as a small correction factor to overestimate time needed for SMP to query and pull the
    # image so we don't end up with a hard-to-diagnose bug in which the image expires after checking its
    # age in CI, but before SMP pulls the image.
    - FOUR_DAYS_BEFORE_NOW=$(date --date="-4 days +1 hour" "+%s")
    # Compute UNIX timestamp of potential baseline SHA
    - BASELINE_COMMIT_TIME=$(git -c log.showSignature=false show --no-patch --format=%ct ${BASELINE_SHA})
    # If baseline SHA is older than expiration policy, exit with an error
    - | # Only 1st line of multiline command echoes, which reduces debuggability, so multiline commands are a maintenance tradeoff
      if [[ ${BASELINE_COMMIT_TIME} -le ${FOUR_DAYS_BEFORE_NOW} ]]
      then
          echo "ERROR: Merge-base of this branch is too old for SMP. Please update your branch by merging an up-to-date main branch into your branch or by rebasing it on an up-to-date main branch."
          datadog-ci tag --level job --tags smp_failure_mode:"merge-base-too-old"
          exit 1
      fi
    - echo "Commit ${BASELINE_SHA} is recent enough"
    - echo "Checking if image exists for commit ${BASELINE_SHA}..."
    - |
      while [[ ! $(aws ecr describe-images --region us-west-2 --profile single-machine-performance --registry-id "${SMP_ACCOUNT_ID}" --repository-name "${SMP_AGENT_TEAM_ID}-agent" --image-ids imageTag="${BASELINE_SHA}-7-amd64") ]]
      do
          echo "No image exists for ${BASELINE_SHA} - checking predecessor of ${BASELINE_SHA} next"
          BASELINE_SHA=$(git rev-parse ${BASELINE_SHA}^)
          echo "Checking if commit ${BASELINE_SHA} is recent enough..."
          BASELINE_COMMIT_TIME=$(git -c log.showSignature=false show --no-patch --format=%ct ${BASELINE_SHA})
          if [[ ${BASELINE_COMMIT_TIME} -le ${FOUR_DAYS_BEFORE_NOW} ]]
          then
              echo "ERROR: Merge-base of this branch is too old for SMP. Please update your branch by merging an up-to-date main branch into your branch or by rebasing it on an up-to-date main branch."
              datadog-ci tag --level job --tags smp_failure_mode:"merge-base-too-old-predecessor"
              exit 1
          fi
          echo "Commit ${BASELINE_SHA} is recent enough"
          echo "Checking if image exists for commit ${BASELINE_SHA}..."
      done
    - echo "Image exists for commit ${BASELINE_SHA}"
    - echo "Baseline SHA is ${BASELINE_SHA}"
    - echo -n "${BASELINE_SHA}" > "${CI_COMMIT_SHA}-baseline_sha"
    # Copy the baseline SHA to SMP for debugging purposes later
    - aws s3 cp --profile single-machine-performance --only-show-errors "${CI_COMMIT_SHA}-baseline_sha" "s3://${SMP_AGENT_TEAM_ID}-smp-artifacts/information/"
    - BASELINE_IMAGE=${SMP_ECR_URL}/${SMP_AGENT_TEAM_ID}-agent:${BASELINE_SHA}-7-amd64
    - echo "${BASELINE_SHA} | ${BASELINE_IMAGE}"
    - COMPARISON_IMAGE=${SMP_ECR_URL}/${SMP_AGENT_TEAM_ID}-agent:${CI_COMMIT_SHA}-7-amd64
    - echo "${CI_COMMIT_SHA} | ${COMPARISON_IMAGE}"
    - SMP_TAGS="ci_pipeline_id=${CI_PIPELINE_ID},ci_job_id=${CI_JOB_ID}"
    - echo "Tags passed through SMP are ${SMP_TAGS}"
    - RUST_LOG="info,aws_config::profile::credentials=error"
    - RUST_LOG_DEBUG="debug,aws_config::profile::credentials=error"
    - |
      RUST_LOG="${RUST_LOG}" ./smp --team-id ${SMP_AGENT_TEAM_ID} --api-base ${SMP_API} --aws-named-profile ${AWS_NAMED_PROFILE} \
      job submit \
      --baseline-image ${BASELINE_IMAGE} \
      --comparison-image ${COMPARISON_IMAGE} \
      --baseline-sha ${BASELINE_SHA} \
      --comparison-sha ${CI_COMMIT_SHA} \
      --target-config-dir test/regression/ \
      --submission-metadata submission_metadata \
      --tags ${SMP_TAGS} || {
        exit_code=$?
        echo "smp job submit command failed with code $exit_code"
        datadog-ci tag --level job --tags smp_failure_mode:"job-submission"
        exit $exit_code
      }
    # Get the SMP Job Id from 'submission-metadata' and use 'datadog-ci'
    # to tag the gitlab job seen in CI Visibility with the SMP Job Id.
    - SMP_JOB_ID=$(jq -r '.jobId' submission_metadata)
    - echo "SMP Job Id is ${SMP_JOB_ID}"
    - datadog-ci tag --level job --tags smp_job_id:${SMP_JOB_ID}
    # Wait for job to complete.
    - |
      RUST_LOG="${RUST_LOG}" ./smp --team-id ${SMP_AGENT_TEAM_ID} --api-base ${SMP_API} --aws-named-profile ${AWS_NAMED_PROFILE} \
      job status \
      --wait \
      --wait-delay-seconds 60 \
      --submission-metadata submission_metadata || {
        exit_code=$?
        echo "smp job status command failed with code $exit_code"
        datadog-ci tag --level job --tags smp_failure_mode:"job-status"
        exit $exit_code
      }
    # Now that the job is completed pull the analysis report, output it to stdout.
    - |
      RUST_LOG="${RUST_LOG}" ./smp --team-id ${SMP_AGENT_TEAM_ID} --api-base ${SMP_API} --aws-named-profile ${AWS_NAMED_PROFILE} \
      job sync \
      --submission-metadata submission_metadata \
      --output-path outputs || {
        exit_code=$?
        echo "smp job sync command failed with code $exit_code"
        datadog-ci tag --level job --tags smp_failure_mode:"job-sync"
        exit $exit_code
      }
    # Replace empty lines in the output with lines containing various unicode
    # space characters. This avoids
    # https://gitlab.com/gitlab-org/gitlab/-/issues/217231.
    - cat outputs/report.md | sed "s/^\$/$(echo -ne '\uFEFF\u00A0\u200B')/g"
    # Upload JUnit XML outside of Agent CI's tooling because the `junit_upload`
    # invoke task has additional logic that does not seem to apply well to SMP's
    # JUnit XML. Agent CI seems to use `datadog-agent` as the service name when
    # uploading JUnit XML, so the upload command below respects that convention.
    - datadog-ci junit upload --service datadog-agent outputs/junit.xml
    # At this point if the script has not failed the `smp_failure_mode` tag should be none.
    # Although this may not be necessarily true, failures as a result of violations in optimization goals
    # bounds checks and quality gates will be signaled by their own tag.
    - datadog-ci tag --level job --tags smp_failure_mode:"none"
    # Check for failing regression detector for the purpose of tagging.
    # For consistency we start by tagging with smp_optimization_goal:passed and overwrite to failed if a failure is detected.
    - datadog-ci tag --level job --tags smp_optimization_goal:"passed"
    - |
      RUST_LOG="${RUST_LOG}" ./smp --team-id ${SMP_AGENT_TEAM_ID} --api-base ${SMP_API} --aws-named-profile ${AWS_NAMED_PROFILE} \
        job result \
        --submission-metadata submission_metadata --signal regression-detector || {
        exit_code=$?
        echo "smp regression detector has detected a regression"
        datadog-ci tag --level job --tags smp_optimization_goal:"failed"
      }
    # Check for failing bounds checks for the purpose of tagging.
    # For consistency we start by tagging with smp_bounds_check:passed and overwrite to failed if a failure is detected.
    - datadog-ci tag --level job --tags smp_bounds_check:"passed"
    - |
      RUST_LOG="${RUST_LOG}" ./smp --team-id ${SMP_AGENT_TEAM_ID} --api-base ${SMP_API} --aws-named-profile ${AWS_NAMED_PROFILE} \
        job result \
        --submission-metadata submission_metadata --signal bounds-check || {
        exit_code=$?
        echo "smp regression detector has detected a failed bounds check"
        datadog-ci tag --level job --tags smp_bounds_check:"failed"
      }
    # Run quality gate check script
    # In order to determine if the following python script failed we assume quality gates failure here and update accordingly
    # if we make it through the python script successfully. The consequence of this is that any failure in the python script will
    # be seen as a quality gates failure.
    - datadog-ci tag --level job --tags smp_quality_gates:"failed"
    - |
      python3 <<'EOF'
      import json
      import sys

      try:
          with open('outputs/report.json') as f:
              data = json.load(f)
      except FileNotFoundError:
          print("Machine readable report not found.")
          sys.exit(1)
      except json.JSONDecodeError as e:
          print(f"Error parsing JSON report: {e}")
          sys.exit(1)

      experiments = data.get('experiments', {})
      failed = False
      decision_record = []

      for exp_name, exp_data in experiments.items():
          if exp_name.startswith('quality_gate_'):
              bounds_checks = exp_data.get('bounds_checks', {})
              for check_name, check_data in bounds_checks.items():
                  results = check_data.get('results', {})
                  comparison = results.get('comparison', [])
                  num_total = len(comparison)
                  failed_replicates = [
                      replicate for replicate in comparison if not replicate.get('passed', False)
                  ]
                  num_failed = len(failed_replicates)
                  num_passed = num_total - num_failed
                  if failed_replicates:
                      decision_record.append(
                          f"- **{exp_name}**, bounds check **{check_name}**: {num_passed}/{num_total} replicas passed. Failed {num_failed} which is > 0. Gate **FAILED**."
                      )
                      failed = True
                  else:
                      decision_record.append(
                          f"- **{exp_name}**, bounds check **{check_name}**: {num_passed}/{num_total} replicas passed. Gate passed."
                      )

      with open('outputs/decision_record.md', 'w') as f:
          # Extra newline since this is appended to another report
          f.write('\n\n## CI Pass/Fail Decision\n\n')
          if failed:
              f.write('❌ **Failed.** Some Quality Gates were violated.\n\n')
              f.write('\n'.join(decision_record))
          else:
              f.write('✅ **Passed.** All Quality Gates passed.\n\n')
              f.write('\n'.join(decision_record))

      if failed:
          print("Quality gate failed, see decision record")
          sys.exit(1)
      else:
          print("Quality gate passed.")
          sys.exit(0)
      EOF
    # If we make it here that means quality gates must not have failed.
    - datadog-ci tag --level job --tags smp_quality_gates:"passed"

# Shamelessly adapted from golang_deps_commenter job config in
# golang_deps_diff.yml at commit 01da274032e510d617161cf4e264a53292f44e55.
single-machine-performance-regression_detector-pr-comment:
  stage: functional_test
  rules:
    - !reference [.except_main_or_release_branch]
    - when: always
  image:
    name: "486234852809.dkr.ecr.us-east-1.amazonaws.com/pr-commenter:3"
    entrypoint: [""] # disable entrypoint script for the pr-commenter image
  tags: ["arch:amd64"]
  needs:
    - job: single-machine-performance-regression_detector
  artifacts:
    expire_in: 1 weeks
    paths:
      - report_as_json_string.txt # for debugging transform to valid JSON string
      - pr_comment_payload.json # for debugging PR commenter JSON payload bugs
  variables:
    # Not using the entrypoint script for the pr-commenter image
    FF_KUBERNETES_HONOR_ENTRYPOINT: false
  allow_failure: true # allow_failure here should have same setting as in job above
  script: # ignore error message about no PR, because it happens for dev branches without PRs
    # Prevent posting empty Regression Detector report if Markdown report is not found or
    # has zero size.
    - |
      if [[ ! -s "outputs/report.md" ]]
      then
          echo "ERROR: Regression Detector report not found -- no PR comment posted"
          exit 1
      fi
    # We need to transform the Markdown report into a valid JSON string (without
    # quotes) in order to pass a well-formed payload to the PR commenting
    # service. Note that on macOS, the "-z" flag is invalid for `sed` (but
    # should be fine for GNU `sed`). We need to use `sed` to escape newlines
    # because JSON does not permit (raw) newlines in strings. We use the "-z"
    # option with `sed` because that option treats its input as
    # NUL-character-separated (i.e., '\0'-separated, the zero-byte character),
    # so `sed` does not interpret its input as newline-delimited. We also need
    # to escape double quotes to distinguish literal quotes in the report from
    # the double quotes that delimit the value of the "message" field in the
    # payload.
    # Appends the Decision Record to final report
    - cat outputs/report.md outputs/decision_record.md | sed -z 's/\n/\\n/g' | sed -z 's/"/\\"/g' > report_as_json_string.txt
    - cat report_as_json_string.txt
    # Transforming the Markdown report to a valid JSON string is easy to foul
    # up, so to make debugging easier, we store the payload in a variable to
    # help debugging.
    - PR_COMMENT_JSON_PAYLOAD='{"org":"DataDog", "repo":"datadog-agent", "commit":"'"${CI_COMMIT_SHA}"'", "header":"Regression Detector", "message":"'"$(cat report_as_json_string.txt)"'"}'
    - printf "%s\n" "PR comment JSON payload:${PR_COMMENT_JSON_PAYLOAD}"
    - printf "%s\n" "${PR_COMMENT_JSON_PAYLOAD}" > pr_comment_payload.json
    # Craft an HTTPS request to pr-commenter service to post Markdown report to
    # GitHub, per
    # https://github.com/DataDog/dd-source/tree/7c941f527fb9c44a73433c7dd0a090d92be7deb4/domains/devex/codex/apps/apis/pr-commenter
    # and gracefully handle the case when the commit being tested is not a PR
    - |
      set +e
      out=$(curl https://pr-commenter.us1.ddbuild.io/internal/cit/pr-comment \
          -H "$(authanywhere)" \
          -H "X-DdOrigin: curl" \
          -X PATCH \
          -d "${PR_COMMENT_JSON_PAYLOAD}")
      exitcode=$?
      set -e
      if [ -n "${out}" ]; then
        if [ $exitcode -eq 0 ]; then
          echo $out
        else
          echo $out >&2
        fi
      fi
      if [ "${out}" != "${out/invalid request: no pr found for this commit}" ]; then
        exit 0
      fi
      exit $exitcode
