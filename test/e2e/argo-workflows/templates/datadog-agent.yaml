apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: datadog-agent
spec:
  templates:
    - name: create
      inputs:
        parameters:
          - name: namespace
          - name: dd-url
          - name: site
          - name: agent-image-repository
          - name: agent-image-tag
          - name: cluster-agent-image-repository
          - name: cluster-agent-image-tag
          - name: ci_commit_short_sha
          - name: ci_pipeline_id
          - name: ci_job_id
          - name: remote_configuration_enabled
      script:
        image: alpine/k8s:1.25.4
        envFrom:
          - secretRef:
              name: dd-keys
        command: [sh]
        source: |
          set -euo pipefail

          # for CWS tests we need to have a test policy before the container start
          mkdir -p /tmp/runtime-security.d
          cat > /tmp/runtime-security.d/test.policy <<EOF
          rules:
            - id: TEST
              expression: open.file.path == "/tmp/test123"
          EOF
          kubectl create configmap cws-test-policy --from-file=/tmp/runtime-security.d/test.policy

          cat > /tmp/values.yaml <<EOF
          datadog:
            kubeStateMetricsEnabled: false
            kubeStateMetricsCore:
              enabled: true

            dd_url: {{inputs.parameters.dd-url}}
            site: {{inputs.parameters.site}}
            apiKey: $DD_API_KEY
            appKey: $DD_APP_KEY
            tags:
              - tag1
              - tag2
              - app:agent-e2e-tests
              - ci_commit_short_sha:{{inputs.parameters.ci_commit_short_sha}}
              - ci_pipeline_id:{{inputs.parameters.ci_pipeline_id}}
              - ci_job_id:{{inputs.parameters.ci_job_id}}
            kubelet:
              tlsVerify: false
            env:
              - name: DD_HOSTNAME
                value: k8s-e2e-tests-control-plane
            leaderElection: true
            logs:
              enabled: true
              containerCollectAll: true
            apm:
              enabled: true
            otlp:
              receiver:
                protocols:
                  grpc:
                    enabled: true
            processAgent:
              enabled: true
            systemProbe:
              enableTCPQueueLength: false
              enableOOMKill: false
            networkMonitoring:
              enabled: true
            securityAgent:
              compliance:
                enabled: true
              runtime:
                enabled: true
                network:
                  enabled: true

            confd:
              memory.yaml: |
                init_config:
                instances:
                  - empty_default_hostname: true

              network.yaml: |
                init_config:
                instances:
                  - collect_connection_state: false
                    excluded_interfaces:
                      - lo
                      - lo0
                  - collect_connection_state: false
                    empty_default_hostname: true
                    excluded_interfaces:
                      - lo
                      - lo0

            dogstatsd:
              useSocketVolume: true
              socketPath: /var/run/dogstatsd/dsd.socket
              hostSocketPath: /var/run/dogstatsd

          agents:
            image:
              repository: {{inputs.parameters.agent-image-repository}}
              tag: {{inputs.parameters.agent-image-tag}}
              doNotCheckTag: true
              pullSecrets:
                - name: docker-registry
            containers:
              agent:
                env:
                  - name:  DD_USE_V2_API_SERIES
                    value: "false"
                  - name: DD_REMOTE_CONFIGURATION_ENABLED
                    value: "{{inputs.parameters.remote_configuration_enabled}}"
              systemProbe:
                logLevel: TRACE
                env:
                  - name:  DD_RUNTIME_SECURITY_CONFIG_LOG_PATTERNS
                    value: "module.APIServer.*"
                  - name: DD_RUNTIME_SECURITY_CONFIG_POLICIES_DIR
                    value: "/tmp/runtime-security.d"
                  - name: DD_RUNTIME_SECURITY_CONFIG_REMOTE_CONFIGURATION_ENABLED
                    value: "{{inputs.parameters.remote_configuration_enabled}}"
                securityContext:
                  capabilities:
                    drop:
                      - all
            volumes:
              - configMap:
                  name: cws-test-policy
                name: cws-test-policy
            volumeMounts:
              - name: cws-test-policy
                mountPath: /tmp/runtime-security.d/test.policy
                subPath: test.policy
            useConfigMap: true
            customAgentConfig:
              additional_endpoints:
                https://agent.datadoghq.com.: $DD_DDDEV_API_KEY
              logs_config:
                use_http: true
                additional_endpoints:
                  - host: agent-http-intake.logs.datadoghq.com.
                    api_key: $DD_DDDEV_API_KEY
                    is_reliable: true

          clusterAgent:
            enabled: true
            image:
              repository: {{inputs.parameters.cluster-agent-image-repository}}
              tag: {{inputs.parameters.cluster-agent-image-tag}}
              doNotCheckTag: true
              pullSecrets:
                - name: docker-registry
            token: c9e21a248434a400b1de021dbdd554d790983a1212a5eac0ba36e79346ec52fd
            metricsProvider:
              enabled: true
            admissionController:
              enabled: true
            env:
              - name:  DD_USE_V2_API_SERIES
                value: "false"
              - name: DATADOG_HOST
                value: {{inputs.parameters.dd-url}}
          EOF

          helm repo add datadog https://helm.datadoghq.com
          helm repo update
          helm --namespace {{inputs.parameters.namespace}} install \
            --values /tmp/values.yaml \
            datadog-agent datadog/datadog

    - name: delete
      inputs:
        parameters:
          - name: namespace
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          helm --namespace {{inputs.parameters.namespace}} uninstall datadog-agent

    - name: health
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          until kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent; do
            sleep 1
          done

          while true; do
            for po in $(kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers); do
              kubectl exec --namespace {{inputs.parameters.namespace}} $po -c agent -- agent health || {
                sleep 4
                continue 2
              }
            done
            exit 0
          done

    - name: ready
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          until kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent; do
            sleep 1
          done

          until ! kubectl --namespace {{inputs.parameters.namespace}} get pod -l app=datadog-agent -o custom-columns=ready:status.conditions[?\(.type==\"Ready\"\)].status --no-headers | grep -v True; do
            kubectl --namespace {{inputs.parameters.namespace}} get pod -l app=datadog-agent
            sleep 1
          done

    - name: leader
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          until kubectl --namespace {{inputs.parameters.namespace}} get cm datadog-agent-leader-election -o jsonpath={.metadata.annotations."control-plane\.alpha\.kubernetes\.io/leader"}; do
            sleep 1
          done

    - name: wait
      inputs:
        parameters:
          - name: namespace
      steps:
        - - name: health
            template: health
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: ready
            template: ready
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: leader
            template: leader
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"

    - name: find-kube-state-metrics
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: mongo:4.4.1
        command: [mongo, "fake-datadog.{{inputs.parameters.namespace}}.svc.cluster.local/datadog"]
        source: |
          // This step is intended to test end-to-end scraping of prometheus metrics
          // by asserting the value of a few simple metrics collected from the
          // kubernetes_state integration.

          while (1) {
            var nb = db.series.find({
            metric: "kubernetes_state.daemonset.ready",
            tags: { $all: ["kube_namespace:{{inputs.parameters.namespace}}", "kube_daemon_set:datadog-agent"] },
            "points.0.1": { $eq: 1 } }).count();
            print("find: " + nb)
            if (nb != 0) {
              break;
            }
            sleep(2000);
          }

    - name: find-metrics-kubernetes
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: mongo:4.4.1
        command: [mongo, "fake-datadog.{{inputs.parameters.namespace}}.svc.cluster.local/datadog"]
        source: |
          while (1) {
            var nb = db.series.find({
              metric: {$regex: "kubernetes*"},
              tags: {$all: ["kube_namespace:kube-system", "pod_name:kube-controller-manager-k8s-e2e-tests-control-plane"]}
            }).count();

            print("find: " + nb)
            if (nb != 0) {
              break;
            }
            sleep(2000);
          }

    - name: find-container-meta
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: mongo:4.4.1
        command: [mongo, "fake-datadog.{{inputs.parameters.namespace}}.svc.cluster.local/datadog"]
        source: |
          while (1) {
            var nb = db.intake.find({
              $and : [
              {"apiKey":"123er"},
              {"gohai":{$exists: 1}},
              {"container-meta.kubelet_version":{$regex: "^v1."}},
              {"container-meta.cri_name":{$exists: 1}},
              {"container-meta.cri_version":{$exists: 1}} ]
            }).count();
            print("find: " + nb)
            if (nb != 0) {
              break;
            }
            sleep(2000);
          }

    - name: find-checks-hostname
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: mongo:4.4.1
        command: [mongo, "fake-datadog.{{inputs.parameters.namespace}}.svc.cluster.local/datadog"]
        source: |
          while (1) {
            sleep(2000);

            // Go memory check
            var nb = db.series.find({
              metric: "system.cpu.idle",
              host: "k8s-e2e-tests-control-plane"
            }).count();
            if (nb == 0) {
              print("no system.cpu.idle metric with nominal hostname");
              continue;
            }
            var nb = db.series.find({
              metric: "system.mem.free",
              host: ""
            }).count();
            if (nb == 0) {
              print("no system.mem.free metric with empty hostname");
              continue;
            }

            // Python network check
            var nb = db.series.find({
              metric: "system.net.bytes_sent",
              host: "k8s-e2e-tests-control-plane"
            }).count();
            if (nb == 0) {
              print("no system.net.bytes_sent metric with nominal hostname");
              continue;
            }
            var nb = db.series.find({
              metric: "system.net.bytes_sent",
              host: ""
            }).count();
            if (nb == 0) {
              print("no system.net.bytes_sent metric with empty hostname");
              continue;
            }

            print("All good");
            break;
          }

    - name: test
      inputs:
        parameters:
          - name: namespace
      steps:
        - - name: find-kube-state-metrics
            template: find-kube-state-metrics
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: find-metrics-kubernetes
            template: find-metrics-kubernetes
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: find-container-meta
            template: find-metrics-kubernetes
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: find-checks-hostname
            template: find-checks-hostname
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"

    - name: test-cws-e2e
      inputs:
        parameters:
          - name: namespace
          - name: site
      activeDeadlineSeconds: 900
      script:
        image: public.ecr.aws/docker/library/python:latest
        envFrom:
          - secretRef:
              name: dd-keys
        command: [bash]
        volumeMounts:
          - name: datadog-agent-volume
            mountPath: /host/datadog-agent
        source: |
          set -euo pipefail

          export DD_SITE={{inputs.parameters.site}}

          cd /host/datadog-agent/test/e2e/cws-tests
          python -m venv /tmp/.venv
          source /tmp/.venv/bin/activate
          pip install -q -r requirements.txt
          python tests/test_e2e_cws_kubernetes.py --namespace {{inputs.parameters.namespace}} --in-cluster

    - name: test-cspm-e2e
      inputs:
        parameters:
          - name: namespace
          - name: site
      activeDeadlineSeconds: 500
      script:
        image: public.ecr.aws/docker/library/python:latest
        envFrom:
          - secretRef:
              name: dd-keys
        command: [bash]
        volumeMounts:
          - name: datadog-agent-volume
            mountPath: /host/datadog-agent
        source: |
          set -euo pipefail

          export DD_SITE={{inputs.parameters.site}}

          cd /host/datadog-agent/test/e2e/cws-tests
          python -m venv /tmp/.venv
          source /tmp/.venv/bin/activate
          pip install -q -r requirements.txt
          python tests/test_e2e_cspm_kubernetes.py --namespace {{inputs.parameters.namespace}} --in-cluster

    - name: describe-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} describe pod $po
          done

    - name: describe-cluster-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-cluster-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} describe pod $po
          done

    - name: log-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po -c agent
          done

    - name: log-process-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po -c process-agent
          done

    - name: log-trace-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po -c trace-agent
          done

    - name: log-system-probe
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po -c system-probe
          done

    - name: log-security-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po -c security-agent
          done

    - name: log-cluster-agent
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-cluster-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} logs $po
          done

    - name: status
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} exec $po -c agent -- agent status
          done

    - name: config
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} exec $po -c agent -- agent config
          done

    - name: configcheck
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} exec $po -c agent -- agent configcheck
          done

    - name: tagger-list
      inputs:
        parameters:
          - name: namespace
      activeDeadlineSeconds: 300
      script:
        image: alpine/k8s:1.25.4
        command: [sh]
        source: |
          set -euo pipefail
          set -x

          kubectl --namespace {{inputs.parameters.namespace}} get pods -l app=datadog-agent -o custom-columns=name:metadata.name --no-headers | while read -r po; do
            kubectl --namespace {{inputs.parameters.namespace}} exec $po -c agent -- agent tagger-list
          done

    - name: diagnose
      inputs:
        parameters:
          - name: namespace
      steps:
        - - name: describe-agent
            template: describe-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: describe-cluster-agent
            template: describe-cluster-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-agent
            template: log-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-process-agent
            template: log-process-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-trace-agent
            template: log-trace-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-system-probe
            template: log-system-probe
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-security-agent
            template: log-security-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: log-cluster-agent
            template: log-cluster-agent
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: status
            template: status
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: config
            template: config
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: configcheck
            template: configcheck
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
          - name: tagger-list
            template: tagger-list
            arguments:
              parameters:
                - name: namespace
                  value: "{{inputs.parameters.namespace}}"
