apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: argo-datadog-cluster-agent-hpa
spec:
  entrypoint: main
  #onExit: delete # call argo submit --entrypoint delete instead
  arguments:
    parameters:
    - name: cluster-agent-rbac-cluster-role
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: dca
        rules:
        - apiGroups:
          - ""
          resources:
          - services
          - events
          - endpoints
          - pods
          - nodes
          - componentstatuses
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - "autoscaling"
          resources:
          - horizontalpodautoscalers
          verbs:
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - configmaps
          resourceNames:
          - datadogtoken
          verbs:
          - get
          - update
        - apiGroups:
          - ""
          resources:
          - configmaps
          verbs:
          - get
          - update
          - create

    - name: cluster-agent-rbac-sa
      value: |
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: dca
          namespace: default

    - name: cluster-agent-rbac-cluster-role-binding
      value: |
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: dca
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: dca
          subjects:
          - kind: ServiceAccount
            name: dca
            namespace: default

    - name: hpa-rbac
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: system:auth-delegator
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: system:auth-delegator
        subjects:
        - kind: ServiceAccount
          name: dca
          namespace: default
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: RoleBinding
        metadata:
          name: dca
          namespace: kube-system
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: Role
          name: extension-apiserver-authentication-reader
        subjects:
        - kind: ServiceAccount
          name: dca
          namespace: default
        ---
        apiVersion: apiregistration.k8s.io/v1beta1
        kind: APIService
        metadata:
          name: v1beta1.external.metrics.k8s.io
        spec:
          insecureSkipTLSVerify: true
          group: external.metrics.k8s.io
          groupPriorityMinimum: 100
          versionPriority: 100
          priority: 100
          service:
            name: datadog-cluster-hpa
            namespace: default
          version: v1beta1
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: external-metrics-reader
        rules:
        - apiGroups:
          - "external.metrics.k8s.io"
          resources:
          - "*"
          verbs:
          - list
          - get
          - watch
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: external-metrics-reader
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: external-metrics-reader
        subjects:
        - kind: ServiceAccount
          name: horizontal-pod-autoscaler
          namespace: kube-system

    - name: cluster-agent-deployment
      value: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: datadog-cluster-agent
          namespace: default
        spec:
          template:
            metadata:
              labels:
                app: datadog-cluster-agent
              name: datadog-cluster-agent
            spec:
              serviceAccount: dca
              containers:
              - name: datadog-cluster-agent
                image: datadog/cluster-agent-dev:dca-cmapi
                imagePullPolicy: IfNotPresent
                env:
                - name: DD_API_KEY
                  value: "123er"
                - name: DD_APP_KEY
                  value: "123er1"
                - name: DATADOG_HOST
                  value: "http://fake-datadog.default.svc.cluster.local"
                - name: DD_DD_URL
                  value: "http://fake-datadog.default.svc.cluster.local"
                - name: DD_LOG_LEVEL
                  value: "debug"
                - name: DD_CLUSTER_AGENT_AUTH_TOKEN
                  value: "c9e21a248434a400b1de021dbdd554d790983a1212a5eac0ba36e79346ec52fd"
                - name: DD_ENABLE_HPA
                  value: "true"
                livenessProbe:
                  exec:
                    command:
                    - datadog-cluster-agent
                    - status
                  initialDelaySeconds: 30
                  periodSeconds: 10
                readinessProbe:
                  exec:
                    command:
                    - datadog-cluster-agent
                    - status
                  failureThreshold: 5
                  initialDelaySeconds: 20

    - name: cluster-agent-svc
      value: |
        apiVersion: v1
        kind: Service
        metadata:
         name: dca
         labels:
           app: datadog-cluster-agent
        spec:
         ports:
         - port: 5001
           protocol: TCP
         selector:
           app: datadog-cluster-agent

    - name: cluster-agent-hpa-svc
      value: |
        kind: Service
        apiVersion: v1
        metadata:
          name: datadog-cluster-hpa
        spec:
          selector:
            app: datadog-cluster-agent
          ports:
          - protocol: TCP
            port: 443
            targetPort: 443

    - name: hpa-manifest
      value: |
        apiVersion: autoscaling/v2beta1
        kind: HorizontalPodAutoscaler
        metadata:
          name: nginxext
        spec:
          minReplicas: 1
          maxReplicas: 3
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: nginx
          metrics:
          - type: External
            external:
              metricName: nginx.net.request_per_s
              metricSelector:
                matchLabels:
                    kube_container_name: nginx
              targetAverageValue: 9

    - name: nginx
      value: |
        apiVersion: apps/v1beta1
        kind: Deployment
        metadata:
          name: nginx
          labels:
            app: nginx
        spec:
          replicas: 1
          selector:
            matchLabels:
              app: nginx
          template:
            metadata:
              labels:
                app: nginx
              annotations:
                ad.datadoghq.com/nginx.check_names: '["nginx"]'
                ad.datadoghq.com/nginx.init_configs: '[{}]'
                ad.datadoghq.com/nginx.instances: '[{"nginx_status_url": "http://%%host%%/nginx_status", "tags": "%%tags%%"}]'
                ad.datadoghq.com/nginx.logs: '[{"type": "docker","image": "nginx","service": "nginx","source": "nginx"}]'
            spec:
              containers:
              - name: nginx
                image: nginx:latest
                ports:
                - name: http
                  containerPort: 80
                volumeMounts:
                - name: "config"
                  mountPath: "/etc/nginx/nginx.conf"
                  subPath: "nginx.conf"
              volumes:
                - name: "config"
                  configMap:
                    name: "nginxconfig"

        ---
        apiVersion: v1
        data:
          nginx.conf: |+
            worker_processes  5;
            events {
              worker_connections  4096;  ## Default: 1024
            }
            http {
                server {
                    location /nginx_status {
                      stub_status on;
                      access_log  /dev/stdout;
                      allow all;
                    }

                    location / {
                        proxy_pass http://nginx:80;
                        proxy_set_header Host  $host;
                        proxy_set_header X-Real-IP $remote_addr;
                        proxy_redirect off;
                    }
                }
            }

        kind: ConfigMap
        metadata:
          name: nginxconfig
          namespace: default
        ---
        apiVersion: v1
        kind: Service
        metadata:
          labels:
            app: nginx
          name: nginx
        spec:
          selector:
            app: nginx
          ports:
          - name: http
            port: 8090
            targetPort: 80

    - name: agent-service-account
      value: |
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: datadog-agent
          namespace: default

    - name: agent-cluster-role
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: datadog-agent
        rules:
        - apiGroups:
          - ""
          resources:
          - nodes/metrics
          - nodes/spec
          - nodes/proxy
          verbs:
          - get

    - name: agent-cluster-role-binding
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: datadog-agent
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: datadog-agent
        subjects:
        - kind: ServiceAccount
          name: datadog-agent
          namespace: default

    - name: agent-configmap
      value: |
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: datadog
          namespace: default
        data:
          datadog.yaml: |
            api_key: "123er"
            dd_url: "http://fake-datadog.default.svc.cluster.local"
            listeners:
            - name: kubelet
            config_providers:
            - name: kubelet
              polling: true
            leader_election: true

          kubelet.yaml: |
            init_config:
            instances:
            - {}

          apiserver.yaml: |
            init_configs:
            instances:
            - {}

          network.yaml: |
            init_config:
            instances:
            - collect_connection_state: false
              excluded_interfaces:
                - lo
                - lo0

          docker.yaml: |
            init_config:
            instances:
            - {}

    - name: agent-daemonset
      value: |
        apiVersion: extensions/v1beta1
        kind: DaemonSet
        metadata:
          name: datadog-agent
          namespace: default
        spec:
          updateStrategy:
            rollingUpdate:
              maxUnavailable: 1
          template:
            metadata:
              labels:
                app: datadog-agent
              name: datadog-agent
            spec:
              serviceAccount: datadog-agent
              containers:
              - name: agent
                image: datadog/agent-dev:dca-cmapi # TODO provide the ECR PR image
                command:
                - /opt/datadog-agent/bin/agent/agent
                - start
                env:
                - name: DD_KUBERNETES_KUBELET_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                resources:
                  requests:
                    memory: "128Mi"
                    cpu: "100m"
                  limits:
                    memory: "256Mi"
                    cpu: "250m"
                livenessProbe:
                  exec:
                    command:
                    - /opt/datadog-agent/bin/agent/agent
                    - health
                  initialDelaySeconds: 30
                  periodSeconds: 5
                readinessProbe:
                  exec:
                    command:
                    - /opt/datadog-agent/bin/agent/agent
                    - health
                  failureThreshold: 5
                  initialDelaySeconds: 20
                volumeMounts:
                - name: datadog-config
                  mountPath: /etc/datadog-agent/datadog.yaml
                  subPath: datadog.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/kubernetes_apiserver.d/conf.yaml
                  subPath: apiserver.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/kubelet.d/conf.yaml
                  subPath: kubelet.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/network.d/conf.yaml.default
                  subPath: network.yaml
                - name: proc
                  mountPath: /host/proc
                  readOnly: true
                - name: cgroup
                  mountPath: /host/sys/fs/cgroup
                  readOnly: true
                - name: dockersocket
                  mountPath: /var/run/docker.sock
                  readOnly: true

              volumes:
              - name: datadog-config
                configMap:
                  name: datadog
              - name: proc
                hostPath:
                  path: /proc
              - name: cgroup
                hostPath:
                  path: /sys/fs/cgroup
              - hostPath:
                  path: /var/run/docker.sock
                name: dockersocket

    - name: fake-datadog-service
      value: |
        apiVersion: v1
        kind: Service
        metadata:
          name: fake-datadog
          namespace: default
        spec:
          ports:
          - port: 80
            protocol: TCP
            targetPort: 80
            name: api
          - port: 27017
            protocol: TCP
            targetPort: 27017
            name: mongo
          selector:
            app: fake-datadog
          type: ClusterIP

    - name: fake-datadog-deployment
      value: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: fake-datadog
          namespace: default
        spec:
          replicas: 1
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxSurge: 1
              maxUnavailable: 0
          template:
            metadata:
              labels:
                app: fake-datadog
            spec:
              containers:
              - name: api
                image: datadog/fake-datadog:query
              - name: mongo
                image: mongo:3.6.3

  templates:
  - name: main
    inputs:
      parameters:
      - name: nginx
      - name: agent-configmap
      - name: agent-service-account
      - name: agent-cluster-role
      - name: agent-cluster-role-binding
      - name: agent-daemonset
      - name: hpa-rbac
      - name: cluster-agent-rbac-cluster-role
      - name: cluster-agent-rbac-sa
      - name: cluster-agent-rbac-cluster-role-binding
      - name: cluster-agent-deployment
      - name: cluster-agent-hpa-svc
      - name: cluster-agent-svc
      - name: hpa-manifest
      - name: fake-datadog-deployment
      - name: fake-datadog-service
    steps:
    - - name: fake-dd-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.fake-datadog-deployment}}"
        - "{{inputs.parameters.fake-datadog-service}}"

      - name: nginx-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.nginx}}"

    - - name: fake-dd-reset
        template: fake-dd-reset

    - - name: agent-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.agent-configmap}}"
        - "{{inputs.parameters.agent-service-account}}"
        - "{{inputs.parameters.agent-cluster-role}}"
        - "{{inputs.parameters.agent-cluster-role-binding}}"
        - "{{inputs.parameters.agent-daemonset}}"

    - - name: cluster-agent-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role}}"
        - "{{inputs.parameters.cluster-agent-rbac-sa}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role-binding}}"
        - "{{inputs.parameters.cluster-agent-deployment}}"
        - "{{inputs.parameters.cluster-agent-svc}}"
        - "{{inputs.parameters.cluster-agent-hpa-svc}}"

    - - name: hpa
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.hpa-rbac}}"
        - "{{inputs.parameters.hpa-manifest}}"

    - - name: find-metrics-nginx
        template: find-metrics-nginx

    - - name: validate-hpa
        template: validate-hpa

    - - name: run-hpa
        template: run-hpa

    - - name: delete-nginx
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "delete"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.nginx}}"

    - - name: no-more-nginx
        template: no-more-metrics-nginx

    - - name: delete-cm-datadog-hpa
        template: delete-cm-datadog-hpa

  - name: query-job
    activeDeadlineSeconds: 120
    inputs:
      parameters:
      - name: manifest
    resource:
      action: create
      successCondition: status.succeeded > 0
      failureCondition: status.failed > 10
      manifest: "{{inputs.parameters.manifest}}"

  - name: delete
    inputs:
      parameters:
      - name: nginx
      - name: agent-configmap
      - name: agent-service-account
      - name: agent-cluster-role
      - name: agent-cluster-role-binding
      - name: agent-daemonset
      - name: fake-datadog-deployment
      - name: fake-datadog-service
      - name: hpa-rbac
      - name: cluster-agent-rbac-cluster-role
      - name: cluster-agent-rbac-sa
      - name: cluster-agent-rbac-cluster-role-binding
      - name: cluster-agent-deployment
      - name: cluster-agent-hpa-svc
      - name: cluster-agent-svc
      - name: hpa-manifest
    steps:
    - - name: delete-manifest
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "delete"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.nginx}}"
        - "{{inputs.parameters.agent-configmap}}"
        - "{{inputs.parameters.agent-service-account}}"
        - "{{inputs.parameters.agent-cluster-role}}"
        - "{{inputs.parameters.agent-cluster-role-binding}}"
        - "{{inputs.parameters.agent-daemonset}}"
        - "{{inputs.parameters.fake-datadog-service}}"
        - "{{inputs.parameters.fake-datadog-deployment}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role}}"
        - "{{inputs.parameters.cluster-agent-rbac-sa}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role-binding}}"
        - "{{inputs.parameters.cluster-agent-deployment}}"
        - "{{inputs.parameters.cluster-agent-svc}}"
        - "{{inputs.parameters.cluster-agent-hpa-svc}}"
        - "{{inputs.parameters.hpa-manifest}}"

  - name: manifest
    inputs:
      parameters:
      - name: action
      - name: manifest
    resource:
      action: "{{inputs.parameters.action}}"
      manifest: "{{inputs.parameters.manifest}}"

  - name: validate-hpa
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -x
        set -o pipefail

        # Verify the DCA has written in the CM
        until kubectl get cm datadog-hpa -o json -n default | jq -re .data[]
        do
         sleep 1
        done

  - name: run-hpa
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -x
        set -o pipefail

        nginxsvc=$(kubectl get svc nginx -o json -n default | jq -r .spec.clusterIP)
        until (( "$(kubectl get hpa nginxext -o json | jq -re .status.currentReplicas)" > 1 )); do
          for i in {1..100}
          do
            curl $nginxsvc:8090/nginx_status >& /dev/null
            sleep 0.03
          done
        done

  - name: fake-dd-reset
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -o pipefail
        set -x

        until curl -f http://fake-datadog.default.svc.cluster.local/_/reset -XPOST --connect-timeout 1
        do
          sleep 3
        done

  - name: delete-cm-datadog-hpa
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -o pipefail
        set -x
        kubectl delete cm datadog-hpa
        echo $?

  - name: find-metrics-nginx
    activeDeadlineSeconds: 200
    script:
      image: mongo:3.6.3
      command: [mongo, "fake-datadog.default.svc.cluster.local/datadog"]
      source: |
        while (1) {
          var nb = db.series.find({
            metric: {$regex: "nginx*"},
            tags: {$all: ["image_name:nginx"]}
          }).count();
          print("find: " + nb)
          if (nb != 0) {
            break;
          }
          sleep(2000);
        }

  - name: no-more-metrics-nginx
    activeDeadlineSeconds: 200
    script:
      image: mongo:3.6.3
      command: [mongo, "fake-datadog.default.svc.cluster.local/datadog"]
      source: |
        var prevNb = -1;
        while (1) {
          var nb = db.series.find({
            metric: {$regex: "nginx*"}
          }).count();

          print("prev-find: " + prevNb)
          print("find: " + nb)
          if (nb == prevNb) {
            break;
          }
          prevNb = nb;
          sleep(30000);
        }
