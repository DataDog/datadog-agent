apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: argo-datadog-cluster-agent-hpa
spec:
  entrypoint: main
  #onExit: delete # call argo submit --entrypoint delete instead
  arguments:
    parameters:
    - name: cluster-agent-rbac-cluster-role
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: dca
        rules:
        - apiGroups:
          - ""
          resources:
          - services
          - events
          - endpoints
          - pods
          - nodes
          - componentstatuses
          verbs:
          - get
          - list
          - watch
        - apiGroups:
          - "autoscaling"
          resources:
          - horizontalpodautoscalers
          verbs:
          - list
          - watch
        - apiGroups:
          - ""
          resources:
          - configmaps
          resourceNames:
          - datadogtoken
          verbs:
          - get
          - update
        - apiGroups:
          - ""
          resources:
          - configmaps
          verbs:
          - get
          - update
          - create

    - name: cluster-agent-rbac-sa
      value: |
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: dca
          namespace: default

    - name: cluster-agent-rbac-cluster-role-binding
      value: |
          apiVersion: rbac.authorization.k8s.io/v1
          kind: ClusterRoleBinding
          metadata:
            name: dca
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: ClusterRole
            name: dca
          subjects:
          - kind: ServiceAccount
            name: dca
            namespace: default

    - name: hpa-rbac
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: system:auth-delegator
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: system:auth-delegator
        subjects:
        - kind: ServiceAccount
          name: dca
          namespace: default
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: RoleBinding
        metadata:
          name: dca
          namespace: kube-system
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: Role
          name: extension-apiserver-authentication-reader
        subjects:
        - kind: ServiceAccount
          name: dca
          namespace: default
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: custom-metrics-resource-reader
        rules:
        - apiGroups:
          - ""
          resources:
          - namespaces
          - pods
          - services
          verbs:
          - get
          - list
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: custom-metrics-apiserver-resource-reader
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: custom-metrics-resource-reader
        subjects:
        - kind: ServiceAccount
          name: dca
          namespace: default
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: custom-metrics-getter
        rules:
        - apiGroups:
          - custom.metrics.k8s.io
          resources:
          - "*"
          verbs:
          - "*"
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: hpa-custom-metrics-getter
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: custom-metrics-getter
        subjects:
        - kind: ServiceAccount
          name: horizontal-pod-autoscaler
          namespace: kube-system
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: custom-metrics-server-resources
        rules:
        - apiGroups:
          - custom-metrics.metrics.k8s.io
          resources: ["*"]
          verbs: ["*"]
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: hpa-controller-custom-metrics
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: custom-metrics-server-resources
        subjects:
        - kind: ServiceAccount
          name: horizontal-pod-autoscaler
          namespace: kube-system
        ---
        apiVersion: apiregistration.k8s.io/v1beta1
        kind: APIService
        metadata:
          name: v1beta1.external.metrics.k8s.io
        spec:
          insecureSkipTLSVerify: true
          group: external.metrics.k8s.io
          groupPriorityMinimum: 100
          versionPriority: 100
          priority: 100
          service:
            name: datadog-cluster-hpa
            namespace: default
          version: v1beta1
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: external-metrics-reader
        rules:
        - apiGroups:
          - "external.metrics.k8s.io"
          resources:
          - "*"
          verbs:
          - list
          - get
          - watch
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: external-metrics-reader
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: external-metrics-reader
        subjects:
        - kind: ServiceAccount
          name: horizontal-pod-autoscaler
          namespace: kube-system

    - name: cluster-agent-deployment
      value: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: datadog-cluster-agent
          namespace: default
        spec:
          template:
            metadata:
              labels:
                app: datadog-cluster-agent
              name: datadog-cluster-agent
            spec:
              serviceAccount: dca
              containers:
              - name: datadog-cluster-agent
                image: charlyyfon/dca:alpha
                imagePullPolicy: IfNotPresent
                env:
                - name: DD_API_KEY
                  value: "123er"
                - name: DD_APP_KEY
                  value: "123er1"
                - name: DATADOG_HOST
                  value: "http://fake-datadog.default.svc.cluster.local"
                - name: DD_LOG_LEVEL
                  value: "debug"
                - name: DD_CLUSTER_AGENT_AUTH_TOKEN
                  value: "c9e21a248434a400b1de021dbdd554d790983a1212a5eac0ba36e79346ec52fd"
                - name: DD_ENABLE_HPA
                  value: "true"
                livenessProbe:
                  exec:
                    command:
                    - datadog-cluster-agent
                    - status
                  initialDelaySeconds: 30
                  periodSeconds: 10
                readinessProbe:
                  exec:
                    command:
                    - datadog-cluster-agent
                    - status
                  failureThreshold: 5
                  initialDelaySeconds: 20

    - name: cluster-agent-svc
      value: |
        apiVersion: v1
        kind: Service
        metadata:
         name: dca
         labels:
           app: datadog-cluster-agent
        spec:
         ports:
         - port: 5001
           protocol: TCP
         selector:
           app: datadog-cluster-agent

    - name: cluster-agent-hpa-svc
      value: |
        kind: Service
        apiVersion: v1
        metadata:
          name: datadog-cluster-hpa
        spec:
          selector:
            app: datadog-cluster-agent
          ports:
          - protocol: TCP
            port: 443
            targetPort: 443

    - name: hpa-manifest
      value: |
        apiVersion: autoscaling/v2beta1
        kind: HorizontalPodAutoscaler
        metadata:
          name: nginxext
        spec:
          minReplicas: 1
          maxReplicas: 5
          scaleTargetRef:
            apiVersion: apps/v1
            kind: Deployment
            name: nginx
          metrics:
          - type: External
            external:
              metricName: docker.mem.limit
              metricSelector:
                matchLabels:
                    dcos_version: 1.9.4
              targetAverageValue: "256000000"

    - name: redis
      value: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: redis
          namespace: default
        spec:
          replicas: 1
          template:
            metadata:
              labels:
                app: redis
              annotations:
                ad.datadoghq.com/redis.check_names: '["redisdb"]'
                ad.datadoghq.com/redis.init_configs: '[{}]'
                ad.datadoghq.com/redis.instances: '[{"host": "%%host%%", "port": "%%port%%"}]'
            spec:
              initContainers:
              - name: useless
                image: busybox:latest
                command:
                - /bin/true
                resources:
                  requests:
                    memory: "32Mi"
                    cpu: "25m"
                  limits:
                    memory: "64Mi"
                    cpu: "50m"
              containers:
              - name: redis
                image: redis
                ports:
                - containerPort: 6379
                resources:
                  requests:
                    memory: "64Mi"
                    cpu: "50m"
                  limits:
                    memory: "128Mi"
                    cpu: "100m"

    - name: agent-service-account
      value: |
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: datadog-agent
          namespace: default

    - name: agent-cluster-role
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: datadog-agent
        rules:
        - apiGroups:
          - ""
          resources:
          - nodes/metrics
          - nodes/spec
          - nodes/proxy
          verbs:
          - get

    - name: agent-cluster-role-binding
      value: |
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: datadog-agent
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: datadog-agent
        subjects:
        - kind: ServiceAccount
          name: datadog-agent
          namespace: default

    - name: agent-configmap
      value: |
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: datadog
          namespace: default
        data:
          datadog.yaml: |
            api_key: "123er"
            dd_url: "http://fake-datadog.default.svc.cluster.local"
            listeners:
            - name: kubelet
            config_providers:
            - name: kubelet
              polling: true
            leader_election: true

          kubelet.yaml: |
            init_config:
            instances:
            - {}

          apiserver.yaml: |
            init_configs:
            instances:
            - {}

          network.yaml: |
            init_config:
            instances:
            - collect_connection_state: false
              excluded_interfaces:
                - lo
                - lo0

          docker.yaml: |
            init_config:
            instances:
            - {}


    - name: agent-daemonset
      value: |
        apiVersion: extensions/v1beta1
        kind: DaemonSet
        metadata:
          name: datadog-agent
          namespace: default
        spec:
          updateStrategy:
            rollingUpdate:
              maxUnavailable: 1
          template:
            metadata:
              labels:
                app: datadog-agent
              name: datadog-agent
            spec:
              serviceAccount: datadog-agent
              containers:
              - name: agent
                image: datadog/agent:latest # TODO provide the ECR PR image
                command:
                - /opt/datadog-agent/bin/agent/agent
                - start
                env:
                - name: DD_KUBERNETES_KUBELET_HOST
                  valueFrom:
                    fieldRef:
                      fieldPath: status.hostIP
                resources:
                  requests:
                    memory: "128Mi"
                    cpu: "100m"
                  limits:
                    memory: "256Mi"
                    cpu: "250m"
                livenessProbe:
                  exec:
                    command:
                    - /opt/datadog-agent/bin/agent/agent
                    - health
                  initialDelaySeconds: 30
                  periodSeconds: 5
                readinessProbe:
                  exec:
                    command:
                    - /opt/datadog-agent/bin/agent/agent
                    - health
                  failureThreshold: 5
                  initialDelaySeconds: 20
                volumeMounts:
                - name: datadog-config
                  mountPath: /etc/datadog-agent/datadog.yaml
                  subPath: datadog.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/kubernetes_apiserver.d/conf.yaml
                  subPath: apiserver.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/kubelet.d/conf.yaml
                  subPath: kubelet.yaml
                - name: datadog-config
                  mountPath: /etc/datadog-agent/conf.d/network.d/conf.yaml.default
                  subPath: network.yaml
                - name: proc
                  mountPath: /host/proc
                  readOnly: true
                - name: cgroup
                  mountPath: /host/sys/fs/cgroup
                  readOnly: true
                - name: dockersocket
                  mountPath: /var/run/docker.sock
                  readOnly: true

              volumes:
              - name: datadog-config
                configMap:
                  name: datadog
              - name: proc
                hostPath:
                  path: /proc
              - name: cgroup
                hostPath:
                  path: /sys/fs/cgroup
              - hostPath:
                  path: /var/run/docker.sock
                name: dockersocket

    - name: fake-datadog-service
      value: |
        apiVersion: v1
        kind: Service
        metadata:
          name: fake-datadog
          namespace: default
        spec:
          ports:
          - port: 80
            protocol: TCP
            targetPort: 80
            name: api
          - port: 27017
            protocol: TCP
            targetPort: 27017
            name: mongo
          selector:
            app: fake-datadog
          type: ClusterIP

    - name: fake-datadog-deployment
      value: |
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: fake-datadog
          namespace: default
        spec:
          replicas: 1
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxSurge: 1
              maxUnavailable: 0
          template:
            metadata:
              labels:
                app: fake-datadog
            spec:
              containers:
              - name: api
                image: datadog/fake-datadog:latest
              - name: mongo
                image: mongo:3.6.3

  templates:
  - name: main
    inputs:
      parameters:
      - name: redis
      - name: agent-configmap
      - name: agent-service-account
      - name: agent-cluster-role
      - name: agent-cluster-role-binding
      - name: agent-daemonset
      - name: hpa-rbac
      - name: cluster-agent-rbac-cluster-role
      - name: cluster-agent-rbac-sa
      - name: cluster-agent-rbac-cluster-role-binding
      - name: cluster-agent-deployment
      - name: cluster-agent-hpa-svc
      - name: cluster-agent-svc
      - name: hpa-manifest
      - name: fake-datadog-deployment
      - name: fake-datadog-service
    steps:
    - - name: fake-dd-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.fake-datadog-deployment}}"
        - "{{inputs.parameters.fake-datadog-service}}"

      - name: redis-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.redis}}"

    - - name: fake-dd-reset
        template: fake-dd-reset

    - - name: agent-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.agent-configmap}}"
        - "{{inputs.parameters.agent-service-account}}"
        - "{{inputs.parameters.agent-cluster-role}}"
        - "{{inputs.parameters.agent-cluster-role-binding}}"
        - "{{inputs.parameters.agent-daemonset}}"

    - - name: cluster-agent-setup
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "apply"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role}}"
        - "{{inputs.parameters.cluster-agent-rbac-sa}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role-binding}}"
        - "{{inputs.parameters.cluster-agent-deployment}}"
        - "{{inputs.parameters.cluster-agent-svc}}"
        - "{{inputs.parameters.cluster-agent-hpa-svc}}"

    - - name: health
        template: datadog-agent-health

      - name: leader
        template: datadog-agent-leader

    - - name: find-metrics-kubernetes
        template: find-metrics-kubernetes

      - name: find-metrics-redis
        template: find-metrics-redis

    - - name: hpa
        template: manifest
        arguments:
          parameters:
          - name: action
          value: "apply"
          - name: manifest
          value: "{{item}}"
        withItems:
        - "{{input.parameters.hpa-rbac}}"
        - "{{input.parameters.hpa-manifest}}"

      - name: validate-hpa
        template: validate-hpa

    - - name: delete-redis
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "delete"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.redis}}"

    - - name: no-more-redis
        template: no-more-metrics-redis

  - name: query-job
    activeDeadlineSeconds: 120
    inputs:
      parameters:
      - name: manifest
    resource:
      action: create
      successCondition: status.succeeded > 0
      failureCondition: status.failed > 10
      manifest: "{{inputs.parameters.manifest}}"

  - name: delete
    inputs:
      parameters:
      - name: redis
      - name: agent-configmap
      - name: agent-service-account
      - name: agent-cluster-role
      - name: agent-cluster-role-binding
      - name: agent-daemonset
      - name: fake-datadog-deployment
      - name: fake-datadog-service
      - name: hpa-rbac
      - name: cluster-agent-rbac-cluster-role
      - name: cluster-agent-rbac-sa
      - name: cluster-agent-rbac-cluster-role-binding
      - name: cluster-agent-deployment
      - name: cluster-agent-hpa-svc
      - name: cluster-agent-svc
      - name: hpa-manifest
    steps:
    - - name: delete-manifest
        template: manifest
        arguments:
          parameters:
          - name: action
            value: "delete"
          - name: manifest
            value: "{{item}}"
        withItems:
        - "{{inputs.parameters.redis}}"
        - "{{inputs.parameters.agent-configmap}}"
        - "{{inputs.parameters.agent-service-account}}"
        - "{{inputs.parameters.agent-cluster-role}}"
        - "{{inputs.parameters.agent-cluster-role-binding}}"
        - "{{inputs.parameters.agent-daemonset}}"
        - "{{inputs.parameters.fake-datadog-service}}"
        - "{{inputs.parameters.fake-datadog-deployment}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role}}"
        - "{{inputs.parameters.cluster-agent-rbac-sa}}"
        - "{{inputs.parameters.cluster-agent-rbac-cluster-role-binding}}"
        - "{{inputs.parameters.cluster-agent-deployment}}"
        - "{{inputs.parameters.cluster-agent-svc}}"
        - "{{inputs.parameters.cluster-agent-hpa-svc}}"

  - name: manifest
    inputs:
      parameters:
      - name: action
      - name: manifest
    resource:
      action: "{{inputs.parameters.action}}"
      manifest: "{{inputs.parameters.manifest}}"

  - name: validate-hpa
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -x
        set -o pipefail

        # Verify HPA is set up
        until kubectl get hpa -o json -n default | jq -re .items[].metadata.name
        do
         sleep 1
        done

        # Verify DCA processed the HPA
        dca = $(kubectl get po -l app=datadog-cluster-agent -o json -n default | jq -re .items[].metadata.name
        while true
        do
          kubectl logs $dca | grep "Finished processing hpa.CustomExternalMetric" || {
               sleep 4
               continue
             }
           done
        done

        # Verify the DCA has written in the CM
        until kubectl get cm -o json -n default | jq -re .data[]
        do
         sleep 1
        done

  - name: datadog-agent-health
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -x
        set -o pipefail

        until kubectl get po -l app=datadog-agent -o json -n default | jq -re .items[].metadata.name
        do
          sleep 1
        done

        while true
        do
          for po in $(kubectl get po -l app=datadog-agent -o json -n default | jq -re .items[].metadata.name)
          do
            kubectl exec $po agent health || {
              sleep 4
              continue 2
            }
          done
          exit 0
        done

  - name: datadog-agent-leader
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -x
        set -o pipefail

        until kubectl get cm datadog-leader-election -n default -o json |  jq '.metadata.annotations | .["control-plane.alpha.kubernetes.io/leader"]'
        do
          sleep 1
        done

  - name: fake-dd-reset
    activeDeadlineSeconds: 200
    script:
      image: argoproj/argoexec:latest
      command: [bash]
      source: |
        set -o pipefail
        set -x

        until curl -f http://fake-datadog.default.svc.cluster.local/_/reset -XPOST --connect-timeout 1
        do
          sleep 3
        done

  - name: find-metrics-kubernetes
    activeDeadlineSeconds: 200
    script:
      image: mongo:3.6.3
      command: [mongo, "fake-datadog.default.svc.cluster.local/datadog"]
      source: |
        while (1) {
          var nb = db.series.find({
            metric: {$regex: "kubernetes*"},
            tags: {$all: ["kube_namespace:kube-system", "pod_name:kube-controller-manager"]}
          }).count();

          print("find: " + nb)
          if (nb != 0) {
            break;
          }
          sleep(2000);
        }

  - name: find-metrics-redis
    activeDeadlineSeconds: 200
    script:
      image: mongo:3.6.3
      command: [mongo, "fake-datadog.default.svc.cluster.local/datadog"]
      source: |
        while (1) {
          var nb = db.series.find({
            metric: {$regex: "redis*"}
          }).count();

          print("find: " + nb)
          if (nb != 0) {
            break;
          }
          sleep(2000);
        }

  - name: no-more-metrics-redis
    activeDeadlineSeconds: 200
    script:
      image: mongo:3.6.3
      command: [mongo, "fake-datadog.default.svc.cluster.local/datadog"]
      source: |
        var prevNb = -1;
        while (1) {
          var nb = db.series.find({
            metric: {$regex: "redis*"}
          }).count();

          print("prev-find: " + prevNb)
          print("find: " + nb)
          if (nb == prevNb) {
            break;
          }
          prevNb = nb;
          sleep(30000);
        }
